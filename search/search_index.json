{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What Single Digital Presence offers \u00b6 Info Your are viewing a version of the documentation that is currently under active development. Some of the sections are missing or incomplete - they are marked with asterisk in the navigation on the left. Single Digital Presence (SDP) is an open, flexible technical solution that government agencies can use to reduce the cost and effort of digital development. SDP is about making it easier for citizens to find, understand and use Victorian Government information. SDP is a project of the Digital Design and Innovation branch at the Department of Premier and Cabinet. Benefits of SDP \u00b6 Get more done for less Spend money on innovation instead of duplication Increases collaboration across agencies and beyond Continuous improvement Secure, supported Easy to use and administer Write once, share everywhere About SDP products \u00b6 SDP offers three products that can be used independently, or as a package: Bay is the infrastructure and hosting layer. Tide is the distribution layer. Ripple is the front-end presentation layer.","title":"About"},{"location":"#what-single-digital-presence-offers","text":"Info Your are viewing a version of the documentation that is currently under active development. Some of the sections are missing or incomplete - they are marked with asterisk in the navigation on the left. Single Digital Presence (SDP) is an open, flexible technical solution that government agencies can use to reduce the cost and effort of digital development. SDP is about making it easier for citizens to find, understand and use Victorian Government information. SDP is a project of the Digital Design and Innovation branch at the Department of Premier and Cabinet.","title":"What Single Digital Presence offers"},{"location":"#benefits-of-sdp","text":"Get more done for less Spend money on innovation instead of duplication Increases collaboration across agencies and beyond Continuous improvement Secure, supported Easy to use and administer Write once, share everywhere","title":"Benefits of SDP"},{"location":"#about-sdp-products","text":"SDP offers three products that can be used independently, or as a package: Bay is the infrastructure and hosting layer. Tide is the distribution layer. Ripple is the front-end presentation layer.","title":"About SDP products"},{"location":"architecture/","text":"Architecture \u00b6 Single Digital Presence is a distribution that consists of Content Repository with exposed API (headless Drupal distribution called Tide ) and a front-end components library ( Vue.js with Nuxt server rendering framework called Ripple ) hosted on the latest generation hosting platform ( Kubernetes -based Docker container platform called Bay ). Application system components \u00b6 At the application layer, there are 2 main components of the system: Tide - Drupal 8 headless distribution that serves as a content repository. Ripple - Vue.js-based library of front-end components. Each instance of Ripple serves as a standalone front-end application for a website. Note The two main requirements that have significant affect on the architecture were: Content sharing across multiple sites. Content syndication via API. Content Sharing is a common issue amongst larger organisation, however the solutions are highly complex and the publicly available options are not mature enough for immediate use. System components inheritance \u00b6 There are 3 layer of components in the Distribution. The features provided by every layer contribute to a final particular website feature set. Each of the layers is owned, supported and maintained by a distinct community: - Open Source - provides Drupal core and contributed modules. It is maintained by a worldwide Drupal community. - Distribution - provides content types, multi-channel and API features. It is maintained by SDP development team. - Specific website - provides unique site features and design components. It is maintained by a particular website development team. See Tide and Ripple for more information about architecture. Content Sharing \u00b6 Content Editors author content and select content sharing targets (Frontend Websites and site sections) for each content piece. Drupal will then serve this content as data through API to each Frontend Website, implemented as a separate front-end application. Content Repository site has only a basic frontend and its IP restricted to a list of allowed IP addresses, so that content editors from designated offices could access the editorial interface. The API endpoints for the Content Repository site are accessible to the world over the same predefined domain (e.g., https://api.agency.gov.au ). There is no authentication for content consumers. All content editing for all sites is performed through the central content repository instance (e.g. https://content.agency.gov.au ). There are no restrictions for editing content between the various sites, allowing content editors to be used across sites to better utilise limited resources. Content Approvals are still restricted to ensure content is only published upon approval by relevant users. This ensures cross site changes do not go public without proper approval. All content changes are tracked, so users making changes to the wrong site can receive further training to prevent future mistakes.","title":"Architecture"},{"location":"architecture/#architecture","text":"Single Digital Presence is a distribution that consists of Content Repository with exposed API (headless Drupal distribution called Tide ) and a front-end components library ( Vue.js with Nuxt server rendering framework called Ripple ) hosted on the latest generation hosting platform ( Kubernetes -based Docker container platform called Bay ).","title":"Architecture"},{"location":"architecture/#application-system-components","text":"At the application layer, there are 2 main components of the system: Tide - Drupal 8 headless distribution that serves as a content repository. Ripple - Vue.js-based library of front-end components. Each instance of Ripple serves as a standalone front-end application for a website. Note The two main requirements that have significant affect on the architecture were: Content sharing across multiple sites. Content syndication via API. Content Sharing is a common issue amongst larger organisation, however the solutions are highly complex and the publicly available options are not mature enough for immediate use.","title":"Application system components"},{"location":"architecture/#system-components-inheritance","text":"There are 3 layer of components in the Distribution. The features provided by every layer contribute to a final particular website feature set. Each of the layers is owned, supported and maintained by a distinct community: - Open Source - provides Drupal core and contributed modules. It is maintained by a worldwide Drupal community. - Distribution - provides content types, multi-channel and API features. It is maintained by SDP development team. - Specific website - provides unique site features and design components. It is maintained by a particular website development team. See Tide and Ripple for more information about architecture.","title":"System components inheritance"},{"location":"architecture/#content-sharing","text":"Content Editors author content and select content sharing targets (Frontend Websites and site sections) for each content piece. Drupal will then serve this content as data through API to each Frontend Website, implemented as a separate front-end application. Content Repository site has only a basic frontend and its IP restricted to a list of allowed IP addresses, so that content editors from designated offices could access the editorial interface. The API endpoints for the Content Repository site are accessible to the world over the same predefined domain (e.g., https://api.agency.gov.au ). There is no authentication for content consumers. All content editing for all sites is performed through the central content repository instance (e.g. https://content.agency.gov.au ). There are no restrictions for editing content between the various sites, allowing content editors to be used across sites to better utilise limited resources. Content Approvals are still restricted to ensure content is only published upon approval by relevant users. This ensures cross site changes do not go public without proper approval. All content changes are tracked, so users making changes to the wrong site can receive further training to prevent future mistakes.","title":"Content Sharing"},{"location":"overview/","text":"Overview \u00b6 SDP project covers implementing a Drupal distribution to build a Content Repository containing site sections and providing content for Frontend Websites. It also covers providing of technical implementation to build fully independent sites. Info Example of Content Repository is https://vic.gov.au , which has site-sections such as Aboriginal Victoria or Family Violence. Semi-independent sites are the other sites that have their content centrally managed. An example of such site is the Office of the Victorian Government Architect site. Fully independent sites are completely separate installations of the whole distribution. Project goals \u00b6 Making it easier to find, understand and use Victorian Government information Bringing 50 websites onto one platform and providing a consistent user experience Simplifying and standardising publishing Providing user research and a user first approach Reducing cost Increasing security Benefits \u00b6 More consistent UX Improved Admin Interface Improved Security and Improvement process Cheaper, more scalable and performant hosting Cost savings across Govt Better Government (and community) collaboration Better Developer Experience","title":"Overview"},{"location":"overview/#overview","text":"SDP project covers implementing a Drupal distribution to build a Content Repository containing site sections and providing content for Frontend Websites. It also covers providing of technical implementation to build fully independent sites. Info Example of Content Repository is https://vic.gov.au , which has site-sections such as Aboriginal Victoria or Family Violence. Semi-independent sites are the other sites that have their content centrally managed. An example of such site is the Office of the Victorian Government Architect site. Fully independent sites are completely separate installations of the whole distribution.","title":"Overview"},{"location":"overview/#project-goals","text":"Making it easier to find, understand and use Victorian Government information Bringing 50 websites onto one platform and providing a consistent user experience Simplifying and standardising publishing Providing user research and a user first approach Reducing cost Increasing security","title":"Project goals"},{"location":"overview/#benefits","text":"More consistent UX Improved Admin Interface Improved Security and Improvement process Cheaper, more scalable and performant hosting Cost savings across Govt Better Government (and community) collaboration Better Developer Experience","title":"Benefits"},{"location":"terminology/","text":"Terminology \u00b6 Atomic design \u00b6 Atomic design is methodology for creating design systems. There are five distinct levels in atomic design: Atoms Molecules Organisms Templates Pages API \u00b6 Application Programming Interface (API) is a mechanism to allow applications to communicate with one another. An API is not a database. It is an access point to an app that can access a database. Bay \u00b6 Bay is a fully managed platform and hosting environment that provides an open Platform as a Service model managed by SDP. It: - is an open-source hosting platform based on Lagoon. - allows agencies to build, test and deliver websites via the cloud. Component \u00b6 A UI pattern library is simply a place where all of these components live together. UI pattern libraries can be part of a wider design system. Content Repository \u00b6 Database of digital content with an associated set of data management, search and access methods allowing application-independent access to the content, rather like a digital library, but with the ability to store and modify content in addition to searching and retrieving. It provides an API for clients (frontend websites, mobile applications, etc.) to interact with content. Drupal \u00b6 Drupal is free, open source software that can be used by individuals or groups of users to easily create and manage many types of Web sites. The application includes a content management platform and a development framework. Frontend Website \u00b6 A website built with front-end and server rendering technologies connected to the Content Repository. Git \u00b6 Git is a distributed version-control system for tracking changes in source code during software development.It is designed for coordinating work among programmers, but it can be used to track changes in any set of files. GitHub \u00b6 GitHub is a Git repository hosting service, but it adds many of its own features. While Git is a command line tool, GitHub provides a Web-based graphical interface. It also provides access control and several collaboration features, such as a wikis and basic task management tools for every project. Nuxt \u00b6 Nuxt.js is a framework that helps to build server-rendered Vue.js applications easily. It abstracts most of the complex configuration involved in managing things like asynchronous data, middleware, and routing. It's similar to Angular Universal for Angular, and Next.js for React. Pull-request, PR \u00b6 Pull requests let you tell others about changes you've pushed to a GitHub repository. Once a pull request is sent, interested parties can review the set of changes, discuss potential modifications, and even push follow-up commits if necessary. Ripple \u00b6 Ripple offers a consistent design system, making it easier for citizens to find, understand and use Victorian Government information maintained by SDP. It: - is fully open and includes a library of reusable components, based on atomic pattern design. - uses Vue.js and Nuxt to deliver a consistent look and feel across government websites. - includes a starter kit for agencies. SDP \u00b6 Single Digital Presence is an open, flexible technical solution that government agencies can use to reduce the cost and effort of digital development. Style guide \u00b6 Front-end application to demonstrate components of the Ripple Pattern Library. See more about style guide Storybook \u00b6 Storybook software that powers style guide . Tide \u00b6 Tide is an API first, headless content management system using Drupal 8 and maintained by SDP. Custom built to meet Victorian Government requirements, it offers: - multi-site content distribution - pick and mix features - centralised feature governance Vue.js \u00b6 Vue is a progressive framework for building user interfaces. Unlike other monolithic frameworks, Vue is designed from the ground up to be incrementally adoptable.","title":"Terminology"},{"location":"terminology/#terminology","text":"","title":"Terminology"},{"location":"terminology/#atomic-design","text":"Atomic design is methodology for creating design systems. There are five distinct levels in atomic design: Atoms Molecules Organisms Templates Pages","title":"Atomic design"},{"location":"terminology/#api","text":"Application Programming Interface (API) is a mechanism to allow applications to communicate with one another. An API is not a database. It is an access point to an app that can access a database.","title":"API"},{"location":"terminology/#bay","text":"Bay is a fully managed platform and hosting environment that provides an open Platform as a Service model managed by SDP. It: - is an open-source hosting platform based on Lagoon. - allows agencies to build, test and deliver websites via the cloud.","title":"Bay"},{"location":"terminology/#component","text":"A UI pattern library is simply a place where all of these components live together. UI pattern libraries can be part of a wider design system.","title":"Component"},{"location":"terminology/#content-repository","text":"Database of digital content with an associated set of data management, search and access methods allowing application-independent access to the content, rather like a digital library, but with the ability to store and modify content in addition to searching and retrieving. It provides an API for clients (frontend websites, mobile applications, etc.) to interact with content.","title":"Content Repository"},{"location":"terminology/#drupal","text":"Drupal is free, open source software that can be used by individuals or groups of users to easily create and manage many types of Web sites. The application includes a content management platform and a development framework.","title":"Drupal"},{"location":"terminology/#frontend-website","text":"A website built with front-end and server rendering technologies connected to the Content Repository.","title":"Frontend Website"},{"location":"terminology/#git","text":"Git is a distributed version-control system for tracking changes in source code during software development.It is designed for coordinating work among programmers, but it can be used to track changes in any set of files.","title":"Git"},{"location":"terminology/#github","text":"GitHub is a Git repository hosting service, but it adds many of its own features. While Git is a command line tool, GitHub provides a Web-based graphical interface. It also provides access control and several collaboration features, such as a wikis and basic task management tools for every project.","title":"GitHub"},{"location":"terminology/#nuxt","text":"Nuxt.js is a framework that helps to build server-rendered Vue.js applications easily. It abstracts most of the complex configuration involved in managing things like asynchronous data, middleware, and routing. It's similar to Angular Universal for Angular, and Next.js for React.","title":"Nuxt"},{"location":"terminology/#pull-request-pr","text":"Pull requests let you tell others about changes you've pushed to a GitHub repository. Once a pull request is sent, interested parties can review the set of changes, discuss potential modifications, and even push follow-up commits if necessary.","title":"Pull-request, PR"},{"location":"terminology/#ripple","text":"Ripple offers a consistent design system, making it easier for citizens to find, understand and use Victorian Government information maintained by SDP. It: - is fully open and includes a library of reusable components, based on atomic pattern design. - uses Vue.js and Nuxt to deliver a consistent look and feel across government websites. - includes a starter kit for agencies.","title":"Ripple"},{"location":"terminology/#sdp","text":"Single Digital Presence is an open, flexible technical solution that government agencies can use to reduce the cost and effort of digital development.","title":"SDP"},{"location":"terminology/#style-guide","text":"Front-end application to demonstrate components of the Ripple Pattern Library. See more about style guide","title":"Style guide"},{"location":"terminology/#storybook","text":"Storybook software that powers style guide .","title":"Storybook"},{"location":"terminology/#tide","text":"Tide is an API first, headless content management system using Drupal 8 and maintained by SDP. Custom built to meet Victorian Government requirements, it offers: - multi-site content distribution - pick and mix features - centralised feature governance","title":"Tide"},{"location":"terminology/#vuejs","text":"Vue is a progressive framework for building user interfaces. Unlike other monolithic frameworks, Vue is designed from the ground up to be incrementally adoptable.","title":"Vue.js"},{"location":"assets/README.content-repository/","text":"name \u00b6 Drupal 8 implementation of Content Repository for name Prerequisites \u00b6 Make sure that you have latest versions of all required software installed: Docker Pygmy Ahoy Make sure that all local web development services are shut down ( apache/nginx , mysql , MAMP etc). Local environment setup \u00b6 curl https://raw.githubusercontent.com/dpc-sdp/dev-tools/master/install | bash pygmy up ahoy build Local URL -- http:// machine_name .docker.amazee.io/ Available ahoy commands \u00b6 Run each command as ahoy <command> . build Build or rebuild project. clean Remove all build files. clean-full Remove all development files. cli Start a shell inside CLI container or run a command. composer-merge Merge composer files. deploy Deploy or re-deploy a branch in Bay. doctor Identify problems with current stack. down Stop Docker containers and remove container, images, volumes and networks. drush Run drush commands in the CLI service container. flush-redis Flush Redis cache. info Print information about this project. install-dev Install dependencies. install-site Install site. lint Lint code. login Login to a website. logs Show Docker logs. pull Pull latest docker images. restart Restart all stopped and running Docker containers. start Start existing Docker containers. stop Stop running Docker containers. test-behat Run Behat tests. up Build and start Docker containers. SSHing into CLI container \u00b6 ahoy cli Running a command in CLI container \u00b6 ahoy cli ls /app Mailhog. \u00b6 Mailhog is included with pygmy and is available at http://mailhog.docker.amazee.io/ Stage file proxy. \u00b6 Stage File Proxy is enabled on all non production environments so files are automatically downloaded directly from prod on demand. Adding Drupal modules \u00b6 Modules needs to be added in 2 steps: 1. Require module code installation (through composer). 2. Enable module during site installation. Adding contrib modules composer require drupal/module_name or for specific versions composer require drupal/module_name:1.2 Adding modules as local packages Add local package information to the root of composer.json : \"repositories\": { \"dpc-sdp/tide_page\": { \"type\": \"path\", \"url\": \"dpc-sdp/tide_page\" }, } composer require tide_page To make sure that Composer triggers dependency tree rebuild, run ahoy clean . Run composer update --lock . This will install all dependencies and update root composer.lock file with newly added module. Adding patches for composer packages \u00b6 Add title and url to patch on drupal.org to the patches array in extra section in composer.json . \"extra\": { \"patches\": { \"drupal/core\": { \"Contextual links should not be added inside another link - https://www.drupal.org/node/2898875\": \"https://www.drupal.org/files/issues/contextual_links_should-2898875-3.patch\" } } } composer update --lock Coding standards \u00b6 PHP and JS code linting uses PHP_CodeSniffer with Drupal rules from Coder module and additional local overrides in phpcs.xml.dist and .eslintrc . Behat tests \u00b6 Behat configuration uses multiple extensions: - Drupal Behat Extension - Drupal integration layer. Allows to work with Drupal API from within step definitions. - Behat Screenshot Extension - Behat extension and a step definition to create HTML and image screenshots on demand or test fail. - Behat Progress Fail Output Extension - Behat output formatter to show progress as TAP and fail messages inline. Useful to get feedback about failed tests while continuing test run. - YoursiteDrupalContext - Site-specific Drupal context with custom step definitions. - YoursiteMinkContext - Site-specific Mink context with custom step definitions. Run tests locally: Run Behat tests: ahoy test-behat Run specific test feature: ahoy test-behat tests/behat/features/homepage.feature Run specific test tag: ahoy test-behat -- --tags=wip Automated builds (Continuous Integration) \u00b6 In software engineering, continuous integration (CI) is the practice of merging all developer working copies to a shared mainline several times a day. Before feature changes can be merged into a shared mainline, a complete build must run and pass all tests on CI server. This project uses Circle CI as CI server: it imports production backups into fully built codebase and runs code linting and tests. When tests pass, a deployment process is triggered for nominated branches (usually, master and develop ). Add [skip ci] to the commit subject to skip CI build. Useful for documentation changes. SSH Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. Test artifacts Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI. Debugging \u00b6 PHP application from browser Trigger xDebug from web browser (using one of the browser extensions) so that PHPStorm recognises the server yoursite.docker.amazee.io and configures the path mapping. Alternatively, you can create the server in PHPStorm Settings. Make sure serverName to be yoursite.docker.amazee.io PHP scripts ahoy cli xdebug.sh path/to/script For example, to run a single Behat test: xdebug.sh vendor/bin/behat path/to/test.feature Drush commands ahoy cli `./xdebug.sh vendor/bin/drush <DRUSH_COMMAND> DB connection details Run ahoy info to get the port number. Host: 127.0.0.1 Username: drupal Password: drupal Database: drupal Port: <get from \"ahoy info\">","title":"_name_"},{"location":"assets/README.content-repository/#name","text":"Drupal 8 implementation of Content Repository for name","title":"name"},{"location":"assets/README.content-repository/#prerequisites","text":"Make sure that you have latest versions of all required software installed: Docker Pygmy Ahoy Make sure that all local web development services are shut down ( apache/nginx , mysql , MAMP etc).","title":"Prerequisites"},{"location":"assets/README.content-repository/#local-environment-setup","text":"curl https://raw.githubusercontent.com/dpc-sdp/dev-tools/master/install | bash pygmy up ahoy build Local URL -- http:// machine_name .docker.amazee.io/","title":"Local environment setup"},{"location":"assets/README.content-repository/#available-ahoy-commands","text":"Run each command as ahoy <command> . build Build or rebuild project. clean Remove all build files. clean-full Remove all development files. cli Start a shell inside CLI container or run a command. composer-merge Merge composer files. deploy Deploy or re-deploy a branch in Bay. doctor Identify problems with current stack. down Stop Docker containers and remove container, images, volumes and networks. drush Run drush commands in the CLI service container. flush-redis Flush Redis cache. info Print information about this project. install-dev Install dependencies. install-site Install site. lint Lint code. login Login to a website. logs Show Docker logs. pull Pull latest docker images. restart Restart all stopped and running Docker containers. start Start existing Docker containers. stop Stop running Docker containers. test-behat Run Behat tests. up Build and start Docker containers.","title":"Available ahoy commands"},{"location":"assets/README.content-repository/#sshing-into-cli-container","text":"ahoy cli","title":"SSHing into CLI container"},{"location":"assets/README.content-repository/#running-a-command-in-cli-container","text":"ahoy cli ls /app","title":"Running a command in CLI container"},{"location":"assets/README.content-repository/#mailhog","text":"Mailhog is included with pygmy and is available at http://mailhog.docker.amazee.io/","title":"Mailhog."},{"location":"assets/README.content-repository/#stage-file-proxy","text":"Stage File Proxy is enabled on all non production environments so files are automatically downloaded directly from prod on demand.","title":"Stage file proxy."},{"location":"assets/README.content-repository/#adding-drupal-modules","text":"Modules needs to be added in 2 steps: 1. Require module code installation (through composer). 2. Enable module during site installation.","title":"Adding Drupal modules"},{"location":"assets/README.content-repository/#adding-patches-for-composer-packages","text":"Add title and url to patch on drupal.org to the patches array in extra section in composer.json . \"extra\": { \"patches\": { \"drupal/core\": { \"Contextual links should not be added inside another link - https://www.drupal.org/node/2898875\": \"https://www.drupal.org/files/issues/contextual_links_should-2898875-3.patch\" } } } composer update --lock","title":"Adding patches for composer packages"},{"location":"assets/README.content-repository/#coding-standards","text":"PHP and JS code linting uses PHP_CodeSniffer with Drupal rules from Coder module and additional local overrides in phpcs.xml.dist and .eslintrc .","title":"Coding standards"},{"location":"assets/README.content-repository/#behat-tests","text":"Behat configuration uses multiple extensions: - Drupal Behat Extension - Drupal integration layer. Allows to work with Drupal API from within step definitions. - Behat Screenshot Extension - Behat extension and a step definition to create HTML and image screenshots on demand or test fail. - Behat Progress Fail Output Extension - Behat output formatter to show progress as TAP and fail messages inline. Useful to get feedback about failed tests while continuing test run. - YoursiteDrupalContext - Site-specific Drupal context with custom step definitions. - YoursiteMinkContext - Site-specific Mink context with custom step definitions.","title":"Behat tests"},{"location":"assets/README.content-repository/#automated-builds-continuous-integration","text":"In software engineering, continuous integration (CI) is the practice of merging all developer working copies to a shared mainline several times a day. Before feature changes can be merged into a shared mainline, a complete build must run and pass all tests on CI server. This project uses Circle CI as CI server: it imports production backups into fully built codebase and runs code linting and tests. When tests pass, a deployment process is triggered for nominated branches (usually, master and develop ). Add [skip ci] to the commit subject to skip CI build. Useful for documentation changes.","title":"Automated builds (Continuous Integration)"},{"location":"assets/README.content-repository/#debugging","text":"","title":"Debugging"},{"location":"assets/README.frontend-website/","text":"name \u00b6 Frontend Website Nuxt client for name . Prerequisites \u00b6 Make sure that you have latest versions of all required software installed: NodeJS NPM Make sure that all local web development services are shut down ( apache/nginx , mysql , MAMP etc). Prerequisites - using Docker \u00b6 Make sure that you have latest versions of all required software installed: Docker Pygmy Ahoy Make sure that all local web development services are shut down ( apache/nginx , mysql , MAMP etc). Setting up SITE_ID \u00b6 In order to connect to the Content Repository, a SITE_ID must be issued. Contact your Content Repository administrators and ask them for a SITE_ID . Add SITE_ID to .env file. Local environment setup \u00b6 npm install npm run dev Local URL -- http://localhost:3000 Without content in your site, you may see 404 in homepage, but you should able to visit path /demo-landing-page to start with a demo content page. Local environment setup (with Docker) \u00b6 Run npm run bay:start Local URL -- http:// machine_name .docker.amazee.io/ Available workflow commands npm run bay:start - start local development environment without build. npm run bay:rebuild-full - rebuild local development environment and start. npm run bay:stop - stop all Bay containers. npm run bay:destroy - stop and remove all Bay containers. npm run bay:logs - get logs from all running Bay containers. npm run bay:cli - run a command in node container. Example: npm run bay:cli -- ls -al . npm run bay:pull - pull latest Bay containers. Logs Using the npm run helper script you can get logs from any running container. npm run bay:logs To continue streaming logs, use --follow . npm run bay:logs -- --follow You can also filter the output to show only logs from a particular service. For example npm run bay:logs -- app will show the log output from the node container. The full list of services can be found in the docker-compose.yml SSHing into container SSH into app service docker-compose exec app sh SSH into test service docker-compose exec test sh Lint code \u00b6 npm run lint Test \u00b6 We uses Jest for unit test and end-to-end test. npm test","title":"_name_"},{"location":"assets/README.frontend-website/#name","text":"Frontend Website Nuxt client for name .","title":"name"},{"location":"assets/README.frontend-website/#prerequisites","text":"Make sure that you have latest versions of all required software installed: NodeJS NPM Make sure that all local web development services are shut down ( apache/nginx , mysql , MAMP etc).","title":"Prerequisites"},{"location":"assets/README.frontend-website/#prerequisites-using-docker","text":"Make sure that you have latest versions of all required software installed: Docker Pygmy Ahoy Make sure that all local web development services are shut down ( apache/nginx , mysql , MAMP etc).","title":"Prerequisites - using Docker"},{"location":"assets/README.frontend-website/#setting-up-site_id","text":"In order to connect to the Content Repository, a SITE_ID must be issued. Contact your Content Repository administrators and ask them for a SITE_ID . Add SITE_ID to .env file.","title":"Setting up SITE_ID"},{"location":"assets/README.frontend-website/#local-environment-setup","text":"npm install npm run dev Local URL -- http://localhost:3000 Without content in your site, you may see 404 in homepage, but you should able to visit path /demo-landing-page to start with a demo content page.","title":"Local environment setup"},{"location":"assets/README.frontend-website/#local-environment-setup-with-docker","text":"Run npm run bay:start Local URL -- http:// machine_name .docker.amazee.io/","title":"Local environment setup (with Docker)"},{"location":"assets/README.frontend-website/#lint-code","text":"npm run lint","title":"Lint code"},{"location":"assets/README.frontend-website/#test","text":"We uses Jest for unit test and end-to-end test. npm test","title":"Test"},{"location":"bay/","text":"Bay \u00b6 Bay is a fully managed platform and hosting environment that provides an open Platform as a Service model managed by SDP. It: - is an open-source hosting platform based on Lagoon. - allows agencies to build, test and deliver websites via the cloud. Bay is a Kubernetes-based (OpenShift) Docker container hosting platform with auto-scaling, auto-recovery and high-availability at core. Bay is based on open-source project Lagoon . Quote Lagoon solves what developers are dreaming about: A system that allows developers to locally develop their code and their services with Docker and run the exact same system in production. The same Docker images, the same service configurations and the same code. The platform has several layers (from the bottom to the top): The AWS layer is how the platform is physically hosted. It is spread accross multiple data centers to allow auto-scaling, fault-tolerance and disaster recovery. The Kubernetes layer allows to automate deployment, scale, and manage containerized application. The OpenShift layer is a Kubernetes distribution with enterprise-grade features and support. The Bay layer is an orchestration tool used to bundle containers into projects and manage deployments. The Application layer is where Drupal, NodeJS and other types of application reside. Architecture overview \u00b6 An over-simplified Bay platform architecture overview: Requests coming from the Citizen to the load balancer and then get directed to the dedicated containers in specific data centre (not necessarily the same for all containers). These containers are provisioned, auto-scaled and auto-healed using Orchestration Tool Box. Developers have identical development stack installed locally. Automated builds in Continuous Integration servers use identical container images. In this way, all environments are running identical versions of languages, frameworks and libraries required for a particular website. Namespaces \u00b6 Docker vendor namespace: dpc_sdp Docker images namespace: * (service name) Repositories \u00b6 Bay source code: https://github.com/dpc-sdp/bay Quay: https://quay.io/organization/dpc_sdp","title":"Overview"},{"location":"bay/#bay","text":"Bay is a fully managed platform and hosting environment that provides an open Platform as a Service model managed by SDP. It: - is an open-source hosting platform based on Lagoon. - allows agencies to build, test and deliver websites via the cloud. Bay is a Kubernetes-based (OpenShift) Docker container hosting platform with auto-scaling, auto-recovery and high-availability at core. Bay is based on open-source project Lagoon . Quote Lagoon solves what developers are dreaming about: A system that allows developers to locally develop their code and their services with Docker and run the exact same system in production. The same Docker images, the same service configurations and the same code. The platform has several layers (from the bottom to the top): The AWS layer is how the platform is physically hosted. It is spread accross multiple data centers to allow auto-scaling, fault-tolerance and disaster recovery. The Kubernetes layer allows to automate deployment, scale, and manage containerized application. The OpenShift layer is a Kubernetes distribution with enterprise-grade features and support. The Bay layer is an orchestration tool used to bundle containers into projects and manage deployments. The Application layer is where Drupal, NodeJS and other types of application reside.","title":"Bay"},{"location":"bay/#architecture-overview","text":"An over-simplified Bay platform architecture overview: Requests coming from the Citizen to the load balancer and then get directed to the dedicated containers in specific data centre (not necessarily the same for all containers). These containers are provisioned, auto-scaled and auto-healed using Orchestration Tool Box. Developers have identical development stack installed locally. Automated builds in Continuous Integration servers use identical container images. In this way, all environments are running identical versions of languages, frameworks and libraries required for a particular website.","title":"Architecture overview"},{"location":"bay/#namespaces","text":"Docker vendor namespace: dpc_sdp Docker images namespace: * (service name)","title":"Namespaces"},{"location":"bay/#repositories","text":"Bay source code: https://github.com/dpc-sdp/bay Quay: https://quay.io/organization/dpc_sdp","title":"Repositories"},{"location":"bay/onboarding/","text":"Onboarding to Bay \u00b6 This content has not been developed yet This chapter describes the process of onboarding to Bay: who to contact, what to provide, time frame.","title":"Onboarding *"},{"location":"bay/onboarding/#onboarding-to-bay","text":"This content has not been developed yet This chapter describes the process of onboarding to Bay: who to contact, what to provide, time frame.","title":"Onboarding to Bay"},{"location":"bay/preview-environments/","text":"Preview environments \u00b6 Preview ( dynamic / temporary / disposable / ephemeral ) environments are environments identical to production and created to test features or demo functionality. Bay provides up to 10 preview environments for each Content Repository or Frontend Website. New environments created automatically once a pull-request is created in the GitHub repository. If messenger notifications enabled, a new message about deployment will be posted there. Once pull request is closed, the environment automatically destroyed and all environment data is removed. If messenger notifications enabled, a new message about environment removal will be posted there.","title":"Preview environments"},{"location":"bay/preview-environments/#preview-environments","text":"Preview ( dynamic / temporary / disposable / ephemeral ) environments are environments identical to production and created to test features or demo functionality. Bay provides up to 10 preview environments for each Content Repository or Frontend Website. New environments created automatically once a pull-request is created in the GitHub repository. If messenger notifications enabled, a new message about deployment will be posted there. Once pull request is closed, the environment automatically destroyed and all environment data is removed. If messenger notifications enabled, a new message about environment removal will be posted there.","title":"Preview environments"},{"location":"bay/search/","text":"Search \u00b6 This content has not been developed yet This chapter describes how to connect to Search engine in Bay from Content Repository and Frontend Websites.","title":"Search *"},{"location":"bay/search/#search","text":"This content has not been developed yet This chapter describes how to connect to Search engine in Bay from Content Repository and Frontend Websites.","title":"Search"},{"location":"development/","text":"Development Overview \u00b6 SDP provides development tools, standards and recommended workflow for efficient, effective and consisted development practice. Who are you? \u00b6 Depending on what you are working on, there are several documentation sections that may be useful for you. If you are working on a standalone installation of Content Repository , please see Content Repository section. Also Tide section may become useful to learn more about architecture. If you are working on a standalone installation of Fronted Website , please see Frontend Website section. Also Ripple section may become useful to learn more about architecture. If you are looking for best practices and other project organisation information, please see Development workflow , Code review and Release management sections. If you would like to contribute to this documentation, please submit a pull request for this project.","title":"Overview"},{"location":"development/#development-overview","text":"SDP provides development tools, standards and recommended workflow for efficient, effective and consisted development practice.","title":"Development Overview"},{"location":"development/#who-are-you","text":"Depending on what you are working on, there are several documentation sections that may be useful for you. If you are working on a standalone installation of Content Repository , please see Content Repository section. Also Tide section may become useful to learn more about architecture. If you are working on a standalone installation of Fronted Website , please see Frontend Website section. Also Ripple section may become useful to learn more about architecture. If you are looking for best practices and other project organisation information, please see Development workflow , Code review and Release management sections. If you would like to contribute to this documentation, please submit a pull request for this project.","title":"Who are you?"},{"location":"development/accessibility/","text":"Accessibility requirements \u00b6 WCAG AA 2.0 Requirement \u00b6 All Victoria Government website must be at least WCAG AA 2.0 compliant. Victorian Government Accessibility Toolkit \u00b6 The accessibility toolkit is available to assist all agencies in ensuring their websites are compliant with the Victoria Government standards. Extra Requirements \u00b6 The aim for the SDP project is to go beyond the requirements and focus on ensuring the sites are truly user friendly for users with accessibility needs. The DTA has published a blog article about this topic, https://www.dta.gov.au/blog/Accessibility-going-beyond-the-guidelines/ . There is also a good presentation here on some of the things to think about when building for accessibility. Some steps that should be required either per ticket or at least for the UAT process are: Colour Contrast. Check colour contrast in a tool such as http://www.color-blindness.com/coblis-color-blindness-simulator/ Accessibility checker. Ensure the automated tests in Monsido have run over the new functionality. Keyboard only. Push the mouse away and try to operate the screen. You should be able to navigate with the keyboard only. Screen-reader only. Turn on a screen-reader such as NVDA or VoiceOver and turn off the screen (or look away). All essential content should be read out and you should be able to navigate the screen. Design Considerations \u00b6 High colour contrast is good for colour blind users; it also helps users view a website on a mobile when in bright sunlight. Text over images should be avoided where possible. Some things to consider: Can the text colour change? Can the Image change, thereby changing the colour contrast? Can a solid background colour be applied to the text to ensure visibility Content Considerations \u00b6 There are minimum requirements for WCAG compliance, however, if the users need is considered, the actual requirement should be more defined. alt and title text fields help people to understand visual elements without being able to see them. Read through this explanation from WebAIM , https://webaim.org/techniques/alttext/#context . alt and title text are required, however users should be able to override this when required. For example, purely decorative images that offer no useful content to the user should not have alt and title text and should be ignored by screen readers. https://www.w3.org/WAI/tutorials/images/decorative/ . Try to avoid just copying the title text into the alt text field. Videos should always have captions; look at the YouTube auto CC when using YouTube. When creating links, try to avoid content like 'Click here' or 'here'. A screen reader will read the link as something like \"Leaving list | visited link | here\". Better link text describes what the user will get to, visit the Governors website . Technical Implementation \u00b6 For images, alt and title text fields should be made mandatory. There must be the ability to override this when adding images that are decorative. alt and title attributes must always be present, even when they are blank. Ensure headings are hierarchical; try to always ensure that headings on a page will be read in order. Use aria-live on any dynamic sections. See https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/ARIA_Live_Regions .","title":"Accessibility"},{"location":"development/accessibility/#accessibility-requirements","text":"","title":"Accessibility requirements"},{"location":"development/accessibility/#wcag-aa-20-requirement","text":"All Victoria Government website must be at least WCAG AA 2.0 compliant.","title":"WCAG AA 2.0 Requirement"},{"location":"development/accessibility/#victorian-government-accessibility-toolkit","text":"The accessibility toolkit is available to assist all agencies in ensuring their websites are compliant with the Victoria Government standards.","title":"Victorian Government Accessibility Toolkit"},{"location":"development/accessibility/#extra-requirements","text":"The aim for the SDP project is to go beyond the requirements and focus on ensuring the sites are truly user friendly for users with accessibility needs. The DTA has published a blog article about this topic, https://www.dta.gov.au/blog/Accessibility-going-beyond-the-guidelines/ . There is also a good presentation here on some of the things to think about when building for accessibility. Some steps that should be required either per ticket or at least for the UAT process are: Colour Contrast. Check colour contrast in a tool such as http://www.color-blindness.com/coblis-color-blindness-simulator/ Accessibility checker. Ensure the automated tests in Monsido have run over the new functionality. Keyboard only. Push the mouse away and try to operate the screen. You should be able to navigate with the keyboard only. Screen-reader only. Turn on a screen-reader such as NVDA or VoiceOver and turn off the screen (or look away). All essential content should be read out and you should be able to navigate the screen.","title":"Extra Requirements"},{"location":"development/accessibility/#design-considerations","text":"High colour contrast is good for colour blind users; it also helps users view a website on a mobile when in bright sunlight. Text over images should be avoided where possible. Some things to consider: Can the text colour change? Can the Image change, thereby changing the colour contrast? Can a solid background colour be applied to the text to ensure visibility","title":"Design Considerations"},{"location":"development/accessibility/#content-considerations","text":"There are minimum requirements for WCAG compliance, however, if the users need is considered, the actual requirement should be more defined. alt and title text fields help people to understand visual elements without being able to see them. Read through this explanation from WebAIM , https://webaim.org/techniques/alttext/#context . alt and title text are required, however users should be able to override this when required. For example, purely decorative images that offer no useful content to the user should not have alt and title text and should be ignored by screen readers. https://www.w3.org/WAI/tutorials/images/decorative/ . Try to avoid just copying the title text into the alt text field. Videos should always have captions; look at the YouTube auto CC when using YouTube. When creating links, try to avoid content like 'Click here' or 'here'. A screen reader will read the link as something like \"Leaving list | visited link | here\". Better link text describes what the user will get to, visit the Governors website .","title":"Content Considerations"},{"location":"development/accessibility/#technical-implementation","text":"For images, alt and title text fields should be made mandatory. There must be the ability to override this when adding images that are decorative. alt and title attributes must always be present, even when they are blank. Ensure headings are hierarchical; try to always ensure that headings on a page will be read in order. Use aria-live on any dynamic sections. See https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/ARIA_Live_Regions .","title":"Technical Implementation"},{"location":"development/code-review/","text":"Code review \u00b6 Code review is a vital for effective and efficient collaboration of successful teams. Purpose \u00b6 Promote shared understanding of the codebase. Getting other people to look at code changes improves visibility and understanding of the way in which code works. It therefore helps protect against the loss of knowledge and productivity that can occur as developers come and go. Provide a different perspective on solutions. Coming with a fresh perspective and different experiences, the reviewer of code may think of possibilities that did not occur to the original developer. Improved code quality. The reviewer may notice issues with scalability, typos or other issues that might have slipped by the developer, but which may not cause errors or warnings visible to the end user. Questions to ask when reviewing code \u00b6 Is there enough commenting (or too much)? Is the code readable? Are the names of variables, functions, methods and classes clear and unambiguous? Are functions and class methods broken down to each fulfill one discrete requirement? Have unit tests been written? Has documentation been written/updated? Do comments in the code point to it and vice versa? Is an upgrade script needed? If so, does it run to completion and without an error? Are assumptions being made about the way the site will be used that might not be valid? For example, hard-coding http:// or https:// in URLs instead of check what protocol was used for the request and/or making the URL ambivalent (start with // ). Is code secure or does it avoid creating new vulnerabilities implementations for an existing functionality? Preparing code for code review \u00b6 Provide clear description about what , why and how the code has been changed. Provide screenshots, if applicable. Read your own code changes and add comments to parts that may raise questions. Provide a link to the issue tracker. Assign relevant developers to review the pull request. Assign yourself as an owner of the pull request. Add Needs review label to the pull request. Read more about Mindful Communication in Code Reviews . Labels \u00b6 Using labels on GitHub can help organise pull requests and issues. Here are the labels that describe the most of the states of pull request. An example of the pull request progression through labels: DO NOT REVIEW -> Needs review -> Ready for test -> Ready to be merged Github Labels script can automatically create above labels in your projects.","title":"Code review"},{"location":"development/code-review/#code-review","text":"Code review is a vital for effective and efficient collaboration of successful teams.","title":"Code review"},{"location":"development/code-review/#purpose","text":"Promote shared understanding of the codebase. Getting other people to look at code changes improves visibility and understanding of the way in which code works. It therefore helps protect against the loss of knowledge and productivity that can occur as developers come and go. Provide a different perspective on solutions. Coming with a fresh perspective and different experiences, the reviewer of code may think of possibilities that did not occur to the original developer. Improved code quality. The reviewer may notice issues with scalability, typos or other issues that might have slipped by the developer, but which may not cause errors or warnings visible to the end user.","title":"Purpose"},{"location":"development/code-review/#questions-to-ask-when-reviewing-code","text":"Is there enough commenting (or too much)? Is the code readable? Are the names of variables, functions, methods and classes clear and unambiguous? Are functions and class methods broken down to each fulfill one discrete requirement? Have unit tests been written? Has documentation been written/updated? Do comments in the code point to it and vice versa? Is an upgrade script needed? If so, does it run to completion and without an error? Are assumptions being made about the way the site will be used that might not be valid? For example, hard-coding http:// or https:// in URLs instead of check what protocol was used for the request and/or making the URL ambivalent (start with // ). Is code secure or does it avoid creating new vulnerabilities implementations for an existing functionality?","title":"Questions to ask when reviewing code"},{"location":"development/code-review/#preparing-code-for-code-review","text":"Provide clear description about what , why and how the code has been changed. Provide screenshots, if applicable. Read your own code changes and add comments to parts that may raise questions. Provide a link to the issue tracker. Assign relevant developers to review the pull request. Assign yourself as an owner of the pull request. Add Needs review label to the pull request. Read more about Mindful Communication in Code Reviews .","title":"Preparing code for code review"},{"location":"development/code-review/#labels","text":"Using labels on GitHub can help organise pull requests and issues. Here are the labels that describe the most of the states of pull request. An example of the pull request progression through labels: DO NOT REVIEW -> Needs review -> Ready for test -> Ready to be merged Github Labels script can automatically create above labels in your projects.","title":"Labels"},{"location":"development/documentation/","text":"Documentation for SDP \u00b6 https://dpc-sdp.github.io/sdp-docs/ Requirements \u00b6 Docker Ahoy Quickstart \u00b6 To build locally: ahoy build To serve locally: ahoy deploy Available commands \u00b6 build Build site deploy Deploy site serve Serve site in browser version MkDocs version Automated deployment \u00b6 CircleCI is configured to perform automated deployments for the main branch. The built site is automatically pushed to gh-pages branch. Also note that built site is available in CircleCI build artifacts tab. Important! Do not commit to gh-pages branch manually. Also, try to avoid using ahoy deploy command manually (it is used by CI). Maintenance \u00b6 SDP development team is a main maintainer of this documentation. We welcome contributions to this documentation! Please open an issue or submit a pull request.","title":"Maintaining this documentation"},{"location":"development/documentation/#documentation-for-sdp","text":"https://dpc-sdp.github.io/sdp-docs/","title":"Documentation for SDP"},{"location":"development/documentation/#requirements","text":"Docker Ahoy","title":"Requirements"},{"location":"development/documentation/#quickstart","text":"To build locally: ahoy build To serve locally: ahoy deploy","title":"Quickstart"},{"location":"development/documentation/#available-commands","text":"build Build site deploy Deploy site serve Serve site in browser version MkDocs version","title":"Available commands"},{"location":"development/documentation/#automated-deployment","text":"CircleCI is configured to perform automated deployments for the main branch. The built site is automatically pushed to gh-pages branch. Also note that built site is available in CircleCI build artifacts tab. Important! Do not commit to gh-pages branch manually. Also, try to avoid using ahoy deploy command manually (it is used by CI).","title":"Automated deployment"},{"location":"development/documentation/#maintenance","text":"SDP development team is a main maintainer of this documentation. We welcome contributions to this documentation! Please open an issue or submit a pull request.","title":"Maintenance"},{"location":"development/release/","text":"Managing releases \u00b6 The purpose of this document is to describe the git management process across the Content Repository and Frontend Websites. Issues \u00b6 Changes to the Drupal API can have an effect on the Front end website due to field and entity changes. This can lead to issues on Frontend Websites if they are not updated at the same time as the Content Repository as they rely on a common API. This can cause a delay in deploying Content Repository while changes are merged to the Frontend Websites and go through QA and UAT. Versions \u00b6 Both Content Repository and Frontend Websites release versions should follow semantic versioning . Quote Given a version number MAJOR.MINOR.PATCH , increment the: MAJOR version when you make incompatible API changes, MINOR version when you add functionality in a backwards-compatible manner, and PATCH version when you make backwards-compatible bug fixes. Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format. Git workflow \u00b6 Git branch schema for releases Note that on this diagram production branch only receives release commits (commits tagged with release versions). Such setup is used in hosting that is deploying code for branches rather then for tags. If your hosting provider supports deploying tags, the production branch may be replaced with switching a tag on production environment . Feature branches for both Content Repository and Frontend Websites start from the the develop branch. Frontend Websites may connect to the feature branch environments of the Content Repository to test front-end and back-end changes together. Once ready, the feature branches are merged back as pull requests against develop branch. Release branch for Content Repository starts from the develop branch. It stays unmerged until Frontend Websites validate (through QA process) that newly introduced changes to Content Repository do not break Frontend Websites' functionality. Once Frontend Websites confirm that release for Content Repository is stable, the release branch get's merged into master . At this point, both Content Repository and all Frontend Websites need to coordinate release time frame. Once ready to release, new release tags created in all projects and are deployed to production environments. Releasing \u00b6 Note In the steps below, it is assumed that both Content Repository and Frontend Websites have changes to result in release. If Frontend Websites do not have any new feature changes, they need to release only in case if Content Repository API changes. Note The steps below do not include any release communication steps. Always prepare release plan with communication details, templates and rollback actions ahead of release, or, better, create a standardise release run sheet. Create a release branch from develop in Content Repository Create a release branch for each Frontend Website repository and push the changes as a new pull request against develop for each repository. Have the QA team test the latest changes and perform a spot regression check in both Content Repository and all Frontend Websites. Merge the Content Repository release branch to master Once all Frontend Websites pass QA (or only minor bugs are found that will not effect release), merge the release branch on each Frontend Website to develop and follow the standard release process through to master . Request UAT on all Frontend Websites. Once UAT is complete or 3 business days are passed, prepare to tag and release to production. Tag and deploy Content Repository release to production. Tag and deploy each Frontend Website release to production.","title":"Release management"},{"location":"development/release/#managing-releases","text":"The purpose of this document is to describe the git management process across the Content Repository and Frontend Websites.","title":"Managing releases"},{"location":"development/release/#issues","text":"Changes to the Drupal API can have an effect on the Front end website due to field and entity changes. This can lead to issues on Frontend Websites if they are not updated at the same time as the Content Repository as they rely on a common API. This can cause a delay in deploying Content Repository while changes are merged to the Frontend Websites and go through QA and UAT.","title":"Issues"},{"location":"development/release/#versions","text":"Both Content Repository and Frontend Websites release versions should follow semantic versioning . Quote Given a version number MAJOR.MINOR.PATCH , increment the: MAJOR version when you make incompatible API changes, MINOR version when you add functionality in a backwards-compatible manner, and PATCH version when you make backwards-compatible bug fixes. Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.","title":"Versions"},{"location":"development/release/#git-workflow","text":"Git branch schema for releases Note that on this diagram production branch only receives release commits (commits tagged with release versions). Such setup is used in hosting that is deploying code for branches rather then for tags. If your hosting provider supports deploying tags, the production branch may be replaced with switching a tag on production environment . Feature branches for both Content Repository and Frontend Websites start from the the develop branch. Frontend Websites may connect to the feature branch environments of the Content Repository to test front-end and back-end changes together. Once ready, the feature branches are merged back as pull requests against develop branch. Release branch for Content Repository starts from the develop branch. It stays unmerged until Frontend Websites validate (through QA process) that newly introduced changes to Content Repository do not break Frontend Websites' functionality. Once Frontend Websites confirm that release for Content Repository is stable, the release branch get's merged into master . At this point, both Content Repository and all Frontend Websites need to coordinate release time frame. Once ready to release, new release tags created in all projects and are deployed to production environments.","title":"Git workflow"},{"location":"development/release/#releasing","text":"Note In the steps below, it is assumed that both Content Repository and Frontend Websites have changes to result in release. If Frontend Websites do not have any new feature changes, they need to release only in case if Content Repository API changes. Note The steps below do not include any release communication steps. Always prepare release plan with communication details, templates and rollback actions ahead of release, or, better, create a standardise release run sheet. Create a release branch from develop in Content Repository Create a release branch for each Frontend Website repository and push the changes as a new pull request against develop for each repository. Have the QA team test the latest changes and perform a spot regression check in both Content Repository and all Frontend Websites. Merge the Content Repository release branch to master Once all Frontend Websites pass QA (or only minor bugs are found that will not effect release), merge the release branch on each Frontend Website to develop and follow the standard release process through to master . Request UAT on all Frontend Websites. Once UAT is complete or 3 business days are passed, prepare to tag and release to production. Tag and deploy Content Repository release to production. Tag and deploy each Frontend Website release to production.","title":"Releasing"},{"location":"development/troubleshooting/","text":"Troubleshooting \u00b6 Docker Host container is full \u00b6 If you're seeing errors like Error processing tar file(exit status 1): write /app/docroot/themes/custom/governor/build/images/homepage-background.png: no space left on device` run docker image prune -a to free-up space in your Docker. A branch is pushed into the repo, but no deployments are happening in Bay \u00b6 CI passes, but nothing happening in the messenger build channel. The branch name might be too long. Please make sure that the name of your branch is less then or equal to 40 characters.","title":"Troubleshooting"},{"location":"development/troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"development/troubleshooting/#docker-host-container-is-full","text":"If you're seeing errors like Error processing tar file(exit status 1): write /app/docroot/themes/custom/governor/build/images/homepage-background.png: no space left on device` run docker image prune -a to free-up space in your Docker.","title":"Docker Host container is full"},{"location":"development/troubleshooting/#a-branch-is-pushed-into-the-repo-but-no-deployments-are-happening-in-bay","text":"CI passes, but nothing happening in the messenger build channel. The branch name might be too long. Please make sure that the name of your branch is less then or equal to 40 characters.","title":"A branch is pushed into the repo, but no deployments are happening in Bay"},{"location":"development/workflow/","text":"Development workflow \u00b6 This workflow describes working on features as a developer on Content Repository and Frontend Website projects. Pick a ticket in your issue tracker: Make sure that all requirements, solution direction and acceptance criteria are clear. If not, address issues with Technical Lead or Product Owner. Assign the ticket to yourself. Create a new feature branch named feature/CODE123-short-hyphenated-description . Work on the ticket functionality: Install new contributed modules or packages as required. For Content Repository - configure and export configuration changes; write hook_update_N() implementations (but be mindful that Drupal 8 does not require many of these). For Frontend Website - identify and use existing or create new Ripple components; update styles according to style guide as required; make sure that style guide has been updated and new components were added (it is important to always have style guide up to date). Add tests: For Content Repository - identify required Behat tests (only test your custom configuration, and critical user journeys; do not test Drupal's standard behaviour); identify and implement PHPUnit tests. For Frontend Website - identify required tests and mocks, and implement them; add unit tests for any custom Nuxt functionality. Commit all changed and added files. Pay special attention to configuration files and their counterparts ( composer.json , composer.lock , package.json , package-lock.json ). Create a pull request in your issue tracker - see Preparing code for code review If your are using a messenger to communicate with your development team - copy and paste the link to the created pull request into the messenger and ask for a review. Move the ticket in your issue tracker to In code review state (create this state if it does not exist to help identify tickets pending review). Once pull request is approved - merge it to the mainline branch and make sure that automated tests passed after the merge.","title":"Development workflow"},{"location":"development/workflow/#development-workflow","text":"This workflow describes working on features as a developer on Content Repository and Frontend Website projects. Pick a ticket in your issue tracker: Make sure that all requirements, solution direction and acceptance criteria are clear. If not, address issues with Technical Lead or Product Owner. Assign the ticket to yourself. Create a new feature branch named feature/CODE123-short-hyphenated-description . Work on the ticket functionality: Install new contributed modules or packages as required. For Content Repository - configure and export configuration changes; write hook_update_N() implementations (but be mindful that Drupal 8 does not require many of these). For Frontend Website - identify and use existing or create new Ripple components; update styles according to style guide as required; make sure that style guide has been updated and new components were added (it is important to always have style guide up to date). Add tests: For Content Repository - identify required Behat tests (only test your custom configuration, and critical user journeys; do not test Drupal's standard behaviour); identify and implement PHPUnit tests. For Frontend Website - identify required tests and mocks, and implement them; add unit tests for any custom Nuxt functionality. Commit all changed and added files. Pay special attention to configuration files and their counterparts ( composer.json , composer.lock , package.json , package-lock.json ). Create a pull request in your issue tracker - see Preparing code for code review If your are using a messenger to communicate with your development team - copy and paste the link to the created pull request into the messenger and ask for a review. Move the ticket in your issue tracker to In code review state (create this state if it does not exist to help identify tickets pending review). Once pull request is approved - merge it to the mainline branch and make sure that automated tests passed after the merge.","title":"Development workflow"},{"location":"development/content-repository/automated-builds/","text":"Automated builds \u00b6 SDP uses CircleCI for all automated build (CI) runs. Build steps \u00b6 Download production database Build a site from supplied composer.json file (dependencies are locked in at specific versions) and production database. This builds the site which is identical to the production site before running tests. Check coding standards in custom site code for modules and themes: PHP, JS, SCSS/CSS. Run unit tests (PHPUnit), if any. Run behavioural tests (Behat), if any. Skipping CI builds \u00b6 Add [skip ci] to the commit subject to skip CI build. Useful for documentation changes. SSH into CI build \u00b6 Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. 1. Navigate to the job page 2. Click on the dropdown in the right top corner and select Rebuild with SSH . Test artifacts \u00b6 Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI.","title":"Automated builds"},{"location":"development/content-repository/automated-builds/#automated-builds","text":"SDP uses CircleCI for all automated build (CI) runs.","title":"Automated builds"},{"location":"development/content-repository/automated-builds/#build-steps","text":"Download production database Build a site from supplied composer.json file (dependencies are locked in at specific versions) and production database. This builds the site which is identical to the production site before running tests. Check coding standards in custom site code for modules and themes: PHP, JS, SCSS/CSS. Run unit tests (PHPUnit), if any. Run behavioural tests (Behat), if any.","title":"Build steps"},{"location":"development/content-repository/automated-builds/#skipping-ci-builds","text":"Add [skip ci] to the commit subject to skip CI build. Useful for documentation changes.","title":"Skipping CI builds"},{"location":"development/content-repository/automated-builds/#ssh-into-ci-build","text":"Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. 1. Navigate to the job page 2. Click on the dropdown in the right top corner and select Rebuild with SSH .","title":"SSH into CI build"},{"location":"development/content-repository/automated-builds/#test-artifacts","text":"Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI.","title":"Test artifacts"},{"location":"development/content-repository/coding-standards/","text":"Coding Standards \u00b6 We use Drupal Coding Standards for all our contributed and custom modules. PHPCodeSniffer runs our code linting using rules from Drupal Coder module and additional customizations. See our the PHPCodeSniffer configuration file . Run all coding standards checks: ahoy lint Note that these checks run during automated builds . Composer \u00b6 Alphabetise package order where possible This helps developers to visually scan code faster. Include information to make reviews easier Each patch attribute name should contain the title of the Drupal.org (d.o) issue, the link to the issue comment that contains the patch and the patch attribute value should be the patch file on drupal.org: \"drupal/project\" : { \"Issue title - https://www.drupal.org/node/1234567#12345678\" : \"https://www.drupal.org/files/issues/issue_title-1234567-2.patch\" } , Following this approach makes it simpler to follow up the status of patches during updates. Example of a properly formatted patches attribute: \"patches\" : { \"drupal/better_exposed_filters\" : { \"Add core/drupal as dependency to better_exposed_filters asset libraries - https://www.drupal.org/node/2902742\" : \"https://www.drupal.org/files/issues/add_core_drupal_as-2902742-2.patch\" }, \"drupal/core\" : { \"No validation on text length for menu description when editing node - https://www.drupal.org/node/2852665#comment-12157856\" : \"https://www.drupal.org/files/issues/fatal_error_remove_menu_add_with_tests-2852665-12.patch\" }, } , Setting project coding standards inspections in PHPStorm \u00b6 PHPStorm > Preferences > Code Style Select the appropriate language (in the example image below it is PHP ) Select the Set from... link Select Predefined Style > Drupal It is then possible to use the keyboard shortcut Alt + command + l to format a file or selection.","title":"Coding standards"},{"location":"development/content-repository/coding-standards/#coding-standards","text":"We use Drupal Coding Standards for all our contributed and custom modules. PHPCodeSniffer runs our code linting using rules from Drupal Coder module and additional customizations. See our the PHPCodeSniffer configuration file . Run all coding standards checks: ahoy lint Note that these checks run during automated builds .","title":"Coding Standards"},{"location":"development/content-repository/coding-standards/#composer","text":"Alphabetise package order where possible This helps developers to visually scan code faster. Include information to make reviews easier Each patch attribute name should contain the title of the Drupal.org (d.o) issue, the link to the issue comment that contains the patch and the patch attribute value should be the patch file on drupal.org: \"drupal/project\" : { \"Issue title - https://www.drupal.org/node/1234567#12345678\" : \"https://www.drupal.org/files/issues/issue_title-1234567-2.patch\" } , Following this approach makes it simpler to follow up the status of patches during updates. Example of a properly formatted patches attribute: \"patches\" : { \"drupal/better_exposed_filters\" : { \"Add core/drupal as dependency to better_exposed_filters asset libraries - https://www.drupal.org/node/2902742\" : \"https://www.drupal.org/files/issues/add_core_drupal_as-2902742-2.patch\" }, \"drupal/core\" : { \"No validation on text length for menu description when editing node - https://www.drupal.org/node/2852665#comment-12157856\" : \"https://www.drupal.org/files/issues/fatal_error_remove_menu_add_with_tests-2852665-12.patch\" }, } ,","title":"Composer"},{"location":"development/content-repository/coding-standards/#setting-project-coding-standards-inspections-in-phpstorm","text":"PHPStorm > Preferences > Code Style Select the appropriate language (in the example image below it is PHP ) Select the Set from... link Select Predefined Style > Drupal It is then possible to use the keyboard shortcut Alt + command + l to format a file or selection.","title":"Setting project coding standards inspections in PHPStorm"},{"location":"development/content-repository/local-development-environment/","text":"Local development environment \u00b6 Drupal tools setup \u00b6 We are using Dev Tools for Drupal module and site development. Prerequisites Make sure that you have latest versions of all required software installed: Docker Pygmy Ahoy Make sure that all local web development services are shut down ( apache/nginx , mysql , MAMP etc). Setup curl https://raw.githubusercontent.com/dpc-sdp/dev-tools/master/install | bash pygmy up ahoy build Find more information about Dev Tools at https://github.com/dpc-sdp/dev-tools .","title":"Local development environment"},{"location":"development/content-repository/local-development-environment/#local-development-environment","text":"","title":"Local development environment"},{"location":"development/content-repository/local-development-environment/#drupal-tools-setup","text":"We are using Dev Tools for Drupal module and site development.","title":"Drupal tools setup"},{"location":"development/content-repository/module-development/","text":"Module development \u00b6 Developing contributed module \u00b6 This content has not been developed yet How to include a module into Content Repository. Releasing contributed module \u00b6 This content has not been developed yet How to extract a module from the codebase and release it.","title":"Module Development *"},{"location":"development/content-repository/module-development/#module-development","text":"","title":"Module development"},{"location":"development/content-repository/module-development/#developing-contributed-module","text":"This content has not been developed yet How to include a module into Content Repository.","title":"Developing contributed module"},{"location":"development/content-repository/module-development/#releasing-contributed-module","text":"This content has not been developed yet How to extract a module from the codebase and release it.","title":"Releasing contributed module"},{"location":"development/content-repository/readme-file/","text":"README.md file \u00b6 Use this readme file within your project to hold all required information about your project. Note Please note that you would need to replace several tokens within these files: _name_ - the name of the project _machine_name_ - the machine name of the project _org_machine_name_ - the machine name of the organisation Content Repository \u00b6 README.content-repository.md # _name_ Drupal 8 implementation of Content Repository for _name_ [![CircleCI](https://circleci.com/gh/_org_machine_name_/_machine_name_.svg?style=shield)](https://circleci.com/gh/_org_machine_name_/_machine_name_) ![Release](https://img.shields.io/github/release/_org_machine_name_/_machine_name_.svg) ## Prerequisites 1. Make sure that you have latest versions of all required software installed: - [Docker](https://www.docker.com/) - [Pygmy](https://docs.amazee.io/local_docker_development/pygmy.html) - [Ahoy](https://github.com/ahoy-cli/ahoy) 2. Make sure that all local web development services are shut down (`apache/nginx`, `mysql`, `MAMP` etc). ## Local environment setup 3. `curl https://raw.githubusercontent.com/dpc-sdp/dev-tools/master/install | bash` 4. `pygmy up` 5. `ahoy build` Local URL -- http://_machine_name_.docker.amazee.io/ ## Available `ahoy` commands Run each command as `ahoy <command>`. ``` build Build or rebuild project. clean Remove all build files. clean-full Remove all development files. cli Start a shell inside CLI container or run a command. composer-merge Merge composer files. deploy Deploy or re-deploy a branch in Bay. doctor Identify problems with current stack. down Stop Docker containers and remove container, images, volumes and networks. drush Run drush commands in the CLI service container. flush-redis Flush Redis cache. info Print information about this project. install-dev Install dependencies. install-site Install site. lint Lint code. login Login to a website. logs Show Docker logs. pull Pull latest docker images. restart Restart all stopped and running Docker containers. start Start existing Docker containers. stop Stop running Docker containers. test-behat Run Behat tests. up Build and start Docker containers. ``` ## SSHing into CLI container `ahoy cli` ## Running a command in CLI container `ahoy cli ls /app` ## Mailhog. [Mailhog](https://github.com/mailhog/MailHog) is included with `pygmy` and is available at http://mailhog.docker.amazee.io/ ## Stage file proxy. [Stage File Proxy](https://www.drupal.org/project/stage_file_proxy) is enabled on all non production environments so files are automatically downloaded directly from prod on demand. ## Adding Drupal modules Modules needs to be added in 2 steps: 1. Require module code installation (through composer). 2. Enable module during site installation. ### Adding contrib modules `composer require drupal/module_name` or for specific versions `composer require drupal/module_name:1.2` ### Adding modules as local packages 1. Add local package information to the root of `composer.json`: ``` \"repositories\": { \"dpc-sdp/tide_page\": { \"type\": \"path\", \"url\": \"dpc-sdp/tide_page\" }, } ``` 2. `composer require tide_page` 3. To make sure that Composer triggers dependency tree rebuild, run `ahoy clean`. 4. Run `composer update --lock`. This will install all dependencies and update root `composer.lock` file with newly added module. ## Adding patches for composer packages 1. Add `title` and `url` to patch on drupal.org to the `patches` array in `extra` section in `composer.json`. ``` \"extra\": { \"patches\": { \"drupal/core\": { \"Contextual links should not be added inside another link - https://www.drupal.org/node/2898875\": \"https://www.drupal.org/files/issues/contextual_links_should-2898875-3.patch\" } } } ``` 2. `composer update --lock` ## Coding standards PHP and JS code linting uses [PHP_CodeSniffer](https://github.com/squizlabs/PHP_CodeSniffer) with Drupal rules from [Coder](https://www.drupal.org/project/coder) module and additional local overrides in `phpcs.xml.dist` and `.eslintrc`. ## Behat tests Behat configuration uses multiple extensions: - [Drupal Behat Extension](https://github.com/jhedstrom/drupalextension) - Drupal integration layer. Allows to work with Drupal API from within step definitions. - [Behat Screenshot Extension](https://github.com/integratedexperts/behat-screenshot) - Behat extension and a step definition to create HTML and image screenshots on demand or test fail. - [Behat Progress Fail Output Extension](https://github.com/integratedexperts/behat-format-progress-fail) - Behat output formatter to show progress as TAP and fail messages inline. Useful to get feedback about failed tests while continuing test run. - `YoursiteDrupalContext` - Site-specific Drupal context with custom step definitions. - `YoursiteMinkContext` - Site-specific Mink context with custom step definitions. ### Run tests locally: - Run Behat tests: `ahoy test-behat` - Run specific test feature: `ahoy test-behat tests/behat/features/homepage.feature` - Run specific test tag: `ahoy test-behat -- --tags=wip` ## Automated builds (Continuous Integration) In software engineering, continuous integration (CI) is the practice of merging all developer working copies to a shared mainline several times a day. Before feature changes can be merged into a shared mainline, a complete build must run and pass all tests on CI server. This project uses [Circle CI](https://circleci.com/) as CI server: it imports production backups into fully built codebase and runs code linting and tests. When tests pass, a deployment process is triggered for nominated branches (usually, `master` and `develop`). Add `[skip ci]` to the commit subject to skip CI build. Useful for documentation changes. ### SSH Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. ### Test artifacts Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI. ## Debugging ### PHP application from browser 1. Trigger xDebug from web browser (using one of the browser extensions) so that PHPStorm recognises the server `yoursite.docker.amazee.io` and configures the path mapping. Alternatively, you can create the server in PHPStorm Settings. * Make sure `serverName` to be `yoursite.docker.amazee.io` ### PHP scripts ``` ahoy cli xdebug.sh path/to/script ``` For example, to run a single Behat test: `xdebug.sh vendor/bin/behat path/to/test.feature` ### Drush commands ``` ahoy cli `./xdebug.sh vendor/bin/drush <DRUSH_COMMAND> ``` ### DB connection details Run `ahoy info` to get the port number. ``` Host: 127.0.0.1 Username: drupal Password: drupal Database: drupal Port: <get from \"ahoy info\"> ```","title":"README.md file"},{"location":"development/content-repository/readme-file/#readmemd-file","text":"Use this readme file within your project to hold all required information about your project. Note Please note that you would need to replace several tokens within these files: _name_ - the name of the project _machine_name_ - the machine name of the project _org_machine_name_ - the machine name of the organisation","title":"README.md file"},{"location":"development/content-repository/readme-file/#content-repository","text":"README.content-repository.md # _name_ Drupal 8 implementation of Content Repository for _name_ [![CircleCI](https://circleci.com/gh/_org_machine_name_/_machine_name_.svg?style=shield)](https://circleci.com/gh/_org_machine_name_/_machine_name_) ![Release](https://img.shields.io/github/release/_org_machine_name_/_machine_name_.svg) ## Prerequisites 1. Make sure that you have latest versions of all required software installed: - [Docker](https://www.docker.com/) - [Pygmy](https://docs.amazee.io/local_docker_development/pygmy.html) - [Ahoy](https://github.com/ahoy-cli/ahoy) 2. Make sure that all local web development services are shut down (`apache/nginx`, `mysql`, `MAMP` etc). ## Local environment setup 3. `curl https://raw.githubusercontent.com/dpc-sdp/dev-tools/master/install | bash` 4. `pygmy up` 5. `ahoy build` Local URL -- http://_machine_name_.docker.amazee.io/ ## Available `ahoy` commands Run each command as `ahoy <command>`. ``` build Build or rebuild project. clean Remove all build files. clean-full Remove all development files. cli Start a shell inside CLI container or run a command. composer-merge Merge composer files. deploy Deploy or re-deploy a branch in Bay. doctor Identify problems with current stack. down Stop Docker containers and remove container, images, volumes and networks. drush Run drush commands in the CLI service container. flush-redis Flush Redis cache. info Print information about this project. install-dev Install dependencies. install-site Install site. lint Lint code. login Login to a website. logs Show Docker logs. pull Pull latest docker images. restart Restart all stopped and running Docker containers. start Start existing Docker containers. stop Stop running Docker containers. test-behat Run Behat tests. up Build and start Docker containers. ``` ## SSHing into CLI container `ahoy cli` ## Running a command in CLI container `ahoy cli ls /app` ## Mailhog. [Mailhog](https://github.com/mailhog/MailHog) is included with `pygmy` and is available at http://mailhog.docker.amazee.io/ ## Stage file proxy. [Stage File Proxy](https://www.drupal.org/project/stage_file_proxy) is enabled on all non production environments so files are automatically downloaded directly from prod on demand. ## Adding Drupal modules Modules needs to be added in 2 steps: 1. Require module code installation (through composer). 2. Enable module during site installation. ### Adding contrib modules `composer require drupal/module_name` or for specific versions `composer require drupal/module_name:1.2` ### Adding modules as local packages 1. Add local package information to the root of `composer.json`: ``` \"repositories\": { \"dpc-sdp/tide_page\": { \"type\": \"path\", \"url\": \"dpc-sdp/tide_page\" }, } ``` 2. `composer require tide_page` 3. To make sure that Composer triggers dependency tree rebuild, run `ahoy clean`. 4. Run `composer update --lock`. This will install all dependencies and update root `composer.lock` file with newly added module. ## Adding patches for composer packages 1. Add `title` and `url` to patch on drupal.org to the `patches` array in `extra` section in `composer.json`. ``` \"extra\": { \"patches\": { \"drupal/core\": { \"Contextual links should not be added inside another link - https://www.drupal.org/node/2898875\": \"https://www.drupal.org/files/issues/contextual_links_should-2898875-3.patch\" } } } ``` 2. `composer update --lock` ## Coding standards PHP and JS code linting uses [PHP_CodeSniffer](https://github.com/squizlabs/PHP_CodeSniffer) with Drupal rules from [Coder](https://www.drupal.org/project/coder) module and additional local overrides in `phpcs.xml.dist` and `.eslintrc`. ## Behat tests Behat configuration uses multiple extensions: - [Drupal Behat Extension](https://github.com/jhedstrom/drupalextension) - Drupal integration layer. Allows to work with Drupal API from within step definitions. - [Behat Screenshot Extension](https://github.com/integratedexperts/behat-screenshot) - Behat extension and a step definition to create HTML and image screenshots on demand or test fail. - [Behat Progress Fail Output Extension](https://github.com/integratedexperts/behat-format-progress-fail) - Behat output formatter to show progress as TAP and fail messages inline. Useful to get feedback about failed tests while continuing test run. - `YoursiteDrupalContext` - Site-specific Drupal context with custom step definitions. - `YoursiteMinkContext` - Site-specific Mink context with custom step definitions. ### Run tests locally: - Run Behat tests: `ahoy test-behat` - Run specific test feature: `ahoy test-behat tests/behat/features/homepage.feature` - Run specific test tag: `ahoy test-behat -- --tags=wip` ## Automated builds (Continuous Integration) In software engineering, continuous integration (CI) is the practice of merging all developer working copies to a shared mainline several times a day. Before feature changes can be merged into a shared mainline, a complete build must run and pass all tests on CI server. This project uses [Circle CI](https://circleci.com/) as CI server: it imports production backups into fully built codebase and runs code linting and tests. When tests pass, a deployment process is triggered for nominated branches (usually, `master` and `develop`). Add `[skip ci]` to the commit subject to skip CI build. Useful for documentation changes. ### SSH Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. ### Test artifacts Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI. ## Debugging ### PHP application from browser 1. Trigger xDebug from web browser (using one of the browser extensions) so that PHPStorm recognises the server `yoursite.docker.amazee.io` and configures the path mapping. Alternatively, you can create the server in PHPStorm Settings. * Make sure `serverName` to be `yoursite.docker.amazee.io` ### PHP scripts ``` ahoy cli xdebug.sh path/to/script ``` For example, to run a single Behat test: `xdebug.sh vendor/bin/behat path/to/test.feature` ### Drush commands ``` ahoy cli `./xdebug.sh vendor/bin/drush <DRUSH_COMMAND> ``` ### DB connection details Run `ahoy info` to get the port number. ``` Host: 127.0.0.1 Username: drupal Password: drupal Database: drupal Port: <get from \"ahoy info\"> ```","title":"Content Repository"},{"location":"development/content-repository/setup/","text":"Setting up a new Content Repository \u00b6 Note This chapter describes how to setup Content Repository using whole Tide distribution with all Tide modules included. It does not cover setting up of Tide modules outside of the distribution. Setup \u00b6 Setting up Content Repository is similar to setting up a Drupal site from any other contributed profile. Create drupal project. Using drupal-project composer create-project drupal-composer/drupal-project:8.x-dev some-dir --no-interaction Add Tide profile: composer require dpc-sdp/tide Commit scaffolding files. Install a site using drush site-install : drush site-install tide --db-url=mysql://user:pwd@localhost/db_name --site-name=Example --account-name=admin --account-pass=pwd Export the database and import it into your production database. Hosting on Bay \u00b6 Content Repository can be hosted on Bay. See Onboarding to Bay chapter. Environments \u00b6 The diagram below describes recommended environments for efficient front-end and back-end development: Production front-end sites are connected to production Content Repository where API is stable and content is live. This is standard environments for production sites. UAT front-end sites are connected to UAT Content Repository, where API is stable and content is live, but changes are not public. These environments allow to work with a copy of the live content without exposing it to public, which is useful during new feature testing. Local, CI and Preview (per branch) environments are connected to API-DEV Content Repository, where the latest API is still being developed and demonstrative-only but consistent content. This provides access to the latest API changes while developing new front-end or back-end functionality. Other content consumers under active development may connect to the API Content Repository with stable API and demonstrative-only but consistent content. This allows predictable API behaviour and data, but without access to change it. Expand to see the diagram","title":"Setup"},{"location":"development/content-repository/setup/#setting-up-a-new-content-repository","text":"Note This chapter describes how to setup Content Repository using whole Tide distribution with all Tide modules included. It does not cover setting up of Tide modules outside of the distribution.","title":"Setting up a new Content Repository"},{"location":"development/content-repository/setup/#setup","text":"Setting up Content Repository is similar to setting up a Drupal site from any other contributed profile. Create drupal project. Using drupal-project composer create-project drupal-composer/drupal-project:8.x-dev some-dir --no-interaction Add Tide profile: composer require dpc-sdp/tide Commit scaffolding files. Install a site using drush site-install : drush site-install tide --db-url=mysql://user:pwd@localhost/db_name --site-name=Example --account-name=admin --account-pass=pwd Export the database and import it into your production database.","title":"Setup"},{"location":"development/content-repository/setup/#hosting-on-bay","text":"Content Repository can be hosted on Bay. See Onboarding to Bay chapter.","title":"Hosting on Bay"},{"location":"development/content-repository/setup/#environments","text":"The diagram below describes recommended environments for efficient front-end and back-end development: Production front-end sites are connected to production Content Repository where API is stable and content is live. This is standard environments for production sites. UAT front-end sites are connected to UAT Content Repository, where API is stable and content is live, but changes are not public. These environments allow to work with a copy of the live content without exposing it to public, which is useful during new feature testing. Local, CI and Preview (per branch) environments are connected to API-DEV Content Repository, where the latest API is still being developed and demonstrative-only but consistent content. This provides access to the latest API changes while developing new front-end or back-end functionality. Other content consumers under active development may connect to the API Content Repository with stable API and demonstrative-only but consistent content. This allows predictable API behaviour and data, but without access to change it. Expand to see the diagram","title":"Environments"},{"location":"development/frontend-website/automated-builds/","text":"Automated builds \u00b6 SDP uses CircleCI for all automated build (CI) runs. Build steps \u00b6 Build a site from supplied package.json file (dependencies are locked-in at specific versions). This builds the site which is identical to the production site before running tests. Build style guide site Check coding standards in custom site code: JS, SCSS. Run unit tests (Jest), if any. Skipping CI builds \u00b6 Add [skip ci] to the commit subject to skip CI build. Useful for documentation changes. SSH into CI build \u00b6 Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. 1. Navigate to the job page 2. Click on the dropdown in the right top corner and select Rebuild with SSH . Test artifacts \u00b6 Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI.","title":"Automated builds"},{"location":"development/frontend-website/automated-builds/#automated-builds","text":"SDP uses CircleCI for all automated build (CI) runs.","title":"Automated builds"},{"location":"development/frontend-website/automated-builds/#build-steps","text":"Build a site from supplied package.json file (dependencies are locked-in at specific versions). This builds the site which is identical to the production site before running tests. Build style guide site Check coding standards in custom site code: JS, SCSS. Run unit tests (Jest), if any.","title":"Build steps"},{"location":"development/frontend-website/automated-builds/#skipping-ci-builds","text":"Add [skip ci] to the commit subject to skip CI build. Useful for documentation changes.","title":"Skipping CI builds"},{"location":"development/frontend-website/automated-builds/#ssh-into-ci-build","text":"Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. 1. Navigate to the job page 2. Click on the dropdown in the right top corner and select Rebuild with SSH .","title":"SSH into CI build"},{"location":"development/frontend-website/automated-builds/#test-artifacts","text":"Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI.","title":"Test artifacts"},{"location":"development/frontend-website/coding-standards/","text":"Front-End Coding Standards \u00b6 We use JavaScript Standard Style and Official ESLint plugin for Vue.js for all our contributed and custom components. Components styling agreements \u00b6 rpl prefix is used for all classes. Use hyphen - to separate words within class, use 2 hyphens -- to separate class parts. For example, .rpl-vertical-tabs--open . Use underscore _ to separate words within mixins, use 2 underscores __ to separate mixin parts. For example, rpl_vertical_tabs__tabs() . Class names are based on hierarchy: Component class name: .rpl-[component-name] Element class name: .rpl-[component-name]__[element-name] Modifier class name: .rpl-[component-name]--[modifier-name] Each component should define as variables: colours font sizes padding margins (Not needed on margins if values are used for absolute placement, e.g. auto , 0 ). Variables should use rpl prefix. HTML elements can be defined by their tag (not just class) where suitable. Component example: // Core // ===================================== // Variables. $rpl-core-link-color : blue ; // Mixins. @mixin rpl_core_link () { color : $ rpl-core-link-color ; text-decoration : underline ; }","title":"Coding standards"},{"location":"development/frontend-website/coding-standards/#front-end-coding-standards","text":"We use JavaScript Standard Style and Official ESLint plugin for Vue.js for all our contributed and custom components.","title":"Front-End Coding Standards"},{"location":"development/frontend-website/coding-standards/#components-styling-agreements","text":"rpl prefix is used for all classes. Use hyphen - to separate words within class, use 2 hyphens -- to separate class parts. For example, .rpl-vertical-tabs--open . Use underscore _ to separate words within mixins, use 2 underscores __ to separate mixin parts. For example, rpl_vertical_tabs__tabs() . Class names are based on hierarchy: Component class name: .rpl-[component-name] Element class name: .rpl-[component-name]__[element-name] Modifier class name: .rpl-[component-name]--[modifier-name] Each component should define as variables: colours font sizes padding margins (Not needed on margins if values are used for absolute placement, e.g. auto , 0 ). Variables should use rpl prefix. HTML elements can be defined by their tag (not just class) where suitable. Component example: // Core // ===================================== // Variables. $rpl-core-link-color : blue ; // Mixins. @mixin rpl_core_link () { color : $ rpl-core-link-color ; text-decoration : underline ; }","title":"Components styling agreements"},{"location":"development/frontend-website/component-development/","text":"Component development \u00b6 This content has not been developed yet How to develop custom component and contribute it back. API mocking \u00b6 We need to develop Frontend Websites against stable API. When Content Repository is still being developed alongside with Frontend Website, it is very hard for front-end developers to develop against non-stable API. Below is extensive explanation how to use different ways of mocking. Frontend Websites may choose the most suitable method for their development. 3 ways of mocking Internal mocking inside of Nuxt Inject mock HTTP client inside of Nuxt application and use it to read JSON responses from generated responses as a part of the test. Automated mock generation Generate API response mocks using automatically generated API schema and serve it to FE framework as a predictable and stable alternative API endpoint. Manual mock generation Generate dummy data on API side and store responses as JSON files to serve it to the FE framework as a predictable and stable alternative API endpoint. Internal mocking inside of Nuxt Inject mock HTTP client inside of Nuxt application and use it to read JSON responses from generated responses as a part of the test. How it would look like for a developer (DX) Initial setup Write a test that would test specific functionality. Write a mock generation code within a test. Repeat 1-2 for each test. Commit code to the codebase When API is updated (for example, new field is added to a content type) Update mock generation and assertions for all relevant tests. Commit code to the codebase Problems Writing mock generation code is complex and tiresome. When/if API changes, there may need to be a change to a lot of mock generation code. These mocks will not be used to browse fullFrontend Website. I.e., it will not be possible to browse homepage using these mocks. Changes to API require manual update of files. Automated mock generation Generate API response mocks using automatically generated API schema and serve it to FE framework as a predictable and stable alternative API endpoint. How it would look like for a developer (DX) Initial setup Drupal exposes API schema. Fake generator reads the schema and generates response JSON files. Files committed to FE repository. Mock server serves JSON files. When API is updated (for example, new field is added to a content type) Re-genearate JSON response files (same as step 2 above). Commit updated JSON files to FE repo (same as step 1 above). Problems The biggest problem is that current Drupal schema, provided by Schemata module, does not provide enough context to allow automated generation and relationships linking. For example, while descibing 'UUID' field, it says that the type is 'string', but says nothing about the format of such string. As a result - generated UUID is a random string in incorrect format. And this goes on for all fields. Even if p.1 is resolved, the generated content uses random apporach to fill fields. This has 2 issues: the content will be constantly changing making a lot of changes in committed files and confusing developers that expect specific data to be shown optional fields will be randomly filled-in (which is what we want), but there is no guarantee that all optional fields are used in a set of produced mocks. In other words, we need not just content with some randomised fields, but a full content set of permutations of all fields. Changes to API require manual update of files. Manual mock generation Generate dummy data on API side and store responses as JSON files to serve it to the FE framework as a predictable and stable alternative API endpoint. How it would look like for a developer (DX) Initial setup API has some dummy content generated in predictable way that covers all permutations. Manually ran script (or drush command) downloads all JSON responses as files. Files committed to FE repository. Mock server serves JSON files. When API is updated (for example, new field is added to a content type) Re-genearate JSON response files (same as step 2 above). Commit updated JSON files to FE repo (same as step 1 above). Problems Requires dummy content to exist on API site. Changes to API require manual update of files.","title":"Component Development *"},{"location":"development/frontend-website/component-development/#component-development","text":"This content has not been developed yet How to develop custom component and contribute it back.","title":"Component development"},{"location":"development/frontend-website/component-development/#api-mocking","text":"We need to develop Frontend Websites against stable API. When Content Repository is still being developed alongside with Frontend Website, it is very hard for front-end developers to develop against non-stable API. Below is extensive explanation how to use different ways of mocking. Frontend Websites may choose the most suitable method for their development.","title":"API mocking"},{"location":"development/frontend-website/local-development-environment/","text":"Local development environment \u00b6 Vue.js tools setup \u00b6 The steps below describe how to setup IDE (PHPStorm/WebStorm) to work with Vue.js application. Setup JS version Install Vue.js plugin (follow the setup guide at https://www.jetbrains.com/help/phpstorm/vue-js.html ) Set \"JavaScript language version\" to \"ECMAScript 6\" Setup JS Debugging Create a new JavaScript debug configuration Specify the URL the app is running on ( http://localhost:8080 ) Set a breakpoint Start the debug session by pressing \"Debug\" button in WebStorm/PHPStorm. Once the code where the breakpoint is has been triggered, the execution will stop, and you\u2019ll see the local and global variables, the call stack, and many other things in the IDE debug tools window.","title":"Local development environment"},{"location":"development/frontend-website/local-development-environment/#local-development-environment","text":"","title":"Local development environment"},{"location":"development/frontend-website/local-development-environment/#vuejs-tools-setup","text":"The steps below describe how to setup IDE (PHPStorm/WebStorm) to work with Vue.js application.","title":"Vue.js tools setup"},{"location":"development/frontend-website/readme-file/","text":"README.md file \u00b6 Use this readme file within your project to hold all required information about your project. Note Please note that you would need to replace several tokens within these files: _name_ - the name of the project _machine_name_ - the machine name of the project _org_machine_name_ - the machine name of the organisation Front-end implementation site \u00b6 README.frontend-website.md # _name_ Frontend Website Nuxt client for _name_. [![CircleCI](https://circleci.com/gh/_org_machine_name_/_machine_name_.svg?style=svg)](https://circleci.com/gh/_org_machine_name_/_machine_name_) ![Release](https://img.shields.io/github/release/dpc-sdp/_machine_name_.svg) ## Prerequisites 1. Make sure that you have latest versions of all required software installed: - [NodeJS](https://nodejs.org/) - [NPM](https://www.npmjs.com/) 2. Make sure that all local web development services are shut down (`apache/nginx`, `mysql`, `MAMP` etc). ## Prerequisites - using Docker 1. Make sure that you have latest versions of all required software installed: - [Docker](https://www.docker.com/) - [Pygmy](https://docs.amazee.io/local_docker_development/pygmy.html) - [Ahoy](https://github.com/ahoy-cli/ahoy) 2. Make sure that all local web development services are shut down (`apache/nginx`, `mysql`, `MAMP` etc). ## Setting up `SITE_ID` In order to connect to the Content Repository, a `SITE_ID` must be issued. 1. Contact your Content Repository administrators and ask them for a `SITE_ID`. 2. Add `SITE_ID` to `.env` file. ## Local environment setup ``` bash npm install npm run dev ``` Local URL -- [http://localhost:3000](http://localhost:3000) Without content in your site, you may see 404 in homepage, but you should able to visit path `/demo-landing-page` to start with a demo content page. ## Local environment setup (with Docker) Run `npm run bay:start` Local URL -- http://_machine_name_.docker.amazee.io/ ### Available workflow commands - `npm run bay:start` - start local development environment without build. - `npm run bay:rebuild-full` - rebuild local development environment and start. - `npm run bay:stop` - stop all Bay containers. - `npm run bay:destroy` - stop and remove all Bay containers. - `npm run bay:logs` - get logs from all running Bay containers. - `npm run bay:cli` - run a command in `node` container. Example: `npm run bay:cli -- ls -al`. - `npm run bay:pull` - pull latest Bay containers. ### Logs Using the npm run helper script you can get logs from any running container. `npm run bay:logs` To continue streaming logs, use `--follow`. `npm run bay:logs -- --follow` You can also filter the output to show only logs from a particular service. For example `npm run bay:logs -- app` will show the log output from the node container. The full list of services can be found in the `docker-compose.yml` ### SSHing into container SSH into app service `docker-compose exec app sh` SSH into test service `docker-compose exec test sh` ## Lint code ``` bash npm run lint ``` ## Test We uses [Jest](https://jestjs.io/) for unit test and end-to-end test. ``` bash npm test ```","title":"README.md file"},{"location":"development/frontend-website/readme-file/#readmemd-file","text":"Use this readme file within your project to hold all required information about your project. Note Please note that you would need to replace several tokens within these files: _name_ - the name of the project _machine_name_ - the machine name of the project _org_machine_name_ - the machine name of the organisation","title":"README.md file"},{"location":"development/frontend-website/readme-file/#front-end-implementation-site","text":"README.frontend-website.md # _name_ Frontend Website Nuxt client for _name_. [![CircleCI](https://circleci.com/gh/_org_machine_name_/_machine_name_.svg?style=svg)](https://circleci.com/gh/_org_machine_name_/_machine_name_) ![Release](https://img.shields.io/github/release/dpc-sdp/_machine_name_.svg) ## Prerequisites 1. Make sure that you have latest versions of all required software installed: - [NodeJS](https://nodejs.org/) - [NPM](https://www.npmjs.com/) 2. Make sure that all local web development services are shut down (`apache/nginx`, `mysql`, `MAMP` etc). ## Prerequisites - using Docker 1. Make sure that you have latest versions of all required software installed: - [Docker](https://www.docker.com/) - [Pygmy](https://docs.amazee.io/local_docker_development/pygmy.html) - [Ahoy](https://github.com/ahoy-cli/ahoy) 2. Make sure that all local web development services are shut down (`apache/nginx`, `mysql`, `MAMP` etc). ## Setting up `SITE_ID` In order to connect to the Content Repository, a `SITE_ID` must be issued. 1. Contact your Content Repository administrators and ask them for a `SITE_ID`. 2. Add `SITE_ID` to `.env` file. ## Local environment setup ``` bash npm install npm run dev ``` Local URL -- [http://localhost:3000](http://localhost:3000) Without content in your site, you may see 404 in homepage, but you should able to visit path `/demo-landing-page` to start with a demo content page. ## Local environment setup (with Docker) Run `npm run bay:start` Local URL -- http://_machine_name_.docker.amazee.io/ ### Available workflow commands - `npm run bay:start` - start local development environment without build. - `npm run bay:rebuild-full` - rebuild local development environment and start. - `npm run bay:stop` - stop all Bay containers. - `npm run bay:destroy` - stop and remove all Bay containers. - `npm run bay:logs` - get logs from all running Bay containers. - `npm run bay:cli` - run a command in `node` container. Example: `npm run bay:cli -- ls -al`. - `npm run bay:pull` - pull latest Bay containers. ### Logs Using the npm run helper script you can get logs from any running container. `npm run bay:logs` To continue streaming logs, use `--follow`. `npm run bay:logs -- --follow` You can also filter the output to show only logs from a particular service. For example `npm run bay:logs -- app` will show the log output from the node container. The full list of services can be found in the `docker-compose.yml` ### SSHing into container SSH into app service `docker-compose exec app sh` SSH into test service `docker-compose exec test sh` ## Lint code ``` bash npm run lint ``` ## Test We uses [Jest](https://jestjs.io/) for unit test and end-to-end test. ``` bash npm test ```","title":"Front-end implementation site"},{"location":"development/frontend-website/setup/","text":"Setting up a new Frontend Website \u00b6 This content has not been developed yet How to setup a new Frontend Website Install Ripple in your Nuxt project \u00b6 Example for installing @dpc-sdp/ripple-global and @dpc-sdp/ripple-site-header . npm install @dpc-sdp/ripple-global @dpc-sdp/ripple-site-header --save Usage in Nuxt project: import RplSiteHeader from '@dpc-sdp/ripple-site-header' import RplBreadcrumb from '@dpc-sdp/ripple-breadcrumb' import RplFooterNavigation from '@dpc-sdp/ripple-footer-navigation'","title":"Setup *"},{"location":"development/frontend-website/setup/#setting-up-a-new-frontend-website","text":"This content has not been developed yet How to setup a new Frontend Website","title":"Setting up a new Frontend Website"},{"location":"development/frontend-website/setup/#install-ripple-in-your-nuxt-project","text":"Example for installing @dpc-sdp/ripple-global and @dpc-sdp/ripple-site-header . npm install @dpc-sdp/ripple-global @dpc-sdp/ripple-site-header --save Usage in Nuxt project: import RplSiteHeader from '@dpc-sdp/ripple-site-header' import RplBreadcrumb from '@dpc-sdp/ripple-breadcrumb' import RplFooterNavigation from '@dpc-sdp/ripple-footer-navigation'","title":"Install Ripple in your Nuxt project"},{"location":"development/frontend-website/style-guide/","text":"Style guide \u00b6 A style guide is a document that provides guidelines for the way your brand should be presented from both a graphic and language perspective. The purpose of a style guide is to make sure that multiple contributors create in a clear and cohesive way that reflects the corporate style and ensures brand consistency with everything from design to writing. Ripple Component Library uses Storybook open-source software for a \"living\" style guide: any changes to the components in code are reflected within Storybook. Example of style guide Example of the style guide take from Ripple Component library Setup \u00b6 Frontend Websites can add Storybook configuration and publish it as GitHub pages using automated builds. See official setup guide https://storybook.js.org/docs/guides/guide-vue/ Components can be organised as required (Ripple uses atomic design) - Storybook supports flexible configuration. See https://github.com/dpc-sdp/ripple/tree/master/.storybook The components can also be customised to be displayed in groups etc. See https://github.com/dpc-sdp/ripple/tree/master/src/storybook-components The demo data to use in Storybook components can be provided in a separate file. See https://github.com/dpc-sdp/ripple/blob/master/src/storybook-components/_data/demoData.js","title":"Style guide"},{"location":"development/frontend-website/style-guide/#style-guide","text":"A style guide is a document that provides guidelines for the way your brand should be presented from both a graphic and language perspective. The purpose of a style guide is to make sure that multiple contributors create in a clear and cohesive way that reflects the corporate style and ensures brand consistency with everything from design to writing. Ripple Component Library uses Storybook open-source software for a \"living\" style guide: any changes to the components in code are reflected within Storybook. Example of style guide Example of the style guide take from Ripple Component library","title":"Style guide"},{"location":"development/frontend-website/style-guide/#setup","text":"Frontend Websites can add Storybook configuration and publish it as GitHub pages using automated builds. See official setup guide https://storybook.js.org/docs/guides/guide-vue/ Components can be organised as required (Ripple uses atomic design) - Storybook supports flexible configuration. See https://github.com/dpc-sdp/ripple/tree/master/.storybook The components can also be customised to be displayed in groups etc. See https://github.com/dpc-sdp/ripple/tree/master/src/storybook-components The demo data to use in Storybook components can be provided in a separate file. See https://github.com/dpc-sdp/ripple/blob/master/src/storybook-components/_data/demoData.js","title":"Setup"},{"location":"ripple/","text":"Ripple \u00b6 Ripple offers a consistent design system, making it easier for citizens to find, understand and use Victorian Government information maintained by SDP. It: is fully open and includes a library of reusable components, based on atomic pattern design. uses Vue.js and Nuxt to deliver a consistent look and feel across government websites. includes a starter kit for agencies. Namespaces \u00b6 NPM vendor namespace: dpc-sdp NPM packages namespace: ripple-* Repositories \u00b6 Ripple source code: https://github.com/dpc-sdp/ripple (this is a monorepo ). NPM: https://www.npmjs.com/org/dpc-sdp","title":"Overview"},{"location":"ripple/#ripple","text":"Ripple offers a consistent design system, making it easier for citizens to find, understand and use Victorian Government information maintained by SDP. It: is fully open and includes a library of reusable components, based on atomic pattern design. uses Vue.js and Nuxt to deliver a consistent look and feel across government websites. includes a starter kit for agencies.","title":"Ripple"},{"location":"ripple/#namespaces","text":"NPM vendor namespace: dpc-sdp NPM packages namespace: ripple-*","title":"Namespaces"},{"location":"ripple/#repositories","text":"Ripple source code: https://github.com/dpc-sdp/ripple (this is a monorepo ). NPM: https://www.npmjs.com/org/dpc-sdp","title":"Repositories"},{"location":"ripple/api/","text":"Ripple API \u00b6 This content has not been developed yet This chapter describes how to use Ripple/Nuxt API and how to configure field mapping.","title":"API *"},{"location":"ripple/api/#ripple-api","text":"This content has not been developed yet This chapter describes how to use Ripple/Nuxt API and how to configure field mapping.","title":"Ripple API"},{"location":"ripple/components/","text":"Components \u00b6 Ripple provides components library hosted at https://ripple.sdp.vic.gov.au Forms \u00b6 Ripple supports Drupal Webform . All backend Drupal webforms in Ripple frontend are rendered dynamically using Vue Form Generator (VFG) . Note Only limited set functionality is currently supported. See \"Support status\" column. Configuration Webform field Support status VFG form field #title IMPLEMENTED label #required IMPLEMENTED required #options IMPLEMENTED values #empty_option IMPLEMENTED placeholder #description IMPLEMENTED hint #placeholder IMPLEMENTED placeholder Elements Webform element name Webform Category Webform element ID Support status VFG form element Checkbox Basic checkbox PLANNED checkbox Hidden Basic hidden IMPLEMENTED input: hidden Textarea Basic textarea IMPLEMENTED textArea Text field Basic textfield IMPLEMENTED input: text Autocomplete Advanced NOT PLANNED CAPTCHA Advanced NOT PLANNED CodeMirror Advanced NOT PLANNED Color Advanced NOT PLANNED Email Advanced email IMPLEMENTED input: email Email confirm Advanced NOT PLANNED Email multiple Advanced NOT PLANNED Mapping Advanced Mapping NOT PLANNED Number Advanced number IMPLEMENTED input: number Range Advanced NOT PLANNED Rating Advanced NOT PLANNED Search Advanced NOT PLANNED Signature Advanced NOT PLANNED Telephone Advanced tel input: tel Terms of service Advanced NOT PLANNED Text format Advanced NOT PLANNED Toggle Advanced NOT PLANNED URL Advanced NOT PLANNED Value Advanced NOT PLANNED Basic address Composite NOT PLANNED Advanced address Composite NOT PLANNED Contact Composite NOT PLANNED Custom composite Composite NOT PLANNED Link Composite NOT PLANNED Location Composite NOT PLANNED Name Composite NOT PLANNED Telephone advanced? Composite NOT PLANNED Advanced HTML/Text Markup processed_text PLANNED label Basic HTML Markup webform_markup PLANNED label Horizontal rule Markup horizontal_rule PLANNED custom Message Markup NOT PLANNED Label Markup label PLANNED label Audio file File upload file NOT PLANNED Document file File upload file NOT PLANNED File File upload file NOT PLANNED Image file File upload file NOT PLANNED Video file File upload file NOT PLANNED Buttons Options NOT PLANNED Checkboxes Options NOT PLANNED Checkboxes other Options NOT PLANNED Likert Options NOT PLANNED Radios Options radios IMPLEMENTED radios Radios other Options NOT PLANNED Select Options select LIMITED vueMultiSelect Multi Select Options NOT PLANNED Select other Options select_other NOT PLANNED Table select Options NOT PLANNED Tableselect sort Options NOT PLANNED Table sort Options NOT PLANNED Computed token Computed NOT PLANNED Computed Twig Computed NOT PLANNED Container Container NOT PLANNED Details Container NOT PLANNED Fieldset Container NOT PLANNED Flexbox layout Container NOT PLANNED Item Container NOT PLANNED Section Container NOT PLANNED Date Date/time date PLANNED Date/time Date/time NOT PLANNED Date list Date/time NOT PLANNED Time Date/time NOT PLANNED Submit button(s) Buttons webform_actions LIMITED Entity autocomplete Entity reference NOT PLANNED Entity checkboxes Entity reference NOT PLANNED Entity radios Entity reference NOT PLANNED Entity select Entity reference NOT PLANNED Term checkboxes Entity reference NOT PLANNED Term select Entity reference webform_term_select PLANNED","title":"Components"},{"location":"ripple/components/#components","text":"Ripple provides components library hosted at https://ripple.sdp.vic.gov.au","title":"Components"},{"location":"ripple/components/#forms","text":"Ripple supports Drupal Webform . All backend Drupal webforms in Ripple frontend are rendered dynamically using Vue Form Generator (VFG) . Note Only limited set functionality is currently supported. See \"Support status\" column.","title":"Forms"},{"location":"ripple/content-data-flow/","text":"Content data flow \u00b6 This chapter describes how data requested from Content Repository flows to front-end website implementation and how it is then rendered to the visitor in the browser. Request round trip \u00b6 The diagram below shows how a visitor's request travels through all systems to render a page and, subsequently, update a component. Component request diagram There are multiple caching layers to speed up the initial page render: - Static HTML page cache in CloudFront Cache of the previously rendered front-end page. This completely avoids requests to API, making the site render solely in the browser. - Static API JSON response cache in CloudFront Cache of the previously requested API response. This allows to speedup page assembly from several API endpoints. - Content Repository entity cache and other caches Internal caching mechanism within Content Repository. Allows to lower load and minimise expensive data retrieval operations from the database. Once rendered, components may request an update for a part of the page, bypassing all static cache layers, but still re-using caching within Content repository. Note that Content Repository refreshes internal caches and notifies external proxies (CloudFront etc.) once the content changes. This mechanism is inbuilt in Drupal. Nuxt data processing \u00b6 Once request reaches front-end website, Nuxt receives a request, fetches internal configuration and requests content from Content Repository via tide package, which has field mappings and other integrations defined. Once the content is received, the page template assembles page using Ripple component library, after which the page is sent to the browser. Note that Ripple is completely separate from the tide package and Nuxt configuration - this makes it unbound to Tide Content Repository.","title":"Content data flow"},{"location":"ripple/content-data-flow/#content-data-flow","text":"This chapter describes how data requested from Content Repository flows to front-end website implementation and how it is then rendered to the visitor in the browser.","title":"Content data flow"},{"location":"ripple/content-data-flow/#request-round-trip","text":"The diagram below shows how a visitor's request travels through all systems to render a page and, subsequently, update a component. Component request diagram There are multiple caching layers to speed up the initial page render: - Static HTML page cache in CloudFront Cache of the previously rendered front-end page. This completely avoids requests to API, making the site render solely in the browser. - Static API JSON response cache in CloudFront Cache of the previously requested API response. This allows to speedup page assembly from several API endpoints. - Content Repository entity cache and other caches Internal caching mechanism within Content Repository. Allows to lower load and minimise expensive data retrieval operations from the database. Once rendered, components may request an update for a part of the page, bypassing all static cache layers, but still re-using caching within Content repository. Note that Content Repository refreshes internal caches and notifies external proxies (CloudFront etc.) once the content changes. This mechanism is inbuilt in Drupal.","title":"Request round trip"},{"location":"ripple/content-data-flow/#nuxt-data-processing","text":"Once request reaches front-end website, Nuxt receives a request, fetches internal configuration and requests content from Content Repository via tide package, which has field mappings and other integrations defined. Once the content is received, the page template assembles page using Ripple component library, after which the page is sent to the browser. Note that Ripple is completely separate from the tide package and Nuxt configuration - this makes it unbound to Tide Content Repository.","title":"Nuxt data processing"},{"location":"ripple/search/","text":"Search \u00b6 Content for this page has not been migrated yet.","title":"Search"},{"location":"ripple/search/#search","text":"Content for this page has not been migrated yet.","title":"Search"},{"location":"ripple/setup/","text":"Setting up a new Ripple site \u00b6 Content for this page has not been migrated yet. Connecting to Content Repository \u00b6 See Environments for instructions how to connect to relevant Content Repository environment.","title":"Setup new site"},{"location":"ripple/setup/#setting-up-a-new-ripple-site","text":"Content for this page has not been migrated yet.","title":"Setting up a new Ripple site"},{"location":"ripple/setup/#connecting-to-content-repository","text":"See Environments for instructions how to connect to relevant Content Repository environment.","title":"Connecting to Content Repository"},{"location":"tide/","text":"Tide \u00b6 Tide is an API first, headless content management system using Drupal 8 and maintained by SDP. Custom built to meet Victorian Government requirements, it offers: - multi-site content distribution - pick and mix features - centralised feature governance The profile is a mere collection of Tide modules bundled into governed, stable and tested Drupal installation profile. All modules and a profile have automated tests to guarantee that a set of all modules at specified versions is always stable. Namespaces \u00b6 Composer vendor namespace: dpc-sdp Composer Drupal profile namespace: dpc-sdp/tide Composer Drupal modules namespace: tide_* . Drupal.org Drupal profile namespace: tide . Drupal.org Drupal modules namespace: tide_* . Drupal profile machine name: tide Drupal modules machine name: tide_* Repositories \u00b6 Drupal profile: https://github.com/dpc-sdp/tide Drupal custom modules: https://github.com/dpc-sdp/tide_api https://github.com/dpc-sdp/tide_core https://github.com/dpc-sdp/tide_event https://github.com/dpc-sdp/tide_landing_page https://github.com/dpc-sdp/tide_media https://github.com/dpc-sdp/tide_monsido https://github.com/dpc-sdp/tide_news https://github.com/dpc-sdp/tide_page https://github.com/dpc-sdp/tide_search https://github.com/dpc-sdp/tide_site https://github.com/dpc-sdp/tide_test https://github.com/dpc-sdp/tide_webform See Modules chapter for more information about modules.","title":"Overview"},{"location":"tide/#tide","text":"Tide is an API first, headless content management system using Drupal 8 and maintained by SDP. Custom built to meet Victorian Government requirements, it offers: - multi-site content distribution - pick and mix features - centralised feature governance The profile is a mere collection of Tide modules bundled into governed, stable and tested Drupal installation profile. All modules and a profile have automated tests to guarantee that a set of all modules at specified versions is always stable.","title":"Tide"},{"location":"tide/#namespaces","text":"Composer vendor namespace: dpc-sdp Composer Drupal profile namespace: dpc-sdp/tide Composer Drupal modules namespace: tide_* . Drupal.org Drupal profile namespace: tide . Drupal.org Drupal modules namespace: tide_* . Drupal profile machine name: tide Drupal modules machine name: tide_*","title":"Namespaces"},{"location":"tide/#repositories","text":"Drupal profile: https://github.com/dpc-sdp/tide Drupal custom modules: https://github.com/dpc-sdp/tide_api https://github.com/dpc-sdp/tide_core https://github.com/dpc-sdp/tide_event https://github.com/dpc-sdp/tide_landing_page https://github.com/dpc-sdp/tide_media https://github.com/dpc-sdp/tide_monsido https://github.com/dpc-sdp/tide_news https://github.com/dpc-sdp/tide_page https://github.com/dpc-sdp/tide_search https://github.com/dpc-sdp/tide_site https://github.com/dpc-sdp/tide_test https://github.com/dpc-sdp/tide_webform See Modules chapter for more information about modules.","title":"Repositories"},{"location":"tide/api/","text":"Tide API \u00b6 Content API is built from a set of contributed modules and custom code provided through Tide API module. Why JSONAPI? \u00b6 Why we selected JSONAPI standard over generic REST provided by Drupal core: JSON is a standard of REST, a subset of generic REST rules. JSONAPI allows to query individual items and collections. Drupal JSONAPI module automatically exposes entities as endpoints. Because most of functionality is implement as entities in Drupal 8, there is no need for custom code to expose required features. JSONAPI is a newer format JSONAPI will be included in Drupal core. Documentation on using Drupal JSONAPI module: https://www.drupal .org/docs/8/modules/json-api It is assumed that API consumers support the following: Can traverse data. Can cache based on response headers. Can resolve relationships by following links. Drupal JSONAPI and related modules \u00b6 jsonapi - main module that exposes entities as endpoints and provides support for REST operations. jsonapi_extras - helper module to alter JSONAPI config: endpoints prefix (we are using /api/v1 ) and enable/disable endpoints for automatically exposed entities (we use this to limit access to internal entities). Endpoints example \u00b6 While providing a list of all endpoints would be to publish whole Drupal API (which is neither maintainable no required), the example page below demonstrates how Frontend Website can be mapped to Content Repository endpoints. Component Content API endpoint Comment 1 route /api/v1/route?alias=<alias> Given an alias, returns information about current route, including entity UUID. 2 main menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=main 3 banner TBD If exposed as a block - use block-based endpoint. If exposed as a content field - use entity endpoint with inclusion. 4 breadcrumbs TBD Not supported out of the box. May need to use main menu to build breadcrumbs by Frontend Website. 5 content /api/v1/page/<UUID>?include=field_page_paragraph Can be combined with 6 6 related content /api/v1/page/<UUID>?include=field_related_content Can be combined with 5 7 share block /api/v1/block_content/share_block Content is a static HTML 8 was this page helpful TBD Posting of webform submissions is not supported. Custom module may be required. 9 footer main menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=main 10 copyright /api/v1/block_content/copyright Content is a static HTML 11 footer menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=footer 12 Sites information /api/v1/taxonomy_term/sites Allows to retrieve custom site information stored in the Content Repository 13 Router /api/v1/router Alias lookup. May be required for ad-hoc queries from Frontend Website. Request flow \u00b6 The diagram below demonstrates how a single page is assembled by VueJS/Nuxt when hitting multiple endpoints. VueJS/Nuxt retrieves site information and caches it internally until the next cache clear. Each Frontend Website has only site UUID (taxonomy term UUID from Site vocabulary) hardcoded. The rest of configuration comes from taxonomy term: logo, slogan, footer text, main menu name, footer menu name. This information is later used in follow-up requests to retrieve relevant information. Note Since Frontend Websites information is stored using fieldsable taxonomy terms, it is possible to add more fields to capture site information in the Content Repository. The data stored in these fields will become automatically exposed through API. See Sites and sections for more information about organising per-site information. Content API Content , Content API Menu , and Content API Block are shown here as separated endpoints (they are indeed separate), but are handled by the same internal entity controller from JSONAPI Drupal module. The content is filtered by Content API Filter based on provided site and path query parameters. If no site or path is provided the request is considered invalid and an error response is returned. Content API Filter is a thin layer (e.g. request event listener) in front of all JSONAPI endpoints. For example, if the content exists, but is not assigned to a site or section, it is considered as non-existing content when accessed from this site. Internal Router is a mechanism to lookup internal path by provided alias. There is a similar functionality with a Router Endpoint , but it resolves aliases without additional Drupal-to-Drupal request. End-to-end URL resolution \u00b6 The diagram below describes how URL requested by a web browser is resolved by Drupal and served by VueJS/Nuxt. It covers both front-end and back-end mechanisms. To leverage JSONAPI module in Drupal, we are using API Router to resolve requested paths to a set of information about the route (UUID, content type, path, alias). This information then used by Client API path builder to assemble a path to then send a second request to the JSONAPI endpoint. It is important to note that due to how content links can be provided within content, the path resolution within API Router should be able to find the best match from either path or alias provided. For example, paths about-us , /about-us , node/123 , /node/123 should all resolve to UUID of About Us page. When matched entity found, API Router also checks if it has the specified site assigned and returns an error if this path is not available. Also, API Router has all lookups cached in Drupal's dynamic cache, which is tagged with cache tags (so that the cache for path is cleared when entity is updated). Router API endpoint \u00b6 To control content aliases from Drupal and resolve requests coming from Browser into Frontend Website, a special Router endpoint exists to perform a lookup on provided path. Because the provided path can be either internal Drupal path or an alias, the lookup searches through all existing aliases and internal paths. When non-existing alias is provided, the endpoint returns an error according to JSONAPI specification. Router API also allows to filter by site if site URL query parameter is provided. Referenced entities \u00b6 JSONAPI supports including referenced entities in response by using include query parameter and a comma-separated list of entity reference fields. For example, /api/v1/page/<UUID>?include=field_page_paragraph . Drupal caching \u00b6 Response headers pass-through Drupal-generated cache tags. This means that reverse proxies can bind to Drupal cache tags and invalidate their caches as soon as Drupal caches become invalid.","title":"API"},{"location":"tide/api/#tide-api","text":"Content API is built from a set of contributed modules and custom code provided through Tide API module.","title":"Tide API"},{"location":"tide/api/#why-jsonapi","text":"Why we selected JSONAPI standard over generic REST provided by Drupal core: JSON is a standard of REST, a subset of generic REST rules. JSONAPI allows to query individual items and collections. Drupal JSONAPI module automatically exposes entities as endpoints. Because most of functionality is implement as entities in Drupal 8, there is no need for custom code to expose required features. JSONAPI is a newer format JSONAPI will be included in Drupal core. Documentation on using Drupal JSONAPI module: https://www.drupal .org/docs/8/modules/json-api It is assumed that API consumers support the following: Can traverse data. Can cache based on response headers. Can resolve relationships by following links.","title":"Why JSONAPI?"},{"location":"tide/api/#drupal-jsonapi-and-related-modules","text":"jsonapi - main module that exposes entities as endpoints and provides support for REST operations. jsonapi_extras - helper module to alter JSONAPI config: endpoints prefix (we are using /api/v1 ) and enable/disable endpoints for automatically exposed entities (we use this to limit access to internal entities).","title":"Drupal JSONAPI and related modules"},{"location":"tide/api/#endpoints-example","text":"While providing a list of all endpoints would be to publish whole Drupal API (which is neither maintainable no required), the example page below demonstrates how Frontend Website can be mapped to Content Repository endpoints. Component Content API endpoint Comment 1 route /api/v1/route?alias=<alias> Given an alias, returns information about current route, including entity UUID. 2 main menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=main 3 banner TBD If exposed as a block - use block-based endpoint. If exposed as a content field - use entity endpoint with inclusion. 4 breadcrumbs TBD Not supported out of the box. May need to use main menu to build breadcrumbs by Frontend Website. 5 content /api/v1/page/<UUID>?include=field_page_paragraph Can be combined with 6 6 related content /api/v1/page/<UUID>?include=field_related_content Can be combined with 5 7 share block /api/v1/block_content/share_block Content is a static HTML 8 was this page helpful TBD Posting of webform submissions is not supported. Custom module may be required. 9 footer main menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=main 10 copyright /api/v1/block_content/copyright Content is a static HTML 11 footer menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=footer 12 Sites information /api/v1/taxonomy_term/sites Allows to retrieve custom site information stored in the Content Repository 13 Router /api/v1/router Alias lookup. May be required for ad-hoc queries from Frontend Website.","title":"Endpoints example"},{"location":"tide/api/#request-flow","text":"The diagram below demonstrates how a single page is assembled by VueJS/Nuxt when hitting multiple endpoints. VueJS/Nuxt retrieves site information and caches it internally until the next cache clear. Each Frontend Website has only site UUID (taxonomy term UUID from Site vocabulary) hardcoded. The rest of configuration comes from taxonomy term: logo, slogan, footer text, main menu name, footer menu name. This information is later used in follow-up requests to retrieve relevant information. Note Since Frontend Websites information is stored using fieldsable taxonomy terms, it is possible to add more fields to capture site information in the Content Repository. The data stored in these fields will become automatically exposed through API. See Sites and sections for more information about organising per-site information. Content API Content , Content API Menu , and Content API Block are shown here as separated endpoints (they are indeed separate), but are handled by the same internal entity controller from JSONAPI Drupal module. The content is filtered by Content API Filter based on provided site and path query parameters. If no site or path is provided the request is considered invalid and an error response is returned. Content API Filter is a thin layer (e.g. request event listener) in front of all JSONAPI endpoints. For example, if the content exists, but is not assigned to a site or section, it is considered as non-existing content when accessed from this site. Internal Router is a mechanism to lookup internal path by provided alias. There is a similar functionality with a Router Endpoint , but it resolves aliases without additional Drupal-to-Drupal request.","title":"Request flow"},{"location":"tide/api/#end-to-end-url-resolution","text":"The diagram below describes how URL requested by a web browser is resolved by Drupal and served by VueJS/Nuxt. It covers both front-end and back-end mechanisms. To leverage JSONAPI module in Drupal, we are using API Router to resolve requested paths to a set of information about the route (UUID, content type, path, alias). This information then used by Client API path builder to assemble a path to then send a second request to the JSONAPI endpoint. It is important to note that due to how content links can be provided within content, the path resolution within API Router should be able to find the best match from either path or alias provided. For example, paths about-us , /about-us , node/123 , /node/123 should all resolve to UUID of About Us page. When matched entity found, API Router also checks if it has the specified site assigned and returns an error if this path is not available. Also, API Router has all lookups cached in Drupal's dynamic cache, which is tagged with cache tags (so that the cache for path is cleared when entity is updated).","title":"End-to-end URL resolution"},{"location":"tide/api/#router-api-endpoint","text":"To control content aliases from Drupal and resolve requests coming from Browser into Frontend Website, a special Router endpoint exists to perform a lookup on provided path. Because the provided path can be either internal Drupal path or an alias, the lookup searches through all existing aliases and internal paths. When non-existing alias is provided, the endpoint returns an error according to JSONAPI specification. Router API also allows to filter by site if site URL query parameter is provided.","title":"Router API endpoint"},{"location":"tide/api/#referenced-entities","text":"JSONAPI supports including referenced entities in response by using include query parameter and a comma-separated list of entity reference fields. For example, /api/v1/page/<UUID>?include=field_page_paragraph .","title":"Referenced entities"},{"location":"tide/api/#drupal-caching","text":"Response headers pass-through Drupal-generated cache tags. This means that reverse proxies can bind to Drupal cache tags and invalidate their caches as soon as Drupal caches become invalid.","title":"Drupal caching"},{"location":"tide/fields-components/","text":"Fields and components \u00b6 This section describes how Tide Drupal profile and modules use and re-use fields within content types and other entities such as paragraphs and taxonomy terms. Concepts \u00b6 Fields are re-used between system components as much as possible. Fields names are kept to the minimum length. Fields always have a prefix that describes the entity or the feature they belong to. For example: field_page_intro_text is a Introductory text for Page content type. Fields configuration is bundled within Tide modules. Some fields are programmatically created when specific Tide modules are installed (for example, Tide Site creates 2 fields for each content type). Kinds of fields \u00b6 Content fields - used to capture and store content that is later exposed through API and consumed by the front-end. For example, Body or Summary fields. Flag (on/off) fields - used to enable/disable rendering of a pre-defined component / block / feature in Frontend Websites. For example, Show social links field that tells Frontend Website to show or hide Social links component (which exists only in Frontend Website). Reference fields - used to reference other content items. These are rendered in API as references; API consumers are expected to use ?include JSONAPI standard mechanism to include the contents of the referenced entity into the API response. For example, Cards components are paragraphs referenced from within the content type. Frontend Website must include paragraph name to retrieve required paragraph content. Cards \u00b6 Cards are front-end components that are implemented as paragraph items in Tide. Cards implemented as Paragraphs Cards are reusing fields storage (see the list of fields below). List of Card fields Name Machine name Type Title field_paragraph_title Text field Summary field_paragraph_summary Large multiline text field with WYSIWYG support Author field_paragraph_author Text field Media field_paragraph_media Media field Date field_paragraph_date Date field Link field_paragraph_link Link field List field_paragraph_list Entity reference Location field_paragraph_location Location/ Reference field_paragraph_reference Entity reference Topic field_paragraph_topic Entity reference Cards have 1-to-1 mapping to paragraphs. This means that: cards can be added/removed from/to Frontend Websites and have their paragraphs counterparts added/removed in Content Repository mandatory state of the fields on cards is easier to configure and manage there is no need to manage any other 'types' of the same card (i.e. no special fields that would modify the 'type' of the card making it appear differently) Automated cards are using list entity reference field to reference items. About Automated cards Automated cards are cards that source their content from a pre-defined mapping in the Content API. For example, a card with a list of latest 3 events that automatically fetches only 3 latest events. Note that fetching the page with the information about the card does not fetch the contents of the card; Frontend Website must perform an additional request to get this data. Listing cards are comprised of paragraphs, resulting in nesting paragraphs (for example, Key Dates paragraph will have a list of Event paragraphs). Cards and paragraphs The table below describes how every Card component is represented with Tide paragraphs . Card Label (in Drupal) Machine name Fields (label, machine name) Comments Navigation featured (Manual) Navigation featured card_navigation_featured Title - field_paragraph_title Summary - field_paragraph_summary Image - field_paragraph_media Link - field_paragraph_link This card has 1 text link. Link text = Title Navigation featured (Automatic) Navigation featured Automated card_navigation_featured_auto Referred content - field_paragraph_reference This card has 1 text link. Link text = Title Navigation (Manual) Navigation card_navigation Title - field_paragraph_title Summary - field_paragraph_summary Link - field_paragraph_link This card has 1 text link. Link text = Title Navigation Automated Navigation Automated card_navigation_auto Referred content - field_paragraph_reference This card has 1 text link. Link text = Title Promotion (Manual) Promotion card_promotion Title - field_paragraph_title Summary - field_paragraph_summary Image - field_paragraph_media Date - field_paragraph_date Topic - field_paragraph_topic Link - field_paragraph_link This card has 3 text links. Link 1 = Title Link 2 = Topic Link 3 = Link Promotion Automated Promotion Automated card_promotion_auto Referred content - field_paragraph_reference This card has 3 text links. Link 1 = Title Link 2 = Topic Link 3 = Link Event (Manual) Event card_event Title - field_paragraph_title Summary - field_paragraph_summary Image - field_paragraph_media Date - field_paragraph_date Location - field_paragraph_location Topic - field_paragraph_topic Link - field_paragraph_link This card has 4 text links. Link 1 = Title Link 2 = Location Link 3 = Topic Link 4 = Link Key dates (Manual) Key dates card_keydates 1. Add a paragraph type Keydates (with fields): Key Dates - field_paragraph_keydate Title - field_paragraph_title Summary - field_paragraph_summary Link - field_paragraph_link 2. Add a paragraph type - Card Keydates Keydates - Entity Ref - Paragraph type created above - Max 2 values CTA - field_paragraph_cta This card has 3 text links. Link 1 = Link (Keydates 1) Link 2 = Link (Keydates 2) Link 3 = CTA","title":"Fields and components"},{"location":"tide/fields-components/#fields-and-components","text":"This section describes how Tide Drupal profile and modules use and re-use fields within content types and other entities such as paragraphs and taxonomy terms.","title":"Fields and components"},{"location":"tide/fields-components/#concepts","text":"Fields are re-used between system components as much as possible. Fields names are kept to the minimum length. Fields always have a prefix that describes the entity or the feature they belong to. For example: field_page_intro_text is a Introductory text for Page content type. Fields configuration is bundled within Tide modules. Some fields are programmatically created when specific Tide modules are installed (for example, Tide Site creates 2 fields for each content type).","title":"Concepts"},{"location":"tide/fields-components/#kinds-of-fields","text":"Content fields - used to capture and store content that is later exposed through API and consumed by the front-end. For example, Body or Summary fields. Flag (on/off) fields - used to enable/disable rendering of a pre-defined component / block / feature in Frontend Websites. For example, Show social links field that tells Frontend Website to show or hide Social links component (which exists only in Frontend Website). Reference fields - used to reference other content items. These are rendered in API as references; API consumers are expected to use ?include JSONAPI standard mechanism to include the contents of the referenced entity into the API response. For example, Cards components are paragraphs referenced from within the content type. Frontend Website must include paragraph name to retrieve required paragraph content.","title":"Kinds of fields"},{"location":"tide/fields-components/#cards","text":"Cards are front-end components that are implemented as paragraph items in Tide. Cards implemented as Paragraphs Cards are reusing fields storage (see the list of fields below). List of Card fields Name Machine name Type Title field_paragraph_title Text field Summary field_paragraph_summary Large multiline text field with WYSIWYG support Author field_paragraph_author Text field Media field_paragraph_media Media field Date field_paragraph_date Date field Link field_paragraph_link Link field List field_paragraph_list Entity reference Location field_paragraph_location Location/ Reference field_paragraph_reference Entity reference Topic field_paragraph_topic Entity reference Cards have 1-to-1 mapping to paragraphs. This means that: cards can be added/removed from/to Frontend Websites and have their paragraphs counterparts added/removed in Content Repository mandatory state of the fields on cards is easier to configure and manage there is no need to manage any other 'types' of the same card (i.e. no special fields that would modify the 'type' of the card making it appear differently) Automated cards are using list entity reference field to reference items. About Automated cards Automated cards are cards that source their content from a pre-defined mapping in the Content API. For example, a card with a list of latest 3 events that automatically fetches only 3 latest events. Note that fetching the page with the information about the card does not fetch the contents of the card; Frontend Website must perform an additional request to get this data. Listing cards are comprised of paragraphs, resulting in nesting paragraphs (for example, Key Dates paragraph will have a list of Event paragraphs).","title":"Cards"},{"location":"tide/modules/","text":"Modules \u00b6 The standalone modules are split based on the features or functionality they provide. Modules can be installed as a part of the profile as well as a standalone (provided that other dependency modules installed as well). Every module implements a well-defined feature set. Modules are versioned. This allows for more granular approach when picking modules for particular site needs. Every module has a minimal dependency on other modules. Every module has a set of relevant automated tests. List of modules \u00b6 Name Machine name Category Repository Description Tide API tide_api Utility https://github.com/dpc-sdp/tide_api Exposes content entities to API endpoints. it is required for sites running headless. Tide Core tide_core Utility https://github.com/dpc-sdp/tide_core Configurations and settings for Tide distribution. Dependency module for any other Tide module. Tide Event tide_event Content type https://github.com/dpc-sdp/tide_event Event content type and fields. Tide Landing Page tide_landing_page Content type https://github.com/dpc-sdp/tide_landing_page \"Landing page content type with fields. Based on paragrpahs, it allows to create pages with complex layouts.\" Tide Media tide_media Utility https://github.com/dpc-sdp/tide_media Media types and configurations. Tide Monsido tide_monsido 3 rd party integration https://github.com/dpc-sdp/tide_monsido Integration with Monsido platform. Tide News tide_news Content type https://github.com/dpc-sdp/tide_news Event content type and fields. Tide Page tide_page Content type https://github.com/dpc-sdp/tide_page Page content type and fields. Tide Search tide_search Utility https://github.com/dpc-sdp/tide_search Search configurations and settings. Tide Site tide_site Utility https://github.com/dpc-sdp/tide_site Multi-site and multi-section content sharing. Tide Test tide_test Utility https://github.com/dpc-sdp/tide_test Test content type and helpers used to test other modules. Tide Webform tide_webform Utility https://github.com/dpc-sdp/tide_webform Forms supports such as Content Rating form. Automated testing \u00b6 Tide modules use PHPUnit and Behat for unit and integration/behavioural testing. The tests are running inside of the Continuous Integration pipeline provided by CircleCI . For every change pushed to the repository, CircleCI starts the build, where tests are running in 2 modes: normal and suggested . In normal mode the module is installed with it's required dependencies into freshly built Drupal site. Once installed, the tests will run and check that the configuration shipped with the module indeed works. In suggested mode, the module is installed with it's requires and optional dependencies. Once installed, the tests will run and check that the configuration shipped with the module indeed works and that it does not conflict with other optional modules. This \"double-testing\" is very powerful tool to keep configuration in releasable state. Versions \u00b6 Modules versions follow semantic versioning : Quote Given a version number MAJOR.MINOR.PATCH , increment the: MAJOR version when you make incompatible API changes, MINOR version when you add functionality in a backwards-compatible manner, and PATCH version when you make backwards-compatible bug fixes. Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format. With some Tide functionality heavily relying on specific Drupal core version, when features added and changed in MINOR Drupal core versions (like moving Media into Drupal core), Tide modules increment their MAJOR version when Drupal core or dependent contributed modules change their API. Since Tide modules functionality is built on top of Drupal core and contributed modules, it has to \"tighten\" versioning rules. Every Tide module has to increment the: MAJOR version when Drupal core or contrib module has an API change. An example of this is moving Media into Drupal core in version 8.5 . MINOR version when Tide module functionality is enhanced or when other dependent Tide module has it's API change (that would trigger own release). PATCH version when there is a backwards-compatible bug fixes (no change from SemVer). Maintenance \u00b6 SDP development team is committed to support development, maintain all Tide modules and follow versioning rules. Developing modules \u00b6 See Module development chapter.","title":"Modules"},{"location":"tide/modules/#modules","text":"The standalone modules are split based on the features or functionality they provide. Modules can be installed as a part of the profile as well as a standalone (provided that other dependency modules installed as well). Every module implements a well-defined feature set. Modules are versioned. This allows for more granular approach when picking modules for particular site needs. Every module has a minimal dependency on other modules. Every module has a set of relevant automated tests.","title":"Modules"},{"location":"tide/modules/#list-of-modules","text":"Name Machine name Category Repository Description Tide API tide_api Utility https://github.com/dpc-sdp/tide_api Exposes content entities to API endpoints. it is required for sites running headless. Tide Core tide_core Utility https://github.com/dpc-sdp/tide_core Configurations and settings for Tide distribution. Dependency module for any other Tide module. Tide Event tide_event Content type https://github.com/dpc-sdp/tide_event Event content type and fields. Tide Landing Page tide_landing_page Content type https://github.com/dpc-sdp/tide_landing_page \"Landing page content type with fields. Based on paragrpahs, it allows to create pages with complex layouts.\" Tide Media tide_media Utility https://github.com/dpc-sdp/tide_media Media types and configurations. Tide Monsido tide_monsido 3 rd party integration https://github.com/dpc-sdp/tide_monsido Integration with Monsido platform. Tide News tide_news Content type https://github.com/dpc-sdp/tide_news Event content type and fields. Tide Page tide_page Content type https://github.com/dpc-sdp/tide_page Page content type and fields. Tide Search tide_search Utility https://github.com/dpc-sdp/tide_search Search configurations and settings. Tide Site tide_site Utility https://github.com/dpc-sdp/tide_site Multi-site and multi-section content sharing. Tide Test tide_test Utility https://github.com/dpc-sdp/tide_test Test content type and helpers used to test other modules. Tide Webform tide_webform Utility https://github.com/dpc-sdp/tide_webform Forms supports such as Content Rating form.","title":"List of modules"},{"location":"tide/modules/#automated-testing","text":"Tide modules use PHPUnit and Behat for unit and integration/behavioural testing. The tests are running inside of the Continuous Integration pipeline provided by CircleCI . For every change pushed to the repository, CircleCI starts the build, where tests are running in 2 modes: normal and suggested . In normal mode the module is installed with it's required dependencies into freshly built Drupal site. Once installed, the tests will run and check that the configuration shipped with the module indeed works. In suggested mode, the module is installed with it's requires and optional dependencies. Once installed, the tests will run and check that the configuration shipped with the module indeed works and that it does not conflict with other optional modules. This \"double-testing\" is very powerful tool to keep configuration in releasable state.","title":"Automated testing"},{"location":"tide/modules/#versions","text":"Modules versions follow semantic versioning : Quote Given a version number MAJOR.MINOR.PATCH , increment the: MAJOR version when you make incompatible API changes, MINOR version when you add functionality in a backwards-compatible manner, and PATCH version when you make backwards-compatible bug fixes. Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format. With some Tide functionality heavily relying on specific Drupal core version, when features added and changed in MINOR Drupal core versions (like moving Media into Drupal core), Tide modules increment their MAJOR version when Drupal core or dependent contributed modules change their API. Since Tide modules functionality is built on top of Drupal core and contributed modules, it has to \"tighten\" versioning rules. Every Tide module has to increment the: MAJOR version when Drupal core or contrib module has an API change. An example of this is moving Media into Drupal core in version 8.5 . MINOR version when Tide module functionality is enhanced or when other dependent Tide module has it's API change (that would trigger own release). PATCH version when there is a backwards-compatible bug fixes (no change from SemVer).","title":"Versions"},{"location":"tide/modules/#maintenance","text":"SDP development team is committed to support development, maintain all Tide modules and follow versioning rules.","title":"Maintenance"},{"location":"tide/modules/#developing-modules","text":"See Module development chapter.","title":"Developing modules"},{"location":"tide/sites-sections/","text":"Sites and sections \u00b6 Content Repository supports multi-site and multi-section content publishing. This means that a content piece may be re-used several times on multiple sites and sections ( sections belong to sites ). Tide Site module provides an ability for Editor to publish content to selected sites and sections . How it works \u00b6 Sites and sections defined in a single vocabulary Sites with the maximum depth of 1, making root-level terms to become sites and terms of depth level 1 to become sections . The module has code to provide back-end validation to prevent creating of terms with depth more than 1. We decided to use Drupal taxonomy for sites and sections for multiple reasons: Taxonomy terms are fieldable entities. This means that Frontend Websites can extend per-site properties as required, exposing them to the API. Taxonomy terms support hierarchy, which helps to define site-section relationship, and, as a result of this, easily filter associated content by site. Taxonomy terms can be selected in UI using one of the existing contributed widgets. Taxonomy terms have full Token and Pathauto support, which makes it easy to use them for building content URLs based on IA. Taxonomy terms have full JSONAPI support and can be queried by Frontend Websites in the same way as any other entities. The concept of using taxonomy terms to group content is easy to understand. The concept of using taxonomy terms to store per-site settings is easy to understand. Content may be shared between sites, but never between sections, as this would lead to the same content being served from different URLs, which is highly discouraged by search engines. Primary site To mitigate the problem when the same content is shared between different websites, a selection of Primary site is required, which will be used to generate canonical URL for the content piece. As a result, every content type has 2 fields created automatically: site and primary_site . Both fields are compulsory. Editors are expected to select destination site and section for each content piece. Site and Section Fields \u00b6 To provide site and section-specific information through API, every Site taxonomy term has a set of the following information fields: Field Description Domains Multiline plain text field to specify site domains. This is used by Ripple to match on the domain where the request is coming from. One domain per line. Wildcards supported. Title Text field to specify site title. Slogan Text field to specify site slogan. Logo File field to upload site logo. Footer message Text field with WYSIWYG support to specify site footer message. Main Menu Per-site and per-section menus may be helpful to build section-based navigation experience. Site admins may associate existing or create new menu with every site term. This is an entity reference field. Footer Menu Per-site and per-section menus may be helpful to build section-based navigation experience. Site admins may associate existing or create new menu with every site term. This is an entity reference field. Note Since Frontend Websites information is stored using fieldsable taxonomy terms, it is possible to add more fields to capture site information in the Content Repository. The data stored in these fields will become automatically exposed through API. Site menus \u00b6 Per-site and per-section menus may be helpful to build section-based navigation experience. They allow to provide custom menu items for specific sites and sections. Site menus automatically created when a new Site taxonomy term is created. Basically, instead of creating a site and then manually creating a menu on the separate screen, we automatically create and assign a menu for each site within the site creation screen by checking relevant checkbox on Site term ctreation page. Expand for Site menu creation flow diagram Multi-site URL rendering \u00b6 When content piece belongs to multiple sites or sections, it may have links to it from other content pieces of the current domain or other domains. Drupal has to render these links with correct domains as a part of url, so that Frontend Websites could output these links as-is. Example of multi-site URL rendering For example, if we have: 2 sites first.com and second.com 2 pages page1 and page2 page1 has a link to page2 page1 belongs to first.com page2 belongs to both first.com and second.com ; the primary site is set to second.com When the visitor is on the page first.com/page1 and follows the link /page2 she should end up on first.com/page2 and not second.com/page2 . This is because she is currently on first.com domain and continues browsing the same domain. And if the visitor comes from Google search to page2 , she should end up at second.com/page2 , because second.com is a primary site for page2 . This is just an example of the part of the problem. There are more use-cases and they are explained below. For content exposed through API, the links may come from different places and we need to be able to extract internal entity id: For link fields, this should be fairly straightforward: the user enters the link and we have an internal entity id. For links entered in WYSIWYG, we need to use the LinkIt module so that we can extract an internal entity id. For links entered in WYSIWYG within referenced entities (for example, field on the paragraph belonging to the page) the API output will contains the path alias. For all links presented to the user: Internal links should be rendered as a relative path. If the link is to a page available on the current site, either primary or not, render as a relative link. External links (including links to other sites/section) should be rendered with an absolute path. For links within WYSIWYG, Drupal has to extract, analyse and replace links before rendering it through API. For this, we use an enhancer (special piece of code to manipulate content output before it is rendered through API) to scrape the content, then render the relevant link. Implementation details The content is extracted from the raw contents of WYSIWYG filed using Link Extractor . Link Extractor scans HTML and extracts all links. This happens before Drupal sanitizes WYSIWYG field output. Every extracted link is then passed to a Link Resolver . Link Resolver takes node id, loads up the path alias using some complex logic (see diagram below) and then swaps it within the href . Resolved URL is then passed to Link Replacer . Link Replacer replaces old extracted links with new resolved ones within contents of the WYSIWYG field. The processsed field contents is then passed to API for normal rendering as JSONAPI response. For links coming from Link fields, the above applies, but starting from Link Resolver (there is no HTML to extarct teh link from , so Link Extractor is not required). The following diagram describes URL processing and link resolution in detail.","title":"Sites and sections"},{"location":"tide/sites-sections/#sites-and-sections","text":"Content Repository supports multi-site and multi-section content publishing. This means that a content piece may be re-used several times on multiple sites and sections ( sections belong to sites ). Tide Site module provides an ability for Editor to publish content to selected sites and sections .","title":"Sites and sections"},{"location":"tide/sites-sections/#how-it-works","text":"Sites and sections defined in a single vocabulary Sites with the maximum depth of 1, making root-level terms to become sites and terms of depth level 1 to become sections . The module has code to provide back-end validation to prevent creating of terms with depth more than 1. We decided to use Drupal taxonomy for sites and sections for multiple reasons: Taxonomy terms are fieldable entities. This means that Frontend Websites can extend per-site properties as required, exposing them to the API. Taxonomy terms support hierarchy, which helps to define site-section relationship, and, as a result of this, easily filter associated content by site. Taxonomy terms can be selected in UI using one of the existing contributed widgets. Taxonomy terms have full Token and Pathauto support, which makes it easy to use them for building content URLs based on IA. Taxonomy terms have full JSONAPI support and can be queried by Frontend Websites in the same way as any other entities. The concept of using taxonomy terms to group content is easy to understand. The concept of using taxonomy terms to store per-site settings is easy to understand. Content may be shared between sites, but never between sections, as this would lead to the same content being served from different URLs, which is highly discouraged by search engines.","title":"How it works"},{"location":"tide/sites-sections/#site-and-section-fields","text":"To provide site and section-specific information through API, every Site taxonomy term has a set of the following information fields: Field Description Domains Multiline plain text field to specify site domains. This is used by Ripple to match on the domain where the request is coming from. One domain per line. Wildcards supported. Title Text field to specify site title. Slogan Text field to specify site slogan. Logo File field to upload site logo. Footer message Text field with WYSIWYG support to specify site footer message. Main Menu Per-site and per-section menus may be helpful to build section-based navigation experience. Site admins may associate existing or create new menu with every site term. This is an entity reference field. Footer Menu Per-site and per-section menus may be helpful to build section-based navigation experience. Site admins may associate existing or create new menu with every site term. This is an entity reference field. Note Since Frontend Websites information is stored using fieldsable taxonomy terms, it is possible to add more fields to capture site information in the Content Repository. The data stored in these fields will become automatically exposed through API.","title":"Site and Section Fields"},{"location":"tide/sites-sections/#site-menus","text":"Per-site and per-section menus may be helpful to build section-based navigation experience. They allow to provide custom menu items for specific sites and sections. Site menus automatically created when a new Site taxonomy term is created. Basically, instead of creating a site and then manually creating a menu on the separate screen, we automatically create and assign a menu for each site within the site creation screen by checking relevant checkbox on Site term ctreation page. Expand for Site menu creation flow diagram","title":"Site menus"},{"location":"tide/sites-sections/#multi-site-url-rendering","text":"When content piece belongs to multiple sites or sections, it may have links to it from other content pieces of the current domain or other domains. Drupal has to render these links with correct domains as a part of url, so that Frontend Websites could output these links as-is. Example of multi-site URL rendering For example, if we have: 2 sites first.com and second.com 2 pages page1 and page2 page1 has a link to page2 page1 belongs to first.com page2 belongs to both first.com and second.com ; the primary site is set to second.com When the visitor is on the page first.com/page1 and follows the link /page2 she should end up on first.com/page2 and not second.com/page2 . This is because she is currently on first.com domain and continues browsing the same domain. And if the visitor comes from Google search to page2 , she should end up at second.com/page2 , because second.com is a primary site for page2 . This is just an example of the part of the problem. There are more use-cases and they are explained below. For content exposed through API, the links may come from different places and we need to be able to extract internal entity id: For link fields, this should be fairly straightforward: the user enters the link and we have an internal entity id. For links entered in WYSIWYG, we need to use the LinkIt module so that we can extract an internal entity id. For links entered in WYSIWYG within referenced entities (for example, field on the paragraph belonging to the page) the API output will contains the path alias. For all links presented to the user: Internal links should be rendered as a relative path. If the link is to a page available on the current site, either primary or not, render as a relative link. External links (including links to other sites/section) should be rendered with an absolute path. For links within WYSIWYG, Drupal has to extract, analyse and replace links before rendering it through API. For this, we use an enhancer (special piece of code to manipulate content output before it is rendered through API) to scrape the content, then render the relevant link. Implementation details The content is extracted from the raw contents of WYSIWYG filed using Link Extractor . Link Extractor scans HTML and extracts all links. This happens before Drupal sanitizes WYSIWYG field output. Every extracted link is then passed to a Link Resolver . Link Resolver takes node id, loads up the path alias using some complex logic (see diagram below) and then swaps it within the href . Resolved URL is then passed to Link Replacer . Link Replacer replaces old extracted links with new resolved ones within contents of the WYSIWYG field. The processsed field contents is then passed to API for normal rendering as JSONAPI response. For links coming from Link fields, the above applies, but starting from Link Resolver (there is no HTML to extarct teh link from , so Link Extractor is not required). The following diagram describes URL processing and link resolution in detail.","title":"Multi-site URL rendering"}]}