{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What Single Digital Presence offers \u00b6 Warning Your are viewing a version of the documentation that is currently being developed. Some of the sections are missing or incomplete. The documentation will be versioned once it is ready. Please come back later. Single Digital Presence (SDP) is an open, flexible technical solution that government agencies can use to reduce the cost and effort of digital development. SDP is about making it easier for citizens to find, understand and use Victorian Government information. SDP is a project of the Digital Design and Innovation branch at the Department of Premier and Cabinet. Benefits of SDP \u00b6 Get more done for less Spend money on innovation instead of duplication Increases collaboration across agencies and beyond Continuous improvement Secure, supported Easy to use and administer Write once, share everywhere About SDP products \u00b6 SDP offers three products that can be used independently, or as a package: Bay is the infrastructure and hosting layer. Tide is the distribution layer. Ripple is the front-end presentation layer.","title":"About"},{"location":"#what-single-digital-presence-offers","text":"Warning Your are viewing a version of the documentation that is currently being developed. Some of the sections are missing or incomplete. The documentation will be versioned once it is ready. Please come back later. Single Digital Presence (SDP) is an open, flexible technical solution that government agencies can use to reduce the cost and effort of digital development. SDP is about making it easier for citizens to find, understand and use Victorian Government information. SDP is a project of the Digital Design and Innovation branch at the Department of Premier and Cabinet.","title":"What Single Digital Presence offers"},{"location":"#benefits-of-sdp","text":"Get more done for less Spend money on innovation instead of duplication Increases collaboration across agencies and beyond Continuous improvement Secure, supported Easy to use and administer Write once, share everywhere","title":"Benefits of SDP"},{"location":"#about-sdp-products","text":"SDP offers three products that can be used independently, or as a package: Bay is the infrastructure and hosting layer. Tide is the distribution layer. Ripple is the front-end presentation layer.","title":"About SDP products"},{"location":"architecture/","text":"Architecture \u00b6 Single Digital Presence is a distribution that consists of content repository with exposed API (headless Drupal distribution called Tide ) and a front-end components library ( Vue.js with Nuxt server rendering framework called Ripple ) hosted on the latest generation hosting platform ( Kubernetes -based Docker container platform called Bay ). Note The two main requirements that have significant affect on the architecture were: Content sharing across multiple sites. Content syndication via API. Content Sharing is a common issue amongst larger organisation, however the solutions are highly complex and the publicly available options are not mature enough for immediate use. Application system components \u00b6 At the application layer, there are 2 main components of the system: Tide - Drupal 8 headless distribution that serves as a content repository. Ripple - Vue.js-based library of front-end components. Each instance of Ripple serves as a standalone front-end application for a website. System components inheritance \u00b6 There are 3 layer of components in the Distribution. The features provided by every layer contribute to a final particular website feature set. Each of the layers is owned, supported and maintained by a distinct community: - Open Source - provides Drupal core and contributed modules. It is maintained by a worldwide Drupal community. - Distribution - provides content types, multi-channel and API features. It is maintained by SDP development team. - Specific website - provides unique site features and design components. It is maintained by a particular website development team. See Tide and Ripple for more information about architecture. Content Sharing \u00b6 Content Editors author content and select content sharing targets (semi-independent sites and site sections) for each content piece. Drupal will then serve this content as data through API to each front-end consumer site, implemented as a separate front-end application. Content repository site has only a basic frontend and its IP restricted to a list of allowed IP addresses, so that content editors from designated offices could access the editorial interface. The API endpoints for the content repository site are accessible to the world over the same predefined domain (e.g., https://api.agency.gov.au ). There is no authentication for content consumers. All content editing for all sites is performed through the central content repository instance (e.g. https://content.agency.gov.au ). There are no restrictions for editing content between the various sites, allowing content editors to be used across sites to better utilise limited resources. Content Approvals are still restricted to ensure content is only published upon approval by relevant users. This ensures cross site changes do not go public without proper approval. All content changes are tracked, so users making changes to the wrong site can receive further training to prevent future mistakes.","title":"Architecture"},{"location":"architecture/#architecture","text":"Single Digital Presence is a distribution that consists of content repository with exposed API (headless Drupal distribution called Tide ) and a front-end components library ( Vue.js with Nuxt server rendering framework called Ripple ) hosted on the latest generation hosting platform ( Kubernetes -based Docker container platform called Bay ). Note The two main requirements that have significant affect on the architecture were: Content sharing across multiple sites. Content syndication via API. Content Sharing is a common issue amongst larger organisation, however the solutions are highly complex and the publicly available options are not mature enough for immediate use.","title":"Architecture"},{"location":"architecture/#application-system-components","text":"At the application layer, there are 2 main components of the system: Tide - Drupal 8 headless distribution that serves as a content repository. Ripple - Vue.js-based library of front-end components. Each instance of Ripple serves as a standalone front-end application for a website.","title":"Application system components"},{"location":"architecture/#system-components-inheritance","text":"There are 3 layer of components in the Distribution. The features provided by every layer contribute to a final particular website feature set. Each of the layers is owned, supported and maintained by a distinct community: - Open Source - provides Drupal core and contributed modules. It is maintained by a worldwide Drupal community. - Distribution - provides content types, multi-channel and API features. It is maintained by SDP development team. - Specific website - provides unique site features and design components. It is maintained by a particular website development team. See Tide and Ripple for more information about architecture.","title":"System components inheritance"},{"location":"architecture/#content-sharing","text":"Content Editors author content and select content sharing targets (semi-independent sites and site sections) for each content piece. Drupal will then serve this content as data through API to each front-end consumer site, implemented as a separate front-end application. Content repository site has only a basic frontend and its IP restricted to a list of allowed IP addresses, so that content editors from designated offices could access the editorial interface. The API endpoints for the content repository site are accessible to the world over the same predefined domain (e.g., https://api.agency.gov.au ). There is no authentication for content consumers. All content editing for all sites is performed through the central content repository instance (e.g. https://content.agency.gov.au ). There are no restrictions for editing content between the various sites, allowing content editors to be used across sites to better utilise limited resources. Content Approvals are still restricted to ensure content is only published upon approval by relevant users. This ensures cross site changes do not go public without proper approval. All content changes are tracked, so users making changes to the wrong site can receive further training to prevent future mistakes.","title":"Content Sharing"},{"location":"overview/","text":"Overview \u00b6 SDP project covers implementing a Drupal distribution to build a Content Store site containing site sections and providing content for semi-independent sites. It also covers providing of technical implementation to build fully independent sites. Info Example of Content Store site is https://vic.gov.au , which has site-sections such as Aboriginal Victoria or Family Violence. Semi-independent sites are the other sites that have their content centrally managed. An example of such site is the Office of the Victorian Government Architect site. Fully independent sites are completely separate installations of the whole distribution. Project goals \u00b6 Making it easier to find, understand and use Victorian Government information Bringing 50 websites onto one platform and providing a consistent user experience Simplifying and standardising publishing Providing user research and a user first approach Reducing cost Increasing security Benefits \u00b6 More consistent UX Improved Admin Interface Improved Security and Improvement process Cheaper, more scalable and performant hosting Cost savings across Govt Better Government (and community) collaboration Better Developer Experience","title":"Overview"},{"location":"overview/#overview","text":"SDP project covers implementing a Drupal distribution to build a Content Store site containing site sections and providing content for semi-independent sites. It also covers providing of technical implementation to build fully independent sites. Info Example of Content Store site is https://vic.gov.au , which has site-sections such as Aboriginal Victoria or Family Violence. Semi-independent sites are the other sites that have their content centrally managed. An example of such site is the Office of the Victorian Government Architect site. Fully independent sites are completely separate installations of the whole distribution.","title":"Overview"},{"location":"overview/#project-goals","text":"Making it easier to find, understand and use Victorian Government information Bringing 50 websites onto one platform and providing a consistent user experience Simplifying and standardising publishing Providing user research and a user first approach Reducing cost Increasing security","title":"Project goals"},{"location":"overview/#benefits","text":"More consistent UX Improved Admin Interface Improved Security and Improvement process Cheaper, more scalable and performant hosting Cost savings across Govt Better Government (and community) collaboration Better Developer Experience","title":"Benefits"},{"location":"terminology/","text":"Terminology \u00b6 Atomic design \u00b6 Atomic design is methodology for creating design systems. There are five distinct levels in atomic design: Atoms Molecules Organisms Templates Pages Bay \u00b6 Bay is a fully managed platform and hosting environment that provides an open Platform as a Service model managed by SDP. It: - is an open-source hosting platform based on Lagoon. - allows agencies to build, test and deliver websites via the cloud. Component \u00b6 A UI pattern library is simply a place where all of these components live together. ... UI pattern libraries can be part of a wider design system. Material design is an example of a design system. It doesn't just include UI patterns but other elements that help designers and developers such a style guidelines.Jul 24, 2018 Drupal \u00b6 Drupal is free, open source software that can be used by individuals or groups of users to easily create and manage many types of Web sites. The application includes a content management platform and a development framework. Git \u00b6 Git is a distributed version-control system for tracking changes in source code during software development.It is designed for coordinating work among programmers, but it can be used to track changes in any set of files. GitHub \u00b6 GitHub is a Git repository hosting service, but it adds many of its own features. While Git is a command line tool, GitHub provides a Web-based graphical interface. It also provides access control and several collaboration features, such as a wikis and basic task management tools for every project. Nuxt \u00b6 Nuxt.js is a framework that helps to build server-rendered Vue.js applications easily. It abstracts most of the complex configuration involved in managing things like asynchronous data, middleware, and routing. It's similar to Angular Universal for Angular, and Next.js for React. Pull-request, PR \u00b6 Pull requests let you tell others about changes you've pushed to a GitHub repository. Once a pull request is sent, interested parties can review the set of changes, discuss potential modifications, and even push follow-up commits if necessary. Ripple \u00b6 Ripple offers a consistent design system, making it easier for citizens to find, understand and use Victorian Government information maintained by SDP. It: - is fully open and includes a library of reusable components, based on atomic pattern design. - uses Vue.js and Nuxt to deliver a consistent look and feel across government websites. - includes a starter kit for agencies. SDP \u00b6 Single Digital Presence is an open, flexible technical solution that government agencies can use to reduce the cost and effort of digital development. Storybook \u00b6 The Ripple Pattern Library shows how to use the design components for SDP. Tide \u00b6 Tide is an API first, headless content management system using Drupal 8 and maintained by SDP. Custom built to meet Victorian Government requirements, it offers: - multi-site content distribution - pick and mix features - centralised feature governance Vue.js \u00b6 Vue is a progressive framework for building user interfaces. Unlike other monolithic frameworks, Vue is designed from the ground up to be incrementally adoptable.","title":"Terminology"},{"location":"terminology/#terminology","text":"","title":"Terminology"},{"location":"terminology/#atomic-design","text":"Atomic design is methodology for creating design systems. There are five distinct levels in atomic design: Atoms Molecules Organisms Templates Pages","title":"Atomic design"},{"location":"terminology/#bay","text":"Bay is a fully managed platform and hosting environment that provides an open Platform as a Service model managed by SDP. It: - is an open-source hosting platform based on Lagoon. - allows agencies to build, test and deliver websites via the cloud.","title":"Bay"},{"location":"terminology/#component","text":"A UI pattern library is simply a place where all of these components live together. ... UI pattern libraries can be part of a wider design system. Material design is an example of a design system. It doesn't just include UI patterns but other elements that help designers and developers such a style guidelines.Jul 24, 2018","title":"Component"},{"location":"terminology/#drupal","text":"Drupal is free, open source software that can be used by individuals or groups of users to easily create and manage many types of Web sites. The application includes a content management platform and a development framework.","title":"Drupal"},{"location":"terminology/#git","text":"Git is a distributed version-control system for tracking changes in source code during software development.It is designed for coordinating work among programmers, but it can be used to track changes in any set of files.","title":"Git"},{"location":"terminology/#github","text":"GitHub is a Git repository hosting service, but it adds many of its own features. While Git is a command line tool, GitHub provides a Web-based graphical interface. It also provides access control and several collaboration features, such as a wikis and basic task management tools for every project.","title":"GitHub"},{"location":"terminology/#nuxt","text":"Nuxt.js is a framework that helps to build server-rendered Vue.js applications easily. It abstracts most of the complex configuration involved in managing things like asynchronous data, middleware, and routing. It's similar to Angular Universal for Angular, and Next.js for React.","title":"Nuxt"},{"location":"terminology/#pull-request-pr","text":"Pull requests let you tell others about changes you've pushed to a GitHub repository. Once a pull request is sent, interested parties can review the set of changes, discuss potential modifications, and even push follow-up commits if necessary.","title":"Pull-request, PR"},{"location":"terminology/#ripple","text":"Ripple offers a consistent design system, making it easier for citizens to find, understand and use Victorian Government information maintained by SDP. It: - is fully open and includes a library of reusable components, based on atomic pattern design. - uses Vue.js and Nuxt to deliver a consistent look and feel across government websites. - includes a starter kit for agencies.","title":"Ripple"},{"location":"terminology/#sdp","text":"Single Digital Presence is an open, flexible technical solution that government agencies can use to reduce the cost and effort of digital development.","title":"SDP"},{"location":"terminology/#storybook","text":"The Ripple Pattern Library shows how to use the design components for SDP.","title":"Storybook"},{"location":"terminology/#tide","text":"Tide is an API first, headless content management system using Drupal 8 and maintained by SDP. Custom built to meet Victorian Government requirements, it offers: - multi-site content distribution - pick and mix features - centralised feature governance","title":"Tide"},{"location":"terminology/#vuejs","text":"Vue is a progressive framework for building user interfaces. Unlike other monolithic frameworks, Vue is designed from the ground up to be incrementally adoptable.","title":"Vue.js"},{"location":"assets/README.module/","text":"name \u00b6 name content type for Tide distribution for Drupal 8 Tide is a Drupal 8 distribution focused on delivering an API first, headless Drupal content administration site. What is in this package \u00b6 content type fields blocks views JSONAPI module integration Installation \u00b6 To install this package, add this custom repository to repositories section of your composer.json : { \"repositories\" : { \"dpc-sdp/tide_page\" : { \"type\" : \"vcs\" , \"no-api\" : true , \"url\" : \"https://github.com/dpc-sdp/_machine_name_.git\" } } } Require this package as any other Composer package: composer require dpc/_machine_name_ Support \u00b6 Digital Engagement, Department of Premier and Cabinet, Victoria, Australia is a maintainer of this package. Contribute \u00b6 Open an issue on GitHub or submit a pull request with suggested changes. Development and maintenance \u00b6 Development is powered by Dev-Tools . Please refer to Dev-Tools' page for system requirements and other details. To start local development stack: 1. Checkout this project 2. Run ./dev-tools.sh 3. Run ahoy build Related projects \u00b6 tide tide_api tide_core tide_event tide_landing_page tide_media tide_monsido tide_news tide_page tide_search tide_site tide_test tide_webform License \u00b6 This project is licensed under GPL2","title":"_name_"},{"location":"assets/README.module/#name","text":"name content type for Tide distribution for Drupal 8 Tide is a Drupal 8 distribution focused on delivering an API first, headless Drupal content administration site.","title":"name"},{"location":"assets/README.module/#what-is-in-this-package","text":"content type fields blocks views JSONAPI module integration","title":"What is in this package"},{"location":"assets/README.module/#installation","text":"To install this package, add this custom repository to repositories section of your composer.json : { \"repositories\" : { \"dpc-sdp/tide_page\" : { \"type\" : \"vcs\" , \"no-api\" : true , \"url\" : \"https://github.com/dpc-sdp/_machine_name_.git\" } } } Require this package as any other Composer package: composer require dpc/_machine_name_","title":"Installation"},{"location":"assets/README.module/#support","text":"Digital Engagement, Department of Premier and Cabinet, Victoria, Australia is a maintainer of this package.","title":"Support"},{"location":"assets/README.module/#contribute","text":"Open an issue on GitHub or submit a pull request with suggested changes.","title":"Contribute"},{"location":"assets/README.module/#development-and-maintenance","text":"Development is powered by Dev-Tools . Please refer to Dev-Tools' page for system requirements and other details. To start local development stack: 1. Checkout this project 2. Run ./dev-tools.sh 3. Run ahoy build","title":"Development and maintenance"},{"location":"assets/README.module/#related-projects","text":"tide tide_api tide_core tide_event tide_landing_page tide_media tide_monsido tide_news tide_page tide_search tide_site tide_test tide_webform","title":"Related projects"},{"location":"assets/README.module/#license","text":"This project is licensed under GPL2","title":"License"},{"location":"assets/README.site/","text":"name \u00b6 Drupal 8 implementation of Content API for_name_ Prerequisites \u00b6 Make sure that you have latest versions of all required software installed: Docker Pygmy Ahoy Make sure that all local web development services are shut down ( apache/nginx , mysql , MAMP etc). Local environment setup \u00b6 curl https://raw.githubusercontent.com/dpc-sdp/dev-tools/master/install | bash pygmy up ahoy build Local URL -- http:// machine_name .docker.amazee.io/ Available ahoy commands \u00b6 Run each command as ahoy <command> . build Build or rebuild project. clean Remove all build files. clean-full Remove all development files. cli Start a shell inside CLI container or run a command. composer-merge Merge composer files. deploy Deploy or re-deploy a branch in Bay. doctor Identify problems with current stack. down Stop Docker containers and remove container, images, volumes and networks. drush Run drush commands in the CLI service container. flush-redis Flush Redis cache. info Print information about this project. install-dev Install dependencies. install-site Install site. lint Lint code. login Login to a website. logs Show Docker logs. pull Pull latest docker images. restart Restart all stopped and running Docker containers. start Start existing Docker containers. stop Stop running Docker containers. test-behat Run Behat tests. up Build and start Docker containers. SSHing into CLI container \u00b6 ahoy cli Running a command in CLI container \u00b6 ahoy cli ls /app Mailhog. \u00b6 Mailhog is included with pygmy and is available @ http://mailhog.docker.amazee.io/ Documentation for mailhog is available of the project page -- https://github.com/mailhog/MailHog Stage file proxy. \u00b6 Stage File Proxy is enabled on all non production environments so files are automatically downloaded directly from prod on demand. Adding Drupal modules \u00b6 Modules needs to be added in 2 steps: 1. Require module code installation (through composer). 2. Enable module during site installation. Adding contrib modules composer require drupal/module_name or for specific versions composer require drupal/module_name:1.2 Adding modules as local packages Add local package information to the root of composer.json : \"repositories\": { \"dpc-sdp/tide_page\": { \"type\": \"path\", \"url\": \"dpc-sdp/tide_page\" }, } composer require tide_page To make sure that Composer triggers dependency tree rebuild, run ahoy clean . Run composer update --lock . This will install all dependencies and update root composer.lock file with newly added module. Adding patches for composer packages \u00b6 Add title and url to patch on drupal.org to the patches array in extra section in composer.json . \"extra\": { \"patches\": { \"drupal/core\": { \"Contextual links should not be added inside another link - https://www.drupal.org/node/2898875\": \"https://www.drupal.org/files/issues/contextual_links_should-2898875-3.patch\" } } } composer update --lock Coding standards \u00b6 PHP and JS code linting uses PHP_CodeSniffer with Drupal rules from Coder module and additional local overrides in phpcs.xml.dist and .eslintrc . Behat tests \u00b6 Behat configuration uses multiple extensions: - Drupal Behat Extension - Drupal integration layer. Allows to work with Drupal API from within step definitions. - Behat Screenshot Extension - Behat extension and a step definition to create HTML and image screenshots on demand or test fail. - Behat Progress Fail Output Extension - Behat output formatter to show progress as TAP and fail messages inline. Useful to get feedback about failed tests while continuing test run. - YoursiteDrupalContext - Site-specific Drupal context with custom step definitions. - YoursiteMinkContext - Site-specific Mink context with custom step definitions. Generic Behat tests should be written against the test entities from the Tide Test module. If a new test entity (node, block, etc.) is added to the Tide Test module, the relevant permissions must be also granted to Approver and Editor via the hook tide_test_entity_bundle_create() . Run tests locally: Run Behat tests: ahoy test-behat Run specific test feature: ahoy test-behat tests/behat/features/homepage.feature Run specific test tag: ahoy test-behat -- --tags=wip Automated builds (Continuous Integration) \u00b6 In software engineering, continuous integration (CI) is the practice of merging all developer working copies to a shared mainline several times a day. Before feature changes can be merged into a shared mainline, a complete build must run and pass all tests on CI server. This project uses Circle CI as CI server: it imports production backups into fully built codebase and runs code linting and tests. When tests pass, a deployment process is triggered for nominated branches (usually, master and develop ). Add [skip ci] to the commit subject to skip CI build. Useful for documentation changes. SSH Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. Test artifacts Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI. Debugging \u00b6 PHP application from browser Trigger xDebug from web browser (using one of the browser extensions) so that PHPStorm recognises the server yoursite.docker.amazee.io and configures the path mapping. Alternatively, you can create the server in PHPStorm Settings. Make sure serverName to be yoursite.docker.amazee.io PHP scripts ahoy cli xdebug.sh path/to/script For example, to run a single Behat test: xdebug.sh vendor/bin/behat path/to/test.feature Drush commands ahoy cli `./xdebug.sh vendor/bin/drush <DRUSH_COMMAND> DB connection details Run ahoy info to get the port number. Host: 127.0.0.1 Username: drupal Password: drupal Database: drupal Port: <get from \"ahoy info\">","title":"_name_"},{"location":"assets/README.site/#name","text":"Drupal 8 implementation of Content API for_name_","title":"name"},{"location":"assets/README.site/#prerequisites","text":"Make sure that you have latest versions of all required software installed: Docker Pygmy Ahoy Make sure that all local web development services are shut down ( apache/nginx , mysql , MAMP etc).","title":"Prerequisites"},{"location":"assets/README.site/#local-environment-setup","text":"curl https://raw.githubusercontent.com/dpc-sdp/dev-tools/master/install | bash pygmy up ahoy build Local URL -- http:// machine_name .docker.amazee.io/","title":"Local environment setup"},{"location":"assets/README.site/#available-ahoy-commands","text":"Run each command as ahoy <command> . build Build or rebuild project. clean Remove all build files. clean-full Remove all development files. cli Start a shell inside CLI container or run a command. composer-merge Merge composer files. deploy Deploy or re-deploy a branch in Bay. doctor Identify problems with current stack. down Stop Docker containers and remove container, images, volumes and networks. drush Run drush commands in the CLI service container. flush-redis Flush Redis cache. info Print information about this project. install-dev Install dependencies. install-site Install site. lint Lint code. login Login to a website. logs Show Docker logs. pull Pull latest docker images. restart Restart all stopped and running Docker containers. start Start existing Docker containers. stop Stop running Docker containers. test-behat Run Behat tests. up Build and start Docker containers.","title":"Available ahoy commands"},{"location":"assets/README.site/#sshing-into-cli-container","text":"ahoy cli","title":"SSHing into CLI container"},{"location":"assets/README.site/#running-a-command-in-cli-container","text":"ahoy cli ls /app","title":"Running a command in CLI container"},{"location":"assets/README.site/#mailhog","text":"Mailhog is included with pygmy and is available @ http://mailhog.docker.amazee.io/ Documentation for mailhog is available of the project page -- https://github.com/mailhog/MailHog","title":"Mailhog."},{"location":"assets/README.site/#stage-file-proxy","text":"Stage File Proxy is enabled on all non production environments so files are automatically downloaded directly from prod on demand.","title":"Stage file proxy."},{"location":"assets/README.site/#adding-drupal-modules","text":"Modules needs to be added in 2 steps: 1. Require module code installation (through composer). 2. Enable module during site installation.","title":"Adding Drupal modules"},{"location":"assets/README.site/#adding-patches-for-composer-packages","text":"Add title and url to patch on drupal.org to the patches array in extra section in composer.json . \"extra\": { \"patches\": { \"drupal/core\": { \"Contextual links should not be added inside another link - https://www.drupal.org/node/2898875\": \"https://www.drupal.org/files/issues/contextual_links_should-2898875-3.patch\" } } } composer update --lock","title":"Adding patches for composer packages"},{"location":"assets/README.site/#coding-standards","text":"PHP and JS code linting uses PHP_CodeSniffer with Drupal rules from Coder module and additional local overrides in phpcs.xml.dist and .eslintrc .","title":"Coding standards"},{"location":"assets/README.site/#behat-tests","text":"Behat configuration uses multiple extensions: - Drupal Behat Extension - Drupal integration layer. Allows to work with Drupal API from within step definitions. - Behat Screenshot Extension - Behat extension and a step definition to create HTML and image screenshots on demand or test fail. - Behat Progress Fail Output Extension - Behat output formatter to show progress as TAP and fail messages inline. Useful to get feedback about failed tests while continuing test run. - YoursiteDrupalContext - Site-specific Drupal context with custom step definitions. - YoursiteMinkContext - Site-specific Mink context with custom step definitions. Generic Behat tests should be written against the test entities from the Tide Test module. If a new test entity (node, block, etc.) is added to the Tide Test module, the relevant permissions must be also granted to Approver and Editor via the hook tide_test_entity_bundle_create() .","title":"Behat tests"},{"location":"assets/README.site/#automated-builds-continuous-integration","text":"In software engineering, continuous integration (CI) is the practice of merging all developer working copies to a shared mainline several times a day. Before feature changes can be merged into a shared mainline, a complete build must run and pass all tests on CI server. This project uses Circle CI as CI server: it imports production backups into fully built codebase and runs code linting and tests. When tests pass, a deployment process is triggered for nominated branches (usually, master and develop ). Add [skip ci] to the commit subject to skip CI build. Useful for documentation changes.","title":"Automated builds (Continuous Integration)"},{"location":"assets/README.site/#debugging","text":"","title":"Debugging"},{"location":"bay/","text":"Bay \u00b6 Bay is a fully managed platform and hosting environment that provides an open Platform as a Service model managed by SDP. It: - is an open-source hosting platform based on Lagoon. - allows agencies to build, test and deliver websites via the cloud. Bay is a Kubernetes-based (OpenShift) Docker container hosting platform with auto-scaling, auto-recovery and high-availability at core. Bay is based on open-source project Lagoon . Quote Lagoon solves what developers are dreaming about: A system that allows developers to locally develop their code and their services with Docker and run the exact same system in production. The same Docker images, the same service configurations and the same code. The platform has several layers (from the bottom to the top): The AWS layer is how the platform is physically hosted. It is spread accross multiple data centers to allow auto-scaling, fault-tolerance and disaster recovery. The Kubernetes layer allows to automate deployment, scale, and manage containerized application. The OpenShift layer is a Kubernetes distribution with enterprise-grade features and support. The Bay layer is an orchestration tool used to bundle containers into projects and manage deployments. The Application layer is where Drupal, NodeJS and other types of application reside. Architecture overview \u00b6 An over-simplified Bay platform architecture overview: Requests coming from the Citizen to the load balancer and then get directed to the dedicated containers in specific data centre (not necessarily the same for all containers). These containers are provisioned, auto-scaled and auto-healed using Orchestration Tool Box. Developers have identical development stack installed locally. Automated builds in Continuous Integration servers use identical container images. In this way, all environments are running identical versions of languages, frameworks and libraries required for a particular website. Namespaces \u00b6 Docker vendor namespace: dpc_sdp Docker images namespace: * (service name) Repositories \u00b6 Bay source code: https://github.com/dpc-sdp/bay Quay: https://quay.io/organization/dpc_sdp","title":"Overview"},{"location":"bay/#bay","text":"Bay is a fully managed platform and hosting environment that provides an open Platform as a Service model managed by SDP. It: - is an open-source hosting platform based on Lagoon. - allows agencies to build, test and deliver websites via the cloud. Bay is a Kubernetes-based (OpenShift) Docker container hosting platform with auto-scaling, auto-recovery and high-availability at core. Bay is based on open-source project Lagoon . Quote Lagoon solves what developers are dreaming about: A system that allows developers to locally develop their code and their services with Docker and run the exact same system in production. The same Docker images, the same service configurations and the same code. The platform has several layers (from the bottom to the top): The AWS layer is how the platform is physically hosted. It is spread accross multiple data centers to allow auto-scaling, fault-tolerance and disaster recovery. The Kubernetes layer allows to automate deployment, scale, and manage containerized application. The OpenShift layer is a Kubernetes distribution with enterprise-grade features and support. The Bay layer is an orchestration tool used to bundle containers into projects and manage deployments. The Application layer is where Drupal, NodeJS and other types of application reside.","title":"Bay"},{"location":"bay/#architecture-overview","text":"An over-simplified Bay platform architecture overview: Requests coming from the Citizen to the load balancer and then get directed to the dedicated containers in specific data centre (not necessarily the same for all containers). These containers are provisioned, auto-scaled and auto-healed using Orchestration Tool Box. Developers have identical development stack installed locally. Automated builds in Continuous Integration servers use identical container images. In this way, all environments are running identical versions of languages, frameworks and libraries required for a particular website.","title":"Architecture overview"},{"location":"bay/#namespaces","text":"Docker vendor namespace: dpc_sdp Docker images namespace: * (service name)","title":"Namespaces"},{"location":"bay/#repositories","text":"Bay source code: https://github.com/dpc-sdp/bay Quay: https://quay.io/organization/dpc_sdp","title":"Repositories"},{"location":"bay/onboarding/","text":"Onboarding to Bay \u00b6 This chapter describes the process of onboarding to Bay: who to contact, what to provide, time frame.","title":"Onboarding"},{"location":"bay/onboarding/#onboarding-to-bay","text":"This chapter describes the process of onboarding to Bay: who to contact, what to provide, time frame.","title":"Onboarding to Bay"},{"location":"bay/preview-environments/","text":"Preview environments \u00b6 Preview (dynamic/temporary/disposable/ephemeral) environments are environments identical to production and created to test features or demo functionality. SDP Bay provides up to 10 preview environments for each site. New environments created automatically once pull-request is created in the GitHub repository. If messenger notifications enabled, a new message about deployment will be posted. Once pull request is closed, the environment automatically destroyed and all environment data is removed. If messenger notifications enabled, a new message about environment removal will be posted.","title":"Preview environments"},{"location":"bay/preview-environments/#preview-environments","text":"Preview (dynamic/temporary/disposable/ephemeral) environments are environments identical to production and created to test features or demo functionality. SDP Bay provides up to 10 preview environments for each site. New environments created automatically once pull-request is created in the GitHub repository. If messenger notifications enabled, a new message about deployment will be posted. Once pull request is closed, the environment automatically destroyed and all environment data is removed. If messenger notifications enabled, a new message about environment removal will be posted.","title":"Preview environments"},{"location":"development/","text":"Development Overview \u00b6 SDP provides development tools, standards and recommended workflow for efficient, effective and consisted development practice.","title":"Overview"},{"location":"development/#development-overview","text":"SDP provides development tools, standards and recommended workflow for efficient, effective and consisted development practice.","title":"Development Overview"},{"location":"development/accessibility/","text":"Accessibility requirements \u00b6 WCAG AA 2.0 Requirement \u00b6 All Victoria Government website must be at least WCAG AA 2.0 compliant. Victorian Government Accessibility Toolkit \u00b6 The accessibility toolkit is available to assist all agencies in ensuring their websites are compliant with the Victoria Government standards. Extra Requirements \u00b6 The aim for the SDP project is to go beyond the requirements and focus on ensuring the sites are truly user friendly for users with accessibility needs. The DTA has published a blog article about this topic, https://www.dta.gov.au/blog/Accessibility-going-beyond-the-guidelines/ . There is also a good presentation here on some of the things to think about when building for accessibility. Some steps that should be required either per ticket or at least for the UAT process are: Colour Contrast. Check colour contrast in a tool such as http://www.color-blindness.com/coblis-color-blindness-simulator/ Accessibility checker. Ensure the automated tests in Monsido have run over the new functionality. Keyboard only. Push the mouse away and try to operate the screen. You should be able to navigate with the keyboard only. Screen-reader only. Turn on a screen-reader such as NVDA or VoiceOver and turn off the screen (or look away). All essential content should be read out and you should be able to navigate the screen. Design Considerations \u00b6 High colour contrast is good for colour blind users; it also helps users view a website on a mobile when in bright sunlight. Text over images should be avoided where possible. Some things to consider: Can the text colour change? Can the Image change, thereby changing the colour contrast? Can a solid background colour be applied to the text to ensure visibility Content Considerations \u00b6 There are minimum requirements for WCAG compliance, however, if the users need is considered, the actual requirement should be more defined. alt and title text fields help people to understand visual elements without being able to see them. Read through this explanation from WebAIM , https://webaim.org/techniques/alttext/#context . alt and title text are required, however users should be able to override this when required. For example, purely decorative images that offer no useful content to the user should not have alt and title text and should be ignored by screen readers. https://www.w3.org/WAI/tutorials/images/decorative/ . Try to avoid just copying the title text into the alt text field. Videos should always have captions; look at the YouTube auto CC when using YouTube. When creating links, try to avoid content like 'Click here' or 'here'. A screen reader will read the link as something like \"Leaving list | visited link | here\". Better link text describes what the user will get to, visit the Governors website . Technical Implementation \u00b6 For images, alt and title text fields should be made mandatory. There must be the ability to override this when adding images that are decorative. alt and title attributes must always be present, even when they are blank. Ensure headings are hierarchical; try to always ensure that headings on a page will be read in order. Use aria-live on any dynamic sections. See https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/ARIA_Live_Regions .","title":"Accessibility"},{"location":"development/accessibility/#accessibility-requirements","text":"","title":"Accessibility requirements"},{"location":"development/accessibility/#wcag-aa-20-requirement","text":"All Victoria Government website must be at least WCAG AA 2.0 compliant.","title":"WCAG AA 2.0 Requirement"},{"location":"development/accessibility/#victorian-government-accessibility-toolkit","text":"The accessibility toolkit is available to assist all agencies in ensuring their websites are compliant with the Victoria Government standards.","title":"Victorian Government Accessibility Toolkit"},{"location":"development/accessibility/#extra-requirements","text":"The aim for the SDP project is to go beyond the requirements and focus on ensuring the sites are truly user friendly for users with accessibility needs. The DTA has published a blog article about this topic, https://www.dta.gov.au/blog/Accessibility-going-beyond-the-guidelines/ . There is also a good presentation here on some of the things to think about when building for accessibility. Some steps that should be required either per ticket or at least for the UAT process are: Colour Contrast. Check colour contrast in a tool such as http://www.color-blindness.com/coblis-color-blindness-simulator/ Accessibility checker. Ensure the automated tests in Monsido have run over the new functionality. Keyboard only. Push the mouse away and try to operate the screen. You should be able to navigate with the keyboard only. Screen-reader only. Turn on a screen-reader such as NVDA or VoiceOver and turn off the screen (or look away). All essential content should be read out and you should be able to navigate the screen.","title":"Extra Requirements"},{"location":"development/accessibility/#design-considerations","text":"High colour contrast is good for colour blind users; it also helps users view a website on a mobile when in bright sunlight. Text over images should be avoided where possible. Some things to consider: Can the text colour change? Can the Image change, thereby changing the colour contrast? Can a solid background colour be applied to the text to ensure visibility","title":"Design Considerations"},{"location":"development/accessibility/#content-considerations","text":"There are minimum requirements for WCAG compliance, however, if the users need is considered, the actual requirement should be more defined. alt and title text fields help people to understand visual elements without being able to see them. Read through this explanation from WebAIM , https://webaim.org/techniques/alttext/#context . alt and title text are required, however users should be able to override this when required. For example, purely decorative images that offer no useful content to the user should not have alt and title text and should be ignored by screen readers. https://www.w3.org/WAI/tutorials/images/decorative/ . Try to avoid just copying the title text into the alt text field. Videos should always have captions; look at the YouTube auto CC when using YouTube. When creating links, try to avoid content like 'Click here' or 'here'. A screen reader will read the link as something like \"Leaving list | visited link | here\". Better link text describes what the user will get to, visit the Governors website .","title":"Content Considerations"},{"location":"development/accessibility/#technical-implementation","text":"For images, alt and title text fields should be made mandatory. There must be the ability to override this when adding images that are decorative. alt and title attributes must always be present, even when they are blank. Ensure headings are hierarchical; try to always ensure that headings on a page will be read in order. Use aria-live on any dynamic sections. See https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/ARIA_Live_Regions .","title":"Technical Implementation"},{"location":"development/automated-builds/","text":"Automated builds \u00b6 SDP uses CircleCI for all automated build (CI) runs. Who are you? \u00b6 Depending on what you are working on, there are the following targets for automated builds: Tide distribution Ripple library Tide module Every site that uses Tide distribution Every site that uses Ripple components Tide distribution \u00b6 Check coding standards: PHP, JS, CSS. Build a distribution site from supplied composer.json file (dependencies are locked-in at specific versions). Run unit tests (PHPUnit), if any. Run behavioural tests (Behat), if any. Ripple library \u00b6 Check coding standards: JS, SCSS. Build a site from supplied package.json file (dependencies are locked-in at specific versions). Build Storybook site Run unit tests (Jest), if any. Tide module \u00b6 Check coding standards: PHP, JS, CSS. Install a generic site, add current module with dependencies and install it. This will make sure that all dependencies were installed correctly and the configuration import worked correctly. Install a generic site, add current module with dependencies, add optional modules and install it. This will make sure that not only all dependencies were installed correctly and the configuration import worked correctly, but also that optional modules do not have a conflicting configuration. Run unit tests (PHPUnit), if any. Run behavioural tests (Behat), if any. Every site that uses Tide distribution \u00b6 Check coding standards in custom site code for modules and themes: PHP, JS, SCSS/CSS. Build a site from supplied composer.json file (dependencies are locked in at specific versions) and production database. This builds the site which is identical to the production site before running tests. Run unit tests (PHPUnit), if any. Run behavioural tests (Behat), if any. Every site that uses Ripple distribution \u00b6 Check coding standards in custom site code: JS, SCSS. Build a site from supplied package.json file (dependencies are locked-in at specific versions). This builds the site which is identical to the production site before running tests. Build Storybook site Run unit tests (Jest), if any. Skipping CI builds \u00b6 Add [skip ci] to the commit subject to skip CI build. Useful for documentation changes. SSH in CI build \u00b6 Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. 1. Navigate to the job page 2. Click on the dropdown in the right top corner and select Rebuild with SSH . Test artifacts \u00b6 Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI.","title":"Automated builds"},{"location":"development/automated-builds/#automated-builds","text":"SDP uses CircleCI for all automated build (CI) runs.","title":"Automated builds"},{"location":"development/automated-builds/#who-are-you","text":"Depending on what you are working on, there are the following targets for automated builds: Tide distribution Ripple library Tide module Every site that uses Tide distribution Every site that uses Ripple components","title":"Who are you?"},{"location":"development/automated-builds/#tide-distribution","text":"Check coding standards: PHP, JS, CSS. Build a distribution site from supplied composer.json file (dependencies are locked-in at specific versions). Run unit tests (PHPUnit), if any. Run behavioural tests (Behat), if any.","title":"Tide distribution"},{"location":"development/automated-builds/#ripple-library","text":"Check coding standards: JS, SCSS. Build a site from supplied package.json file (dependencies are locked-in at specific versions). Build Storybook site Run unit tests (Jest), if any.","title":"Ripple library"},{"location":"development/automated-builds/#tide-module","text":"Check coding standards: PHP, JS, CSS. Install a generic site, add current module with dependencies and install it. This will make sure that all dependencies were installed correctly and the configuration import worked correctly. Install a generic site, add current module with dependencies, add optional modules and install it. This will make sure that not only all dependencies were installed correctly and the configuration import worked correctly, but also that optional modules do not have a conflicting configuration. Run unit tests (PHPUnit), if any. Run behavioural tests (Behat), if any.","title":"Tide module"},{"location":"development/automated-builds/#every-site-that-uses-tide-distribution","text":"Check coding standards in custom site code for modules and themes: PHP, JS, SCSS/CSS. Build a site from supplied composer.json file (dependencies are locked in at specific versions) and production database. This builds the site which is identical to the production site before running tests. Run unit tests (PHPUnit), if any. Run behavioural tests (Behat), if any.","title":"Every site that uses Tide distribution"},{"location":"development/automated-builds/#every-site-that-uses-ripple-distribution","text":"Check coding standards in custom site code: JS, SCSS. Build a site from supplied package.json file (dependencies are locked-in at specific versions). This builds the site which is identical to the production site before running tests. Build Storybook site Run unit tests (Jest), if any.","title":"Every site that uses Ripple distribution"},{"location":"development/automated-builds/#skipping-ci-builds","text":"Add [skip ci] to the commit subject to skip CI build. Useful for documentation changes.","title":"Skipping CI builds"},{"location":"development/automated-builds/#ssh-in-ci-build","text":"Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. 1. Navigate to the job page 2. Click on the dropdown in the right top corner and select Rebuild with SSH .","title":"SSH in CI build"},{"location":"development/automated-builds/#test-artifacts","text":"Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI.","title":"Test artifacts"},{"location":"development/back-end-coding-standards/","text":"Back-End Coding Standards \u00b6 PHP \u00b6 We use Drupal Coding Standards for all our contributed and custom modules. PHPCodeSniffer runs our code linting using rules from Drupal Coder module and additional customizations. See our the PHPCodeSniffer configuration file . Running locally ahoy lint Setting project coding standards in PHPStorm PHPStorm > Preferences > Code Style Select the appropriate language (in the example image below it is PHP ) Select the Set from... link Select Predefined Style > Drupal It is then possible to use the keyboard shortcut Alt + command + l to format a file or selection. Composer \u00b6 Alphabetise where possible This helps developers to visually scan code faster. Include information to make reviews easier Each patch attribute name should contain the title of the Drupal.org (d.o) issue, the link to the issue comment that contains the patch and the patch attribute value should be the patch file on drupal.org: \"drupal/project\" : { \"Issue title - https://www.drupal.org/node/1234567#12345678\" : \"https://www.drupal.org/files/issues/issue_title-1234567-2.patch\" } , Following this approach makes it simpler to follow up the status of patches during updates. Example of a properly formatted patches attribute: \"patches\" : { \"drupal/better_exposed_filters\" : { \"Add core/drupal as dependency to better_exposed_filters asset libraries - https://www.drupal.org/node/2902742\" : \"https://www.drupal.org/files/issues/add_core_drupal_as-2902742-2.patch\" }, \"drupal/core\" : { \"No validation on text length for menu description when editing node - https://www.drupal.org/node/2852665#comment-12157856\" : \"https://www.drupal.org/files/issues/fatal_error_remove_menu_add_with_tests-2852665-12.patch\" }, } ,","title":"Back-end coding standards"},{"location":"development/back-end-coding-standards/#back-end-coding-standards","text":"","title":"Back-End Coding Standards"},{"location":"development/back-end-coding-standards/#php","text":"We use Drupal Coding Standards for all our contributed and custom modules. PHPCodeSniffer runs our code linting using rules from Drupal Coder module and additional customizations. See our the PHPCodeSniffer configuration file .","title":"PHP"},{"location":"development/back-end-coding-standards/#composer","text":"Alphabetise where possible This helps developers to visually scan code faster. Include information to make reviews easier Each patch attribute name should contain the title of the Drupal.org (d.o) issue, the link to the issue comment that contains the patch and the patch attribute value should be the patch file on drupal.org: \"drupal/project\" : { \"Issue title - https://www.drupal.org/node/1234567#12345678\" : \"https://www.drupal.org/files/issues/issue_title-1234567-2.patch\" } , Following this approach makes it simpler to follow up the status of patches during updates. Example of a properly formatted patches attribute: \"patches\" : { \"drupal/better_exposed_filters\" : { \"Add core/drupal as dependency to better_exposed_filters asset libraries - https://www.drupal.org/node/2902742\" : \"https://www.drupal.org/files/issues/add_core_drupal_as-2902742-2.patch\" }, \"drupal/core\" : { \"No validation on text length for menu description when editing node - https://www.drupal.org/node/2852665#comment-12157856\" : \"https://www.drupal.org/files/issues/fatal_error_remove_menu_add_with_tests-2852665-12.patch\" }, } ,","title":"Composer"},{"location":"development/code-review/","text":"Code review \u00b6 Code review is a vital for effective and efficient collaboration of successful teams. Purpose \u00b6 Promote shared understanding of the codebase. Getting other people to look at code changes improves visibility and understanding of the way in which code works. It therefore helps protect against the loss of knowledge and productivity that can occur as developers come and go. Provide a different perspective on solutions. Coming with a fresh perspective and different experiences, the reviewer of code may think of possibilities that did not occur to the original developer. Improved code quality. The reviewer may notice issues with scalability, typos or other issues that might have slipped by the developer, but which may not cause errors or warnings visible to the end user. Questions to ask when reviewing code \u00b6 Is there enough commenting (or too much)? Is the code readable? Are the names of variables, functions, methods and classes clear and unambiguous? Are functions and class methods broken down to each fulfill one discrete requirement? Have unit tests been written? Has documentation been written / updated? Do comments in the code point to it and vice versa? Is an upgrade script needed? If so, does it run to completion and without an error? Are assumptions being made about the way the site will be used that might not be valid? For example, hard-coding http:// or https:// in URLs instead of check what protocol was used for the request and/or making the URL ambivalent (start with // ). Is code secure or does it avoid creating new vulnerabilities implementations for an existing functionality. Preparing code for code review \u00b6 Provide clear description about what, why and how has been changed. Provide screenshots, if applicable. Read your own code changes and add comments to parts that may raise questions. Provide a link to the issue tracker Assign relevant review developers. Assign yourself as an owner of the pull request. Read more about Mindful Communication in Code Reviews . Labels \u00b6 We advise to use labels on GitHub to help organise pull requests and issues. CONFLICT - pull request has a conflict that needs to be resolved before it can be merged. DO NOT MERGE - do not merge this pull request DO NOT REVIEW - do not review this pull request Needs review - a pull request needs a review from assigned developers Questions - a pull request has some questions that needs to be answered before further review can progress Ready for test - a pull request is ready for manual testing Ready to be merged - a pull request is ready to be merged (required for delayed feature delivery) Requires more work - a pull request was reviewed and reviewer(s) asked to work further on the pull request URGENT - a pull request needs to be urgently reviewed. An example of the pull request progression through labels: DO NOT REVIEW -> Needs review -> Ready for test -> Ready to be merged Use Github Labels script to automatically create consistent labels in your projects.","title":"Code review"},{"location":"development/code-review/#code-review","text":"Code review is a vital for effective and efficient collaboration of successful teams.","title":"Code review"},{"location":"development/code-review/#purpose","text":"Promote shared understanding of the codebase. Getting other people to look at code changes improves visibility and understanding of the way in which code works. It therefore helps protect against the loss of knowledge and productivity that can occur as developers come and go. Provide a different perspective on solutions. Coming with a fresh perspective and different experiences, the reviewer of code may think of possibilities that did not occur to the original developer. Improved code quality. The reviewer may notice issues with scalability, typos or other issues that might have slipped by the developer, but which may not cause errors or warnings visible to the end user.","title":"Purpose"},{"location":"development/code-review/#questions-to-ask-when-reviewing-code","text":"Is there enough commenting (or too much)? Is the code readable? Are the names of variables, functions, methods and classes clear and unambiguous? Are functions and class methods broken down to each fulfill one discrete requirement? Have unit tests been written? Has documentation been written / updated? Do comments in the code point to it and vice versa? Is an upgrade script needed? If so, does it run to completion and without an error? Are assumptions being made about the way the site will be used that might not be valid? For example, hard-coding http:// or https:// in URLs instead of check what protocol was used for the request and/or making the URL ambivalent (start with // ). Is code secure or does it avoid creating new vulnerabilities implementations for an existing functionality.","title":"Questions to ask when reviewing code"},{"location":"development/code-review/#preparing-code-for-code-review","text":"Provide clear description about what, why and how has been changed. Provide screenshots, if applicable. Read your own code changes and add comments to parts that may raise questions. Provide a link to the issue tracker Assign relevant review developers. Assign yourself as an owner of the pull request. Read more about Mindful Communication in Code Reviews .","title":"Preparing code for code review"},{"location":"development/code-review/#labels","text":"We advise to use labels on GitHub to help organise pull requests and issues. CONFLICT - pull request has a conflict that needs to be resolved before it can be merged. DO NOT MERGE - do not merge this pull request DO NOT REVIEW - do not review this pull request Needs review - a pull request needs a review from assigned developers Questions - a pull request has some questions that needs to be answered before further review can progress Ready for test - a pull request is ready for manual testing Ready to be merged - a pull request is ready to be merged (required for delayed feature delivery) Requires more work - a pull request was reviewed and reviewer(s) asked to work further on the pull request URGENT - a pull request needs to be urgently reviewed. An example of the pull request progression through labels: DO NOT REVIEW -> Needs review -> Ready for test -> Ready to be merged Use Github Labels script to automatically create consistent labels in your projects.","title":"Labels"},{"location":"development/documentation/","text":"Documentation for SDP \u00b6 https://dpc-sdp.github.io/sdp-docs/ Requirements \u00b6 Docker Ahoy Quickstart \u00b6 To build locally: ahoy build To serve locally: ahoy deploy Available commands \u00b6 build Build site deploy Deploy site serve Serve site in browser version MkDocs version Automated deployment \u00b6 CircleCI is configured to perform automated deployments for the main branch. The built site is automatically pushed to gh-pages branch. Also note that built site is available in CircleCI build artifacts tab. Important! Do not commit to gh-pages branch manually. Also, try to avoid using ahoy deploy command. Maintenance \u00b6 SDP development team is a main maintainer of this documentation. We welcome contributions to this documentation! Please open an issue or submit a pull request.","title":"Maintaining this documentation"},{"location":"development/documentation/#documentation-for-sdp","text":"https://dpc-sdp.github.io/sdp-docs/","title":"Documentation for SDP"},{"location":"development/documentation/#requirements","text":"Docker Ahoy","title":"Requirements"},{"location":"development/documentation/#quickstart","text":"To build locally: ahoy build To serve locally: ahoy deploy","title":"Quickstart"},{"location":"development/documentation/#available-commands","text":"build Build site deploy Deploy site serve Serve site in browser version MkDocs version","title":"Available commands"},{"location":"development/documentation/#automated-deployment","text":"CircleCI is configured to perform automated deployments for the main branch. The built site is automatically pushed to gh-pages branch. Also note that built site is available in CircleCI build artifacts tab. Important! Do not commit to gh-pages branch manually. Also, try to avoid using ahoy deploy command.","title":"Automated deployment"},{"location":"development/documentation/#maintenance","text":"SDP development team is a main maintainer of this documentation. We welcome contributions to this documentation! Please open an issue or submit a pull request.","title":"Maintenance"},{"location":"development/front-end-coding-standards/","text":"Front-End Coding Standards \u00b6 Content for this page has not been migrated yet. Components styling agreements \u00b6 rpl prefix is used for all classes. Use hyphen - to separate words within class, use 2 hyphens -- to separate class parts. For example, .rpl-vertical-tabs--open . Use underscore _ to separate words within mixins, use 2 underscores __ to separate mixin parts. For example, rpl_vertical_tabs__tabs() . Class names are based on hierarchy: Component class name: .rpl-[component-name] Element class name: .rpl-[component-name]__[element-name] Modifier class name: .rpl-[component-name]--[modifier-name] Each component should define as variables: colours font sizes padding margins (Not needed on margins if values are used for absolute placement, e.g. auto , 0 ). Variables should use rpl prefix. HTML elements can be defined by their tag (not just class) where suitable. Component example: // Core // ===================================== // Variables. $rpl-core-link-color : blue ; // Mixins. @mixin rpl_core_link () { color : $ rpl-core-link-color ; text-decoration : underline ; }","title":"Front-end coding standards"},{"location":"development/front-end-coding-standards/#front-end-coding-standards","text":"Content for this page has not been migrated yet.","title":"Front-End Coding Standards"},{"location":"development/front-end-coding-standards/#components-styling-agreements","text":"rpl prefix is used for all classes. Use hyphen - to separate words within class, use 2 hyphens -- to separate class parts. For example, .rpl-vertical-tabs--open . Use underscore _ to separate words within mixins, use 2 underscores __ to separate mixin parts. For example, rpl_vertical_tabs__tabs() . Class names are based on hierarchy: Component class name: .rpl-[component-name] Element class name: .rpl-[component-name]__[element-name] Modifier class name: .rpl-[component-name]--[modifier-name] Each component should define as variables: colours font sizes padding margins (Not needed on margins if values are used for absolute placement, e.g. auto , 0 ). Variables should use rpl prefix. HTML elements can be defined by their tag (not just class) where suitable. Component example: // Core // ===================================== // Variables. $rpl-core-link-color : blue ; // Mixins. @mixin rpl_core_link () { color : $ rpl-core-link-color ; text-decoration : underline ; }","title":"Components styling agreements"},{"location":"development/local-development-environment/","text":"Local development environment \u00b6 Drupal tools setup \u00b6 We are using Dev Tools for Drupal module and site development. Prerequisites Make sure that you have latest versions of all required software installed: Docker Pygmy Ahoy Make sure that all local web development services are shut down ( apache/nginx , mysql , MAMP etc). Setup curl https://raw.githubusercontent.com/dpc-sdp/dev-tools/master/install | bash pygmy up ahoy build Find more information about Dev Tools at https://github.com/dpc-sdp/dev-tools . Vue.js tools setup \u00b6 The steps below describe how to setup IDE (PHPStorm/WebStorm) to work with Vue.js application. Setup JS version Install Vue.js plugin (follow the setup guide at https://www.jetbrains.com/help/phpstorm/vue-js.html ) Set \"JavaScript language version\" to \"ECMAScript 6\" Setup JS Debugging Create a new JavaScript debug configuration Specify the URL the app is running on ( http://localhost:8080 ) Set a breakpoint Start the debug session by pressing \"Debug\" button in WebStorm/PHPStorm. Once the code where the breakpoint is has been triggered, the execution will stop, and you\u2019ll see the local and global variables, the call stack, and many other things in the IDE debug tools window.","title":"Local development environment"},{"location":"development/local-development-environment/#local-development-environment","text":"","title":"Local development environment"},{"location":"development/local-development-environment/#drupal-tools-setup","text":"We are using Dev Tools for Drupal module and site development.","title":"Drupal tools setup"},{"location":"development/local-development-environment/#vuejs-tools-setup","text":"The steps below describe how to setup IDE (PHPStorm/WebStorm) to work with Vue.js application.","title":"Vue.js tools setup"},{"location":"development/module-development/","text":"Module development \u00b6 Developing contributed module \u00b6 How to include a module into Content repository. Releasing contributed module \u00b6 How to extract a module from the codebase and release it.","title":"Module Development"},{"location":"development/module-development/#module-development","text":"","title":"Module development"},{"location":"development/module-development/#developing-contributed-module","text":"How to include a module into Content repository.","title":"Developing contributed module"},{"location":"development/module-development/#releasing-contributed-module","text":"How to extract a module from the codebase and release it.","title":"Releasing contributed module"},{"location":"development/readme-files/","text":"README.md files \u00b6 We provide 2 templates of README.md files: for consumer projects and Tide modules. Projects \u00b6 # _name_ Drupal 8 implementation of Content API for_name_ [![CircleCI](https://circleci.com/gh/dpc-sdp/_machine_name_.svg?style=shield&circle-token=619001ceda795d221a96315242e2782f621612d4)](https://circleci.com/gh/dpc-sdp/_machine_name_) ![Release](https://img.shields.io/github/release/dpc-sdp/_machine_name_.svg) ## Prerequisites 1. Make sure that you have latest versions of all required software installed: - [Docker](https://www.docker.com/) - [Pygmy](https://docs.amazee.io/local_docker_development/pygmy.html) - [Ahoy](https://github.com/ahoy-cli/ahoy) 2. Make sure that all local web development services are shut down (`apache/nginx`, `mysql`, `MAMP` etc). ## Local environment setup 3. `curl https://raw.githubusercontent.com/dpc-sdp/dev-tools/master/install | bash` 4. `pygmy up` 5. `ahoy build` Local URL -- http://_machine_name_.docker.amazee.io/ ## Available `ahoy` commands Run each command as `ahoy <command>`. ``` build Build or rebuild project. clean Remove all build files. clean-full Remove all development files. cli Start a shell inside CLI container or run a command. composer-merge Merge composer files. deploy Deploy or re-deploy a branch in Bay. doctor Identify problems with current stack. down Stop Docker containers and remove container, images, volumes and networks. drush Run drush commands in the CLI service container. flush-redis Flush Redis cache. info Print information about this project. install-dev Install dependencies. install-site Install site. lint Lint code. login Login to a website. logs Show Docker logs. pull Pull latest docker images. restart Restart all stopped and running Docker containers. start Start existing Docker containers. stop Stop running Docker containers. test-behat Run Behat tests. up Build and start Docker containers. ``` ## SSHing into CLI container `ahoy cli` ## Running a command in CLI container `ahoy cli ls /app` ## Mailhog. Mailhog is included with `pygmy` and is available @ http://mailhog.docker.amazee.io/ Documentation for mailhog is available of the project page -- https://github.com/mailhog/MailHog ## Stage file proxy. Stage File Proxy is enabled on all non production environments so files are automatically downloaded directly from prod on demand. ## Adding Drupal modules Modules needs to be added in 2 steps: 1. Require module code installation (through composer). 2. Enable module during site installation. ### Adding contrib modules `composer require drupal/module_name` or for specific versions `composer require drupal/module_name:1.2` ### Adding modules as local packages 1. Add local package information to the root of `composer.json`: ``` \"repositories\": { \"dpc-sdp/tide_page\": { \"type\": \"path\", \"url\": \"dpc-sdp/tide_page\" }, } ``` 2. `composer require tide_page` 3. To make sure that Composer triggers dependency tree rebuild, run `ahoy clean`. 4. Run `composer update --lock`. This will install all dependencies and update root `composer.lock` file with newly added module. ## Adding patches for composer packages 1. Add `title` and `url` to patch on drupal.org to the `patches` array in `extra` section in `composer.json`. ``` \"extra\": { \"patches\": { \"drupal/core\": { \"Contextual links should not be added inside another link - https://www.drupal.org/node/2898875\": \"https://www.drupal.org/files/issues/contextual_links_should-2898875-3.patch\" } } } ``` 2. `composer update --lock` ## Coding standards PHP and JS code linting uses [PHP_CodeSniffer](https://github.com/squizlabs/PHP_CodeSniffer) with Drupal rules from [Coder](https://www.drupal.org/project/coder) module and additional local overrides in `phpcs.xml.dist` and `.eslintrc`. ## Behat tests Behat configuration uses multiple extensions: - [Drupal Behat Extension](https://github.com/jhedstrom/drupalextension) - Drupal integration layer. Allows to work with Drupal API from within step definitions. - [Behat Screenshot Extension](https://github.com/integratedexperts/behat-screenshot) - Behat extension and a step definition to create HTML and image screenshots on demand or test fail. - [Behat Progress Fail Output Extension](https://github.com/integratedexperts/behat-format-progress-fail) - Behat output formatter to show progress as TAP and fail messages inline. Useful to get feedback about failed tests while continuing test run. - `YoursiteDrupalContext` - Site-specific Drupal context with custom step definitions. - `YoursiteMinkContext` - Site-specific Mink context with custom step definitions. Generic Behat tests should be written against the test entities from the Tide Test module. If a new test entity (node, block, etc.) is added to the Tide Test module, the relevant permissions must be also granted to Approver and Editor via the hook `tide_test_entity_bundle_create()`. ### Run tests locally: - Run Behat tests: `ahoy test-behat` - Run specific test feature: `ahoy test-behat tests/behat/features/homepage.feature` - Run specific test tag: `ahoy test-behat -- --tags=wip` ## Automated builds (Continuous Integration) In software engineering, continuous integration (CI) is the practice of merging all developer working copies to a shared mainline several times a day. Before feature changes can be merged into a shared mainline, a complete build must run and pass all tests on CI server. This project uses [Circle CI](https://circleci.com/) as CI server: it imports production backups into fully built codebase and runs code linting and tests. When tests pass, a deployment process is triggered for nominated branches (usually, `master` and `develop`). Add `[skip ci]` to the commit subject to skip CI build. Useful for documentation changes. ### SSH Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. ### Test artifacts Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI. ## Debugging ### PHP application from browser 1. Trigger xDebug from web browser (using one of the browser extensions) so that PHPStorm recognises the server `yoursite.docker.amazee.io` and configures the path mapping. Alternatively, you can create the server in PHPStorm Settings. * Make sure `serverName` to be `yoursite.docker.amazee.io` ### PHP scripts ``` ahoy cli xdebug.sh path/to/script ``` For example, to run a single Behat test: `xdebug.sh vendor/bin/behat path/to/test.feature` ### Drush commands ``` ahoy cli `./xdebug.sh vendor/bin/drush <DRUSH_COMMAND> ``` ### DB connection details Run `ahoy info` to get the port number. ``` Host: 127.0.0.1 Username: drupal Password: drupal Database: drupal Port: <get from \"ahoy info\"> ``` Tide modules \u00b6 # _name_ _name_ content type for [Tide](https://github.com/dpc-sdp/tide) distribution for [Drupal 8](https://github.com/dpc-sdp) Tide is a Drupal 8 distribution focused on delivering an API first, headless Drupal content administration site. [![CircleCI](https://circleci.com/gh/dpc-sdp/_machine_name_.svg?style=shield&circle-token=2a0e49166724ac193636fba5b458024e00342dce)](https://circleci.com/gh/dpc-sdp/_machine_name_) [![Release](https://img.shields.io/github/release/dpc-sdp/_machine_name_.svg)](https://github.com/dpc-sdp/_machine_name_/releases/latest) ![https://www.drupal.org/8](https://img.shields.io/badge/Drupal-8-blue.svg) [![Licence: GPL 2](https://img.shields.io/badge/licence-GPL2-blue.svg)](https://github.com/dpc-sdp/_machine_name_/blob/master/LICENSE.txt) [![Pull Requests](https://img.shields.io/github/issues-pr/dpc-sdp/tide_page.svg)](https://github.com/dpc-sdp/_machine_name_/pulls) ## What is in this package - content type - fields - blocks - views - JSONAPI module integration ## Installation To install this package, add this custom repository to `repositories` section of your `composer.json`: ```json { \"repositories\": { \"dpc-sdp/tide_page\": { \"type\": \"vcs\", \"no-api\": true, \"url\": \"https://github.com/dpc-sdp/_machine_name_.git\" } } } ``` Require this package as any other Composer package: ```bash composer require dpc/_machine_name_ ``` ## Support [Digital Engagement, Department of Premier and Cabinet, Victoria, Australia](https://github.com/dpc-sdp) is a maintainer of this package. ## Contribute [Open an issue](https://github.com/dpc-sdp) on GitHub or submit a pull request with suggested changes. ## Development and maintenance Development is powered by [Dev-Tools](https://github.com/dpc-sdp/dev-tools). Please refer to Dev-Tools' page for [system requirements](https://github.com/dpc-sdp/dev-tools/#prerequisites) and other details. To start local development stack: 1. Checkout this project 2. Run `./dev-tools.sh` 3. Run `ahoy build` ## Related projects - [tide](https://github.com/dpc-sdp/tide) - [tide_api](https://github.com/dpc-sdp/tide_api) - [tide_core](https://github.com/dpc-sdp/tide_core) - [tide_event](https://github.com/dpc-sdp/tide_event) - [tide_landing_page](https://github.com/dpc-sdp/tide_landing_page) - [tide_media](https://github.com/dpc-sdp/tide_media) - [tide_monsido](https://github.com/dpc-sdp/tide_monsido) - [tide_news](https://github.com/dpc-sdp/tide_news) - [tide_page](https://github.com/dpc-sdp/tide_page) - [tide_search](https://github.com/dpc-sdp/tide_search) - [tide_site](https://github.com/dpc-sdp/tide_site) - [tide_test](https://github.com/dpc-sdp/tide_test) - [tide_webform](https://github.com/dpc-sdp/tide_webform) ## License This project is licensed under [GPL2](https://github.com/dpc-sdp/_machine_name_/blob/master/LICENSE.txt)","title":"README.md files"},{"location":"development/readme-files/#readmemd-files","text":"We provide 2 templates of README.md files: for consumer projects and Tide modules.","title":"README.md files"},{"location":"development/readme-files/#projects","text":"# _name_ Drupal 8 implementation of Content API for_name_ [![CircleCI](https://circleci.com/gh/dpc-sdp/_machine_name_.svg?style=shield&circle-token=619001ceda795d221a96315242e2782f621612d4)](https://circleci.com/gh/dpc-sdp/_machine_name_) ![Release](https://img.shields.io/github/release/dpc-sdp/_machine_name_.svg) ## Prerequisites 1. Make sure that you have latest versions of all required software installed: - [Docker](https://www.docker.com/) - [Pygmy](https://docs.amazee.io/local_docker_development/pygmy.html) - [Ahoy](https://github.com/ahoy-cli/ahoy) 2. Make sure that all local web development services are shut down (`apache/nginx`, `mysql`, `MAMP` etc). ## Local environment setup 3. `curl https://raw.githubusercontent.com/dpc-sdp/dev-tools/master/install | bash` 4. `pygmy up` 5. `ahoy build` Local URL -- http://_machine_name_.docker.amazee.io/ ## Available `ahoy` commands Run each command as `ahoy <command>`. ``` build Build or rebuild project. clean Remove all build files. clean-full Remove all development files. cli Start a shell inside CLI container or run a command. composer-merge Merge composer files. deploy Deploy or re-deploy a branch in Bay. doctor Identify problems with current stack. down Stop Docker containers and remove container, images, volumes and networks. drush Run drush commands in the CLI service container. flush-redis Flush Redis cache. info Print information about this project. install-dev Install dependencies. install-site Install site. lint Lint code. login Login to a website. logs Show Docker logs. pull Pull latest docker images. restart Restart all stopped and running Docker containers. start Start existing Docker containers. stop Stop running Docker containers. test-behat Run Behat tests. up Build and start Docker containers. ``` ## SSHing into CLI container `ahoy cli` ## Running a command in CLI container `ahoy cli ls /app` ## Mailhog. Mailhog is included with `pygmy` and is available @ http://mailhog.docker.amazee.io/ Documentation for mailhog is available of the project page -- https://github.com/mailhog/MailHog ## Stage file proxy. Stage File Proxy is enabled on all non production environments so files are automatically downloaded directly from prod on demand. ## Adding Drupal modules Modules needs to be added in 2 steps: 1. Require module code installation (through composer). 2. Enable module during site installation. ### Adding contrib modules `composer require drupal/module_name` or for specific versions `composer require drupal/module_name:1.2` ### Adding modules as local packages 1. Add local package information to the root of `composer.json`: ``` \"repositories\": { \"dpc-sdp/tide_page\": { \"type\": \"path\", \"url\": \"dpc-sdp/tide_page\" }, } ``` 2. `composer require tide_page` 3. To make sure that Composer triggers dependency tree rebuild, run `ahoy clean`. 4. Run `composer update --lock`. This will install all dependencies and update root `composer.lock` file with newly added module. ## Adding patches for composer packages 1. Add `title` and `url` to patch on drupal.org to the `patches` array in `extra` section in `composer.json`. ``` \"extra\": { \"patches\": { \"drupal/core\": { \"Contextual links should not be added inside another link - https://www.drupal.org/node/2898875\": \"https://www.drupal.org/files/issues/contextual_links_should-2898875-3.patch\" } } } ``` 2. `composer update --lock` ## Coding standards PHP and JS code linting uses [PHP_CodeSniffer](https://github.com/squizlabs/PHP_CodeSniffer) with Drupal rules from [Coder](https://www.drupal.org/project/coder) module and additional local overrides in `phpcs.xml.dist` and `.eslintrc`. ## Behat tests Behat configuration uses multiple extensions: - [Drupal Behat Extension](https://github.com/jhedstrom/drupalextension) - Drupal integration layer. Allows to work with Drupal API from within step definitions. - [Behat Screenshot Extension](https://github.com/integratedexperts/behat-screenshot) - Behat extension and a step definition to create HTML and image screenshots on demand or test fail. - [Behat Progress Fail Output Extension](https://github.com/integratedexperts/behat-format-progress-fail) - Behat output formatter to show progress as TAP and fail messages inline. Useful to get feedback about failed tests while continuing test run. - `YoursiteDrupalContext` - Site-specific Drupal context with custom step definitions. - `YoursiteMinkContext` - Site-specific Mink context with custom step definitions. Generic Behat tests should be written against the test entities from the Tide Test module. If a new test entity (node, block, etc.) is added to the Tide Test module, the relevant permissions must be also granted to Approver and Editor via the hook `tide_test_entity_bundle_create()`. ### Run tests locally: - Run Behat tests: `ahoy test-behat` - Run specific test feature: `ahoy test-behat tests/behat/features/homepage.feature` - Run specific test tag: `ahoy test-behat -- --tags=wip` ## Automated builds (Continuous Integration) In software engineering, continuous integration (CI) is the practice of merging all developer working copies to a shared mainline several times a day. Before feature changes can be merged into a shared mainline, a complete build must run and pass all tests on CI server. This project uses [Circle CI](https://circleci.com/) as CI server: it imports production backups into fully built codebase and runs code linting and tests. When tests pass, a deployment process is triggered for nominated branches (usually, `master` and `develop`). Add `[skip ci]` to the commit subject to skip CI build. Useful for documentation changes. ### SSH Circle CI provides SSH access into the build for 120 minutes after the build is finished. SSH can be enabled once the build is started with SSH support. ### Test artifacts Test artifacts (screenshots etc.) are available under 'Artifacts' tab in CircleCI UI. ## Debugging ### PHP application from browser 1. Trigger xDebug from web browser (using one of the browser extensions) so that PHPStorm recognises the server `yoursite.docker.amazee.io` and configures the path mapping. Alternatively, you can create the server in PHPStorm Settings. * Make sure `serverName` to be `yoursite.docker.amazee.io` ### PHP scripts ``` ahoy cli xdebug.sh path/to/script ``` For example, to run a single Behat test: `xdebug.sh vendor/bin/behat path/to/test.feature` ### Drush commands ``` ahoy cli `./xdebug.sh vendor/bin/drush <DRUSH_COMMAND> ``` ### DB connection details Run `ahoy info` to get the port number. ``` Host: 127.0.0.1 Username: drupal Password: drupal Database: drupal Port: <get from \"ahoy info\"> ```","title":"Projects"},{"location":"development/readme-files/#tide-modules","text":"# _name_ _name_ content type for [Tide](https://github.com/dpc-sdp/tide) distribution for [Drupal 8](https://github.com/dpc-sdp) Tide is a Drupal 8 distribution focused on delivering an API first, headless Drupal content administration site. [![CircleCI](https://circleci.com/gh/dpc-sdp/_machine_name_.svg?style=shield&circle-token=2a0e49166724ac193636fba5b458024e00342dce)](https://circleci.com/gh/dpc-sdp/_machine_name_) [![Release](https://img.shields.io/github/release/dpc-sdp/_machine_name_.svg)](https://github.com/dpc-sdp/_machine_name_/releases/latest) ![https://www.drupal.org/8](https://img.shields.io/badge/Drupal-8-blue.svg) [![Licence: GPL 2](https://img.shields.io/badge/licence-GPL2-blue.svg)](https://github.com/dpc-sdp/_machine_name_/blob/master/LICENSE.txt) [![Pull Requests](https://img.shields.io/github/issues-pr/dpc-sdp/tide_page.svg)](https://github.com/dpc-sdp/_machine_name_/pulls) ## What is in this package - content type - fields - blocks - views - JSONAPI module integration ## Installation To install this package, add this custom repository to `repositories` section of your `composer.json`: ```json { \"repositories\": { \"dpc-sdp/tide_page\": { \"type\": \"vcs\", \"no-api\": true, \"url\": \"https://github.com/dpc-sdp/_machine_name_.git\" } } } ``` Require this package as any other Composer package: ```bash composer require dpc/_machine_name_ ``` ## Support [Digital Engagement, Department of Premier and Cabinet, Victoria, Australia](https://github.com/dpc-sdp) is a maintainer of this package. ## Contribute [Open an issue](https://github.com/dpc-sdp) on GitHub or submit a pull request with suggested changes. ## Development and maintenance Development is powered by [Dev-Tools](https://github.com/dpc-sdp/dev-tools). Please refer to Dev-Tools' page for [system requirements](https://github.com/dpc-sdp/dev-tools/#prerequisites) and other details. To start local development stack: 1. Checkout this project 2. Run `./dev-tools.sh` 3. Run `ahoy build` ## Related projects - [tide](https://github.com/dpc-sdp/tide) - [tide_api](https://github.com/dpc-sdp/tide_api) - [tide_core](https://github.com/dpc-sdp/tide_core) - [tide_event](https://github.com/dpc-sdp/tide_event) - [tide_landing_page](https://github.com/dpc-sdp/tide_landing_page) - [tide_media](https://github.com/dpc-sdp/tide_media) - [tide_monsido](https://github.com/dpc-sdp/tide_monsido) - [tide_news](https://github.com/dpc-sdp/tide_news) - [tide_page](https://github.com/dpc-sdp/tide_page) - [tide_search](https://github.com/dpc-sdp/tide_search) - [tide_site](https://github.com/dpc-sdp/tide_site) - [tide_test](https://github.com/dpc-sdp/tide_test) - [tide_webform](https://github.com/dpc-sdp/tide_webform) ## License This project is licensed under [GPL2](https://github.com/dpc-sdp/_machine_name_/blob/master/LICENSE.txt)","title":"Tide modules"},{"location":"development/release/","text":"Managing releases \u00b6 The purpose of this document is to describe the git management process across the Content repository and semi-independent sites. Issues \u00b6 Changes to the Drupal API can have an effect on the Front end website due to field and entity changes. This can lead to issues on semi-independent sites if they are not updated at the same time as the Content repository as they rely on a common API. This can cause a delay in deploying Content repository while changes are merged to the semi-independent sites and go through QA and UAT. Versions \u00b6 Site release versions should follow semantic versioning . Quote Given a version number MAJOR.MINOR.PATCH , increment the: MAJOR version when you make incompatible API changes, MINOR version when you add functionality in a backwards-compatible manner, and PATCH version when you make backwards-compatible bug fixes. Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format. Git workflow \u00b6 Git branch schema for releases Standard feature branches are taken from the the develop branch. Pull requests for the current release are merged back into develop after QA has occurs in the standard process. Pull requests for subsequent releases should be taken from develop . These pull requests can go through the QA process but must not be merged to develop until after the current release has moved from develop into the master branch. This is to ensure the QA team has time to test the new features on the front-end sites before the backend code is tagged and released to production. Releasing \u00b6 Note The steps below do not include any release communication steps. Always prepare release plan with communication details, templates and rollback actions ahead of release, or, better, create a standardise release run sheet. Create a release branch from develop Copy the release branch to each of the front-end site repositories, manage the conflicts and push the changes as a new pull request against develop for each repository. Have the QA team test the latest changes and perform a spot regression check. Merge the Content repository BE repo through to master Once all front-end sites pass QA (or only minor bugs are found that will not effect release) merge the latest changes to develop and follow the standard release process through to master on each site. Request UAT on all front-end sites. Once UAT is complete or 3 business days are passed, prepare totag and release to production. Tag and deploy Content repository release to production.","title":"Release management"},{"location":"development/release/#managing-releases","text":"The purpose of this document is to describe the git management process across the Content repository and semi-independent sites.","title":"Managing releases"},{"location":"development/release/#issues","text":"Changes to the Drupal API can have an effect on the Front end website due to field and entity changes. This can lead to issues on semi-independent sites if they are not updated at the same time as the Content repository as they rely on a common API. This can cause a delay in deploying Content repository while changes are merged to the semi-independent sites and go through QA and UAT.","title":"Issues"},{"location":"development/release/#versions","text":"Site release versions should follow semantic versioning . Quote Given a version number MAJOR.MINOR.PATCH , increment the: MAJOR version when you make incompatible API changes, MINOR version when you add functionality in a backwards-compatible manner, and PATCH version when you make backwards-compatible bug fixes. Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.","title":"Versions"},{"location":"development/release/#git-workflow","text":"Git branch schema for releases Standard feature branches are taken from the the develop branch. Pull requests for the current release are merged back into develop after QA has occurs in the standard process. Pull requests for subsequent releases should be taken from develop . These pull requests can go through the QA process but must not be merged to develop until after the current release has moved from develop into the master branch. This is to ensure the QA team has time to test the new features on the front-end sites before the backend code is tagged and released to production.","title":"Git workflow"},{"location":"development/release/#releasing","text":"Note The steps below do not include any release communication steps. Always prepare release plan with communication details, templates and rollback actions ahead of release, or, better, create a standardise release run sheet. Create a release branch from develop Copy the release branch to each of the front-end site repositories, manage the conflicts and push the changes as a new pull request against develop for each repository. Have the QA team test the latest changes and perform a spot regression check. Merge the Content repository BE repo through to master Once all front-end sites pass QA (or only minor bugs are found that will not effect release) merge the latest changes to develop and follow the standard release process through to master on each site. Request UAT on all front-end sites. Once UAT is complete or 3 business days are passed, prepare totag and release to production. Tag and deploy Content repository release to production.","title":"Releasing"},{"location":"development/troubleshooting/","text":"Troubleshooting \u00b6 Docker Host container is full \u00b6 If you're seeing errors like Error processing tar file(exit status 1): write /app/docroot/themes/custom/governor/build/images/homepage-background.png: no space left on device` run docker image prune -a to free-up space in your Docker. A branch is pushed into the repo, but no deployments are happening in Bay \u00b6 CI passes, but nothing happening in the messenger build channel. The branch name might be too long. Please make sure that the name of your branch is less then or equal to 40 characters.","title":"Troubleshooting"},{"location":"development/troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"development/troubleshooting/#docker-host-container-is-full","text":"If you're seeing errors like Error processing tar file(exit status 1): write /app/docroot/themes/custom/governor/build/images/homepage-background.png: no space left on device` run docker image prune -a to free-up space in your Docker.","title":"Docker Host container is full"},{"location":"development/troubleshooting/#a-branch-is-pushed-into-the-repo-but-no-deployments-are-happening-in-bay","text":"CI passes, but nothing happening in the messenger build channel. The branch name might be too long. Please make sure that the name of your branch is less then or equal to 40 characters.","title":"A branch is pushed into the repo, but no deployments are happening in Bay"},{"location":"development/workflow/","text":"Development workflow \u00b6 Content for this page has not been fully migrated yet. Example workflow \u00b6 This workflow describes working on features as a developer on websites that use Tide or Ripple. Pick a ticket in your issue tracker: Make sure that all requirements, solution direction and acceptance criteria are clear. If not, address issues with Technical Lead or product Owner. Assign to yourself. Create new feature branch named feature/CODE123-short-hyphenated-description . Work on the ticket functionality: Install new contributed modules or packages as required. For back-end - configure and export configuration changes; write hook_update_N() implementations (but be mindful that Drupal 8 does not require many of those). For front-end - identify and use existing or create new Ripple components; update styles according to style guide as required; make sure that Storybook has updated and new components added (it is important to always have style guide up to date). Add tests: For back-end - identify required Behat tests (only test your custom configuration, and critical user journeys; do not test Drupal's standard behaviour); identify and implement PHPUnit tests. For front-end - identify required tests and mocks, and implement them; add unit tests for any custom Nux functionality. Commit all changed and added files. Pay special attention to configuration files and their counterparts ( composer.json , composer.lock , package.json , package-lock.json ). Create a pull request in your issue tracker - see Preparing code for code review If your are using a messenger to communicate with your development team - copy and paste the link to the created pull request into messenger and ask for a review. Move the ticket in your issue tracker to In code review state (create this state if it does not exist to help identify tickets pending review).","title":"Development Workflow"},{"location":"development/workflow/#development-workflow","text":"Content for this page has not been fully migrated yet.","title":"Development workflow"},{"location":"development/workflow/#example-workflow","text":"This workflow describes working on features as a developer on websites that use Tide or Ripple. Pick a ticket in your issue tracker: Make sure that all requirements, solution direction and acceptance criteria are clear. If not, address issues with Technical Lead or product Owner. Assign to yourself. Create new feature branch named feature/CODE123-short-hyphenated-description . Work on the ticket functionality: Install new contributed modules or packages as required. For back-end - configure and export configuration changes; write hook_update_N() implementations (but be mindful that Drupal 8 does not require many of those). For front-end - identify and use existing or create new Ripple components; update styles according to style guide as required; make sure that Storybook has updated and new components added (it is important to always have style guide up to date). Add tests: For back-end - identify required Behat tests (only test your custom configuration, and critical user journeys; do not test Drupal's standard behaviour); identify and implement PHPUnit tests. For front-end - identify required tests and mocks, and implement them; add unit tests for any custom Nux functionality. Commit all changed and added files. Pay special attention to configuration files and their counterparts ( composer.json , composer.lock , package.json , package-lock.json ). Create a pull request in your issue tracker - see Preparing code for code review If your are using a messenger to communicate with your development team - copy and paste the link to the created pull request into messenger and ask for a review. Move the ticket in your issue tracker to In code review state (create this state if it does not exist to help identify tickets pending review).","title":"Example workflow"},{"location":"ripple/","text":"Ripple \u00b6 Ripple offers a consistent design system, making it easier for citizens to find, understand and use Victorian Government information maintained by SDP. It: is fully open and includes a library of reusable components, based on atomic pattern design. uses Vue.js and Nuxt to deliver a consistent look and feel across government websites. includes a starter kit for agencies. Namespaces \u00b6 NPM vendor namespace: dpc-sdp NPM packages namespace: ripple-* Repositories \u00b6 Ripple source code: https://github.com/dpc-sdp/ripple (this is a monorepo ). NPM: https://www.npmjs.com/org/dpc-sdp","title":"Overview"},{"location":"ripple/#ripple","text":"Ripple offers a consistent design system, making it easier for citizens to find, understand and use Victorian Government information maintained by SDP. It: is fully open and includes a library of reusable components, based on atomic pattern design. uses Vue.js and Nuxt to deliver a consistent look and feel across government websites. includes a starter kit for agencies.","title":"Ripple"},{"location":"ripple/#namespaces","text":"NPM vendor namespace: dpc-sdp NPM packages namespace: ripple-*","title":"Namespaces"},{"location":"ripple/#repositories","text":"Ripple source code: https://github.com/dpc-sdp/ripple (this is a monorepo ). NPM: https://www.npmjs.com/org/dpc-sdp","title":"Repositories"},{"location":"ripple/api/","text":"Ripple API \u00b6 Content for this page has not been migrated yet. API mocking \u00b6 Why do we need mocking We need to develop FE sites against stable API. When Content repository is still being developed alongside with FE application, it is very hard for FE developers to develop against non-stable API. 3 ways of mocking Internal mocking inside of NUXT Inject mock HTTP client inside of NUXT application and use it to read JSON responses from generated responses as a part of the test. Automated mock generation Generate API response mocks using automatically generated API schema and serve it to FE framework as a predictable and stable alternative API endpoint. Manual mock generation Generate dummy data on API side and store responses as JSON files to serve it to the FE framework as a predictable and stable alternative API endpoint. Internal mocking inside of NUXT Inject mock HTTP client inside of NUXT application and use it to read JSON responses from generated responses as a part of the test. How it would look like for a developer (DX) Initial setup Write a test that would test specific functionality. Write a mock generation code within a test. Repeat 1-2 for each test. Commit code to the codebase When API is updated (for example, new field is added to a content type) Update mock generation and assertions for all relevant tests. Commit code to the codebase Problems Writing mock generation code is complex and tiresome. When/if API changes, there may need to be a change to a lot of mock generation code. These mocks will not be used to browse full FE site. I.e., it will not be possible to browse homepage using these mocks. Changes to API require manual update of files. Automated mock generation Generate API response mocks using automatically generated API schema and serve it to FE framework as a predictable and stable alternative API endpoint. How it would look like for a developer (DX) Initial setup Drupal exposes API schema. Fake generator reads the schema and generates response JSON files. Files committed to FE repository. Mock server serves JSON files. When API is updated (for example, new field is added to a content type) Re-genearate JSON response files (same as step 2 above). Commit updated JSON files to FE repo (same as step 1 above). Problems The biggest problem is that current Drupal schema, provided by Schemata module, does not provide enough context to allow automated generation and relationships linking. For example, while descibing 'UUID' field, it says that the type is 'string', but says nothing about the format of such string. As a result - generated UUID is a random string in incorrect format. And this goes on for all fields. Even if p.1 is resolved, the generated content uses random apporach to fill fields. This has 2 issues: the content will be constantly changing making a lot of changes in committed files and confusing developers that expect specific data to be shown optional fields will be randomly filled-in (which is what we want), but there is no guarantee that all optional fields are used in a set of produced mocks. In other words, we need not just content with some randomised fields, but a full content set of permutations of all fields. Changes to API require manual update of files. Manual mock generation Generate dummy data on API side and store responses as JSON files to serve it to the FE framework as a predictable and stable alternative API endpoint. How it would look like for a developer (DX) Initial setup 1. API has some dummy content generated in predictable way that covers all permutations. 2. Manually ran script (or drush command) downloads all JSON responses as files. 3. Files committed to FE repository. 4. Mock server serves JSON files. When API is updated (for example, new field is added to a content type) Re-genearate JSON response files (same as step 2 above). Commit updated JSON files to FE repo (same as step 1 above). Problems Requires dummy content to exist on API site. Changes to API require manual update of files.","title":"API"},{"location":"ripple/api/#ripple-api","text":"Content for this page has not been migrated yet.","title":"Ripple API"},{"location":"ripple/api/#api-mocking","text":"","title":"API mocking"},{"location":"ripple/components/","text":"Components \u00b6 Forms \u00b6 Ripple supports Drupal Webform . All backend Drupal webforms in Ripple frontend are rendered dynamically using Vue Form Generator (VFG). Note Only limited set functionality is currently supported. See \"Support status\" column. Configuration Webform field Support status VFG form field #title IMPLEMENTED label #required IMPLEMENTED required #options IMPLEMENTED values #empty_option IMPLEMENTED placeholder #description IMPLEMENTED hint #placeholder IMPLEMENTED placeholder Elements Webform element name Webform Category Webform element ID Support status VFG form element Checkbox Basic checkbox PLANNED checkbox Hidden Basic hidden IMPLEMENTED input: hidden Textarea Basic textarea IMPLEMENTED textArea Text field Basic textfield IMPLEMENTED input: text Autocomplete Advanced NOT PLANNED CAPTCHA Advanced NOT PLANNED CodeMirror Advanced NOT PLANNED Color Advanced NOT PLANNED Email Advanced email IMPLEMENTED input: email Email confirm Advanced NOT PLANNED Email multiple Advanced NOT PLANNED Mapping Advanced Mapping NOT PLANNED Number Advanced number IMPLEMENTED input: number Range Advanced NOT PLANNED Rating Advanced NOT PLANNED Search Advanced NOT PLANNED Signature Advanced NOT PLANNED Telephone Advanced tel input: tel Terms of service Advanced NOT PLANNED Text format Advanced NOT PLANNED Toggle Advanced NOT PLANNED URL Advanced NOT PLANNED Value Advanced NOT PLANNED Basic address Composite NOT PLANNED Advanced address Composite NOT PLANNED Contact Composite NOT PLANNED Custom composite Composite NOT PLANNED Link Composite NOT PLANNED Location Composite NOT PLANNED Name Composite NOT PLANNED Telephone advanced? Composite NOT PLANNED Advanced HTML/Text Markup processed_text PLANNED label Basic HTML Markup webform_markup PLANNED label Horizontal rule Markup horizontal_rule PLANNED custom Message Markup NOT PLANNED Label Markup label PLANNED label Audio file File upload file NOT PLANNED Document file File upload file NOT PLANNED File File upload file NOT PLANNED Image file File upload file NOT PLANNED Video file File upload file NOT PLANNED Buttons Options NOT PLANNED Checkboxes Options NOT PLANNED Checkboxes other Options NOT PLANNED Likert Options NOT PLANNED Radios Options radios IMPLEMENTED radios Radios other Options NOT PLANNED Select Options select LIMITED vueMultiSelect Multi Select Options NOT PLANNED Select other Options select_other NOT PLANNED Table select Options NOT PLANNED Tableselect sort Options NOT PLANNED Table sort Options NOT PLANNED Computed token Computed NOT PLANNED Computed Twig Computed NOT PLANNED Container Container NOT PLANNED Details Container NOT PLANNED Fieldset Container NOT PLANNED Flexbox layout Container NOT PLANNED Item Container NOT PLANNED Section Container NOT PLANNED Date Date/time date PLANNED Date/time Date/time NOT PLANNED Date list Date/time NOT PLANNED Time Date/time NOT PLANNED Submit button(s) Buttons webform_actions LIMITED Entity autocomplete Entity reference NOT PLANNED Entity checkboxes Entity reference NOT PLANNED Entity radios Entity reference NOT PLANNED Entity select Entity reference NOT PLANNED Term checkboxes Entity reference NOT PLANNED Term select Entity reference webform_term_select PLANNED","title":"Components"},{"location":"ripple/components/#components","text":"","title":"Components"},{"location":"ripple/components/#forms","text":"Ripple supports Drupal Webform . All backend Drupal webforms in Ripple frontend are rendered dynamically using Vue Form Generator (VFG). Note Only limited set functionality is currently supported. See \"Support status\" column.","title":"Forms"},{"location":"ripple/content-data-flow/","text":"Content data flow \u00b6 This chapter describes how data requested from Content repository flows to front-end website implementation and how it is then rendered to the visitor in the browser. Request round trip \u00b6 The diagram below shows how a visitor's request travels through all systems to render a page and, subsequently, update a component. Component request diagram There are multiple caching layers to speed up the initial page render: - Static HTML page cache in CloudFront Cache of the previously rendered front-end page. This completely avoids requests to API, making the site render solely in the browser. - Static API JSON response cache in CloudFront Cache of the previously requested API response. This allows to speedup page assembly from several API endpoints. - Content repository entity cache and other caches Internal caching mechanism within Content repository. Allows to lower load and minimise expensive data retrieval operations from the database. Once rendered, components may request an update for a part of the page, bypassing all static cache layers, but still re-using caching within Content repository. Note that Content repository refreshes internal caches and notifies external proxies (CloudFront etc.) once the content changes. This mechanism is inbuilt in Drupal. NUXT data processing \u00b6 Once request reaches front-end website, NUXT receives a request, fetches internal configuration and requests content from Content repository via tide package, which has field mappings and other integrations defined. Once the content is received, the page template assembles page using Ripple component library, after which the page is sent to the browser. Note that Ripple is completely separate from the tide package and NUXT configuration - this makes it unbound to Tide Content repository.","title":"Content data flow"},{"location":"ripple/content-data-flow/#content-data-flow","text":"This chapter describes how data requested from Content repository flows to front-end website implementation and how it is then rendered to the visitor in the browser.","title":"Content data flow"},{"location":"ripple/content-data-flow/#request-round-trip","text":"The diagram below shows how a visitor's request travels through all systems to render a page and, subsequently, update a component. Component request diagram There are multiple caching layers to speed up the initial page render: - Static HTML page cache in CloudFront Cache of the previously rendered front-end page. This completely avoids requests to API, making the site render solely in the browser. - Static API JSON response cache in CloudFront Cache of the previously requested API response. This allows to speedup page assembly from several API endpoints. - Content repository entity cache and other caches Internal caching mechanism within Content repository. Allows to lower load and minimise expensive data retrieval operations from the database. Once rendered, components may request an update for a part of the page, bypassing all static cache layers, but still re-using caching within Content repository. Note that Content repository refreshes internal caches and notifies external proxies (CloudFront etc.) once the content changes. This mechanism is inbuilt in Drupal.","title":"Request round trip"},{"location":"ripple/content-data-flow/#nuxt-data-processing","text":"Once request reaches front-end website, NUXT receives a request, fetches internal configuration and requests content from Content repository via tide package, which has field mappings and other integrations defined. Once the content is received, the page template assembles page using Ripple component library, after which the page is sent to the browser. Note that Ripple is completely separate from the tide package and NUXT configuration - this makes it unbound to Tide Content repository.","title":"NUXT data processing"},{"location":"ripple/search/","text":"Search \u00b6 Content for this page has not been migrated yet.","title":"Search"},{"location":"ripple/search/#search","text":"Content for this page has not been migrated yet.","title":"Search"},{"location":"ripple/setup/","text":"Setting up a new Ripple site \u00b6 Content for this page has not been migrated yet.","title":"Setup new site"},{"location":"ripple/setup/#setting-up-a-new-ripple-site","text":"Content for this page has not been migrated yet.","title":"Setting up a new Ripple site"},{"location":"tide/","text":"Tide \u00b6 Tide is an API first, headless content management system using Drupal 8 and maintained by SDP. Custom built to meet Victorian Government requirements, it offers: - multi-site content distribution - pick and mix features - centralised feature governance The profile is a mere collection of Tide modules bundled into governed, stable and tested Drupal installation profile. All modules and a profile have automated tests to guarantee that a set of all modules at specified versions is always stable. Namespaces \u00b6 Composer vendor namespace: dpc-sdp Composer Drupal profile namespace: dpc-sdp/tide Composer Drupal modules namespace: tide_* . Drupal.org Drupal profile namespace: tide . Drupal.org Drupal modules namespace: tide_* . Drupal profile machine name: tide Drupal modules machine name: tide_* Repositories \u00b6 Drupal profile: https://github.com/dpc-sdp/tide Drupal custom modules: https://github.com/dpc-sdp/tide_api https://github.com/dpc-sdp/tide_core https://github.com/dpc-sdp/tide_event https://github.com/dpc-sdp/tide_landing_page https://github.com/dpc-sdp/tide_media https://github.com/dpc-sdp/tide_monsido https://github.com/dpc-sdp/tide_news https://github.com/dpc-sdp/tide_page https://github.com/dpc-sdp/tide_search https://github.com/dpc-sdp/tide_site https://github.com/dpc-sdp/tide_test https://github.com/dpc-sdp/tide_webform See Modules chapter for more information about modules.","title":"Overview"},{"location":"tide/#tide","text":"Tide is an API first, headless content management system using Drupal 8 and maintained by SDP. Custom built to meet Victorian Government requirements, it offers: - multi-site content distribution - pick and mix features - centralised feature governance The profile is a mere collection of Tide modules bundled into governed, stable and tested Drupal installation profile. All modules and a profile have automated tests to guarantee that a set of all modules at specified versions is always stable.","title":"Tide"},{"location":"tide/#namespaces","text":"Composer vendor namespace: dpc-sdp Composer Drupal profile namespace: dpc-sdp/tide Composer Drupal modules namespace: tide_* . Drupal.org Drupal profile namespace: tide . Drupal.org Drupal modules namespace: tide_* . Drupal profile machine name: tide Drupal modules machine name: tide_*","title":"Namespaces"},{"location":"tide/#repositories","text":"Drupal profile: https://github.com/dpc-sdp/tide Drupal custom modules: https://github.com/dpc-sdp/tide_api https://github.com/dpc-sdp/tide_core https://github.com/dpc-sdp/tide_event https://github.com/dpc-sdp/tide_landing_page https://github.com/dpc-sdp/tide_media https://github.com/dpc-sdp/tide_monsido https://github.com/dpc-sdp/tide_news https://github.com/dpc-sdp/tide_page https://github.com/dpc-sdp/tide_search https://github.com/dpc-sdp/tide_site https://github.com/dpc-sdp/tide_test https://github.com/dpc-sdp/tide_webform See Modules chapter for more information about modules.","title":"Repositories"},{"location":"tide/api/","text":"Tide API \u00b6 Content API is built from a set of contributed modules and custom code provided through Tide API module. Why JSONAPI? \u00b6 Why we selected JSONAPI standard over generic REST provided by Drupal core: JSON is a standard of REST, a subset of generic REST rules. JSONAPI allows to query individual items and collections. Drupal JSONAPI module automatically exposes entities as endpoints. Because most of functionality is implement as entities in Drupal 8, there is no need for custom code to expose required features. JSONAPI is a newer format JSONAPI will be included in Drupal core. Documentation on using Drupal JSONAPI module: https://www.drupal .org/docs/8/modules/json-api It is assumed that API consumers support the following: Can traverse data. Can cache based on response headers. Can resolve relationships by following links. Drupal JSONAPI and related modules \u00b6 jsonapi - main module that exposes entities as endpoints and provides support for REST operations. jsonapi_extras - helper module to alter JSONAPI config: endpoints prefix (we are using /api/v1 ) and enable/disable endpoints for automatically exposed entities (we use this to limit access to internal entities). Endpoints \u00b6 Component Content API endpoint Comment 1 route /api/v1/route?alias=<alias> 2 main menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=main 3 banner TBD If exposed as a block - use block-based endpoint. If exposed as a content field - use entity endpoint with inclusion. 4 breadcrumbs TBD Not supported out of the box. May need to use main menu to build breadcrumbs by FEF. 5 content /api/v1/page/<UUID>?include=field_page_paragraph Can be combined with 6 6 related content /api/v1/page/<UUID>?include=field_related_content Can be combined with 5 7 share block /api/v1/block_content/share_block Content is static HTML 8 was this page helpful TBD Posting of webform submissions is not supported. Custom module may be required. 9 footer main menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=main 10 copyright /api/v1/block_content/copyright Content is static HTML 11 footer menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=footer 12 Sites information /api/v1/taxonomy_term/sites 13 Router /api/v1/router Alias lookup. May be required for ad-hoc queries from FEF. Page example that may use these endpoints Request flow \u00b6 The diagram below demonstrates how a single page is assembled by VueJS when hitting multiple endpoints. VueJS retrieves site information and caches it internally until the next cache clear. Each consumer site has only site UUID (taxonomy term UUID from Site vocabulary) hardcoded. The rest of configuration comes from taxonomy term: logo, slogan, footer text, main menu name, footer menu name. This information is later used in follow-up requests to retrieve relevant information. Content API Content , Content API Menu , and Content API Block are shown here as separated endpoints (they are indeed separate), but are handled by the same internal entity controller from JSONAPI Drupal module. The content is filtered by Content API Filter based on provided site and path query parameters. If no site or path is provided the request is considered invalid and an error response is returned. Content API Filter is a thin layer (e.g. request event listener) in front of all JSONAPI endpoints. For example, if the content exists, but is not assigned to a site or section, it is considered as non-existing content when accessed from this site. Internal Router is a mechanism to lookup internal path by provided alias. There is a similar functionality with a Router Endpoint , but it resolves aliases without additional Drupal-to-Drupal request. End-to-end URL resolution \u00b6 The diagram below describes how URL requested by a web browser is resolved by Drupal and served by VueJS. It covers both front-end and back-end mechanisms. To leverage JSONAPI module in Drupal, we are using API Router to resolve requested paths to a set of information about the route (UUID, content type, path, alias). This information then used by Client API path builder to assemble a path to then send a second request to the JSONAPI endpoint. It is important to note that due to how content links can be provided within content, the path resolution within API Router should be able to find the best match from either path or alias provided. For example, paths about-us , /about-us , node/123 , /node/123 should all resolve to UUID of About Us page. When matched entity found, API Router also checks if it has the specified site assigned and returns an error if this path is not available. Also, API Router has all lookups cached in Drupal's dynamic cache, which is tagged with cache tags (so that the cache for path is cleared when entity is updated). Router API endpoint \u00b6 To control content aliases from Drupal and resolve requests coming from Browser into FEF, a special Router endpoint exists to perform a lookup on provided path. Because the provided path can be either internal Drupal path or an alias, the lookup searches through all existing aliases and internal paths. When non-existing alias is provided, the endpoint returns an error according to JSONAPI specification. Router API also allows to filter by site if site URL query parameter is provided. Referenced entities \u00b6 JSONAPI supports including referenced entities in response by using include query parameter and a comma-separated list of entity reference fields. For example, /api/v1/page/<UUID>?include=field_page_paragraph . Drupal caching \u00b6 Response headers pass-through Drupal-generated cache tags. This means that reverse proxies can bind to Drupal cache tags and invalidate their caches as soon as Drupal caches become invalid.","title":"API"},{"location":"tide/api/#tide-api","text":"Content API is built from a set of contributed modules and custom code provided through Tide API module.","title":"Tide API"},{"location":"tide/api/#why-jsonapi","text":"Why we selected JSONAPI standard over generic REST provided by Drupal core: JSON is a standard of REST, a subset of generic REST rules. JSONAPI allows to query individual items and collections. Drupal JSONAPI module automatically exposes entities as endpoints. Because most of functionality is implement as entities in Drupal 8, there is no need for custom code to expose required features. JSONAPI is a newer format JSONAPI will be included in Drupal core. Documentation on using Drupal JSONAPI module: https://www.drupal .org/docs/8/modules/json-api It is assumed that API consumers support the following: Can traverse data. Can cache based on response headers. Can resolve relationships by following links.","title":"Why JSONAPI?"},{"location":"tide/api/#drupal-jsonapi-and-related-modules","text":"jsonapi - main module that exposes entities as endpoints and provides support for REST operations. jsonapi_extras - helper module to alter JSONAPI config: endpoints prefix (we are using /api/v1 ) and enable/disable endpoints for automatically exposed entities (we use this to limit access to internal entities).","title":"Drupal JSONAPI and related modules"},{"location":"tide/api/#endpoints","text":"Component Content API endpoint Comment 1 route /api/v1/route?alias=<alias> 2 main menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=main 3 banner TBD If exposed as a block - use block-based endpoint. If exposed as a content field - use entity endpoint with inclusion. 4 breadcrumbs TBD Not supported out of the box. May need to use main menu to build breadcrumbs by FEF. 5 content /api/v1/page/<UUID>?include=field_page_paragraph Can be combined with 6 6 related content /api/v1/page/<UUID>?include=field_related_content Can be combined with 5 7 share block /api/v1/block_content/share_block Content is static HTML 8 was this page helpful TBD Posting of webform submissions is not supported. Custom module may be required. 9 footer main menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=main 10 copyright /api/v1/block_content/copyright Content is static HTML 11 footer menu /api/v1/menu_link_content/menu_link_content?filter[menu_name][value]=footer 12 Sites information /api/v1/taxonomy_term/sites 13 Router /api/v1/router Alias lookup. May be required for ad-hoc queries from FEF. Page example that may use these endpoints","title":"Endpoints"},{"location":"tide/api/#request-flow","text":"The diagram below demonstrates how a single page is assembled by VueJS when hitting multiple endpoints. VueJS retrieves site information and caches it internally until the next cache clear. Each consumer site has only site UUID (taxonomy term UUID from Site vocabulary) hardcoded. The rest of configuration comes from taxonomy term: logo, slogan, footer text, main menu name, footer menu name. This information is later used in follow-up requests to retrieve relevant information. Content API Content , Content API Menu , and Content API Block are shown here as separated endpoints (they are indeed separate), but are handled by the same internal entity controller from JSONAPI Drupal module. The content is filtered by Content API Filter based on provided site and path query parameters. If no site or path is provided the request is considered invalid and an error response is returned. Content API Filter is a thin layer (e.g. request event listener) in front of all JSONAPI endpoints. For example, if the content exists, but is not assigned to a site or section, it is considered as non-existing content when accessed from this site. Internal Router is a mechanism to lookup internal path by provided alias. There is a similar functionality with a Router Endpoint , but it resolves aliases without additional Drupal-to-Drupal request.","title":"Request flow"},{"location":"tide/api/#end-to-end-url-resolution","text":"The diagram below describes how URL requested by a web browser is resolved by Drupal and served by VueJS. It covers both front-end and back-end mechanisms. To leverage JSONAPI module in Drupal, we are using API Router to resolve requested paths to a set of information about the route (UUID, content type, path, alias). This information then used by Client API path builder to assemble a path to then send a second request to the JSONAPI endpoint. It is important to note that due to how content links can be provided within content, the path resolution within API Router should be able to find the best match from either path or alias provided. For example, paths about-us , /about-us , node/123 , /node/123 should all resolve to UUID of About Us page. When matched entity found, API Router also checks if it has the specified site assigned and returns an error if this path is not available. Also, API Router has all lookups cached in Drupal's dynamic cache, which is tagged with cache tags (so that the cache for path is cleared when entity is updated).","title":"End-to-end URL resolution"},{"location":"tide/api/#router-api-endpoint","text":"To control content aliases from Drupal and resolve requests coming from Browser into FEF, a special Router endpoint exists to perform a lookup on provided path. Because the provided path can be either internal Drupal path or an alias, the lookup searches through all existing aliases and internal paths. When non-existing alias is provided, the endpoint returns an error according to JSONAPI specification. Router API also allows to filter by site if site URL query parameter is provided.","title":"Router API endpoint"},{"location":"tide/api/#referenced-entities","text":"JSONAPI supports including referenced entities in response by using include query parameter and a comma-separated list of entity reference fields. For example, /api/v1/page/<UUID>?include=field_page_paragraph .","title":"Referenced entities"},{"location":"tide/api/#drupal-caching","text":"Response headers pass-through Drupal-generated cache tags. This means that reverse proxies can bind to Drupal cache tags and invalidate their caches as soon as Drupal caches become invalid.","title":"Drupal caching"},{"location":"tide/fields-components/","text":"Fields and components \u00b6 Tide utilises Drupal fields within content types and other entities such as paragraphs and taxonomy terms. Concepts \u00b6 Fields are re-used between system components as much as possible. Fields names are kept to the minimum length. Fields always have a prefix that describes the entity or the feature they belong to. For example: field_page_intro_text is a Introductory text for Page content type. Fields configuration is bundled within Tide modules. Some fields are programmatically created when specific Tide modules are installed (for example, Tide Site creates 2 fields for each content type). Kinds of fields \u00b6 Content fields - used to capture and store content that is later exposed through API and consumed by the front-end. For example, Body or Summary fields. Flag (on/off) fields - used to enable/disable rendering of a pre-defined component/block/feature within front-end. For example, Show social links field that tells consumer front-end to show or hide Social links component. Reference fields - used to reference other content items. These are rendered in API as references; API consumers are expected to use ?include JSONAPI standard mechanism to include the contents of the referenced entity into the API response. For example, Cards components are paragraphs referenced from within the content type. Front-end must include paragraph name to retrieve required paragraph content. Cards \u00b6 Cards are front-end components that are implemented as paragraph items in Tide. Cards implemented as Paragraphs Cards are reusing fields storage (see the list of fields below). List of Card fields Name Machine name Type Title field_paragraph_title Text field Summary field_paragraph_summary Large multiline text field with WYSIWYG support Author field_paragraph_author Text field Media field_paragraph_media Media field Date field_paragraph_date Date field Link field_paragraph_link Link field List field_paragraph_list Entity reference Location field_paragraph_location Location/ Reference field_paragraph_reference Entity reference Topic field_paragraph_topic Entity reference Cards have 1-to-1 mapping to paragraphs. This means that: cards can be added/removed from/to consumer front-end websites and have their paragraphs counterparts created in Content repository mandatory state of the fields on cards is easier to configure and manage there is no need to manage any other 'types' of the same card (i.e. no special fields that would modify the 'type' of the card) Automated cards are using list entity reference field to reference items. Listing cards are comprised of paragraphs (for example, Key Dates paragraph will have a list of Event paragraphs). About Automated cards Automated cards are cards that source their content from a pre-defined mapping in the Content APU. For example, a card with a list of latest 3 events that automatically fetches only 3 latest events. Cards and paragraphs The table below describes how every Card component is represented with Tide paragraphs . Card Label (in Drupal) Machine name Fields (label, machine name) Comments Navigation featured (Manual) Navigation featured card_navigation_featured Title - field_paragraph_title Summary - field_paragraph_summary Image - field_paragraph_media Link - field_paragraph_link This card has 1 text link. Link text = Title Navigation featured (Automatic) Navigation featured Automated card_navigation_featured_auto Referred content - field_paragraph_reference This card has 1 text link. Link text = Title Navigation (Manual) Navigation card_navigation Title - field_paragraph_title Summary - field_paragraph_summary Link - field_paragraph_link This card has 1 text link. Link text = Title Navigation Automated Navigation Automated card_navigation_auto Referred content - field_paragraph_reference This card has 1 text link. Link text = Title Promotion (Manual) Promotion card_promotion Title - field_paragraph_title Summary - field_paragraph_summary Image - field_paragraph_media Date - field_paragraph_date Topic - field_paragraph_topic Link - field_paragraph_link This card has 3 text links. Link 1 = Title Link 2 = Topic Link 3 = Link Promotion Automated Promotion Automated card_promotion_auto Referred content - field_paragraph_reference This card has 3 text links. Link 1 = Title Link 2 = Topic Link 3 = Link Event (Manual) Event card_event Title - field_paragraph_title Summary - field_paragraph_summary Image - field_paragraph_media Date - field_paragraph_date Location - field_paragraph_location Topic - field_paragraph_topic Link - field_paragraph_link This card has 4 text links. Link 1 = Title Link 2 = Location Link 3 = Topic Link 4 = Link Key dates (Manual) Key dates card_keydates 1. Add a paragraph type Keydates (with fields): Key Dates - field_paragraph_keydate Title - field_paragraph_title Summary - field_paragraph_summary Link - field_paragraph_link 2. Add a paragraph type - Card Keydates Keydates - Entity Ref - Paragraph type created above - Max 2 values CTA - field_paragraph_cta This card has 3 text links. Link 1 = Link (Keydates 1) Link 2 = Link (Keydates 2) Link 3 = CTA","title":"Fields and components"},{"location":"tide/fields-components/#fields-and-components","text":"Tide utilises Drupal fields within content types and other entities such as paragraphs and taxonomy terms.","title":"Fields and components"},{"location":"tide/fields-components/#concepts","text":"Fields are re-used between system components as much as possible. Fields names are kept to the minimum length. Fields always have a prefix that describes the entity or the feature they belong to. For example: field_page_intro_text is a Introductory text for Page content type. Fields configuration is bundled within Tide modules. Some fields are programmatically created when specific Tide modules are installed (for example, Tide Site creates 2 fields for each content type).","title":"Concepts"},{"location":"tide/fields-components/#kinds-of-fields","text":"Content fields - used to capture and store content that is later exposed through API and consumed by the front-end. For example, Body or Summary fields. Flag (on/off) fields - used to enable/disable rendering of a pre-defined component/block/feature within front-end. For example, Show social links field that tells consumer front-end to show or hide Social links component. Reference fields - used to reference other content items. These are rendered in API as references; API consumers are expected to use ?include JSONAPI standard mechanism to include the contents of the referenced entity into the API response. For example, Cards components are paragraphs referenced from within the content type. Front-end must include paragraph name to retrieve required paragraph content.","title":"Kinds of fields"},{"location":"tide/fields-components/#cards","text":"Cards are front-end components that are implemented as paragraph items in Tide. Cards implemented as Paragraphs Cards are reusing fields storage (see the list of fields below). List of Card fields Name Machine name Type Title field_paragraph_title Text field Summary field_paragraph_summary Large multiline text field with WYSIWYG support Author field_paragraph_author Text field Media field_paragraph_media Media field Date field_paragraph_date Date field Link field_paragraph_link Link field List field_paragraph_list Entity reference Location field_paragraph_location Location/ Reference field_paragraph_reference Entity reference Topic field_paragraph_topic Entity reference Cards have 1-to-1 mapping to paragraphs. This means that: cards can be added/removed from/to consumer front-end websites and have their paragraphs counterparts created in Content repository mandatory state of the fields on cards is easier to configure and manage there is no need to manage any other 'types' of the same card (i.e. no special fields that would modify the 'type' of the card) Automated cards are using list entity reference field to reference items. Listing cards are comprised of paragraphs (for example, Key Dates paragraph will have a list of Event paragraphs). About Automated cards Automated cards are cards that source their content from a pre-defined mapping in the Content APU. For example, a card with a list of latest 3 events that automatically fetches only 3 latest events.","title":"Cards"},{"location":"tide/modules/","text":"Modules \u00b6 The standalone modules are split based on the features or functionality they provide. Modules can be installed as a part of the profile as well as a standalone (provided that other dependency modules installed as well). Every module implements a well-defined feature set. Modules are versioned. This allows for more granular approach when picking modules for particular site needs. Every module has a minimal dependency on other modules. Every module has a set of relevant automated tests. List of modules \u00b6 Name Machine name Category Repository Description Tide API tide_api Utility https://github.com/dpc-sdp/tide_api Exposes content entities to API endpoints. it is required for sites running headless. Tide Core tide_core Utility https://github.com/dpc-sdp/tide_core Configurations and settings for Tide distribution. Dependency module for any other Tide module. Tide Event tide_event Content type https://github.com/dpc-sdp/tide_event Event content type and fields. Tide Landing Page tide_landing_page Content type https://github.com/dpc-sdp/tide_landing_page \"Landing page content type with fields. Based on paragrpahs, it allows to create pages with complex layouts.\" Tide Media tide_media Utility https://github.com/dpc-sdp/tide_media Media types and configurations. Tide Monsido tide_monsido 3 rd party integration https://github.com/dpc-sdp/tide_monsido Integration with Monsido platform. Tide News tide_news Content type https://github.com/dpc-sdp/tide_news Event content type and fields. Tide Page tide_page Content type https://github.com/dpc-sdp/tide_page Page content type and fields. Tide Search tide_search Utility https://github.com/dpc-sdp/tide_search Search configurations and settings. Tide Site tide_site Utility https://github.com/dpc-sdp/tide_site Multi-site and multi-section content sharing. Tide Test tide_test Utility https://github.com/dpc-sdp/tide_test Test content type and helpers used to test other modules. Tide Webform tide_webform Utility https://github.com/dpc-sdp/tide_webform Forms supports such as Content Rating form. Automated testing \u00b6 Tide modules use PHPUnit and Behat for unit and integration/behavioural testing. The tests are running inside of the Continuous Integration pipeline provided by CircleCI . For every change pushed to the repository, CircleCI starts the build, where tests are running in 2 modes: normal and suggested . In normal mode the module is installed with it's required dependencies into freshly built Drupal site. Once installed, the tests will run and check that the configuration shipped with the module indeed works. In suggested mode, the module is installed with it's requires and optional dependencies. Once installed, the tests will run and check that the configuration shipped with the module indeed works and that it does not conflict with other optional modules. This \"double-testing\" is very powerful tool to keep configuration in releasable state. Versions \u00b6 Modules versions follow semantic versioning : Quote Given a version number MAJOR.MINOR.PATCH , increment the: MAJOR version when you make incompatible API changes, MINOR version when you add functionality in a backwards-compatible manner, and PATCH version when you make backwards-compatible bug fixes. Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format. With some Tide functionality heavily relying on specific Drupal core version, when features added and changed in MINOR Drupal core versions (like moving Media into Drupal core), Tide modules increment their MAJOR version when Drupal core or dependent contributed modules change their API. Since Tide modules functionality is built on top of Drupal core and contributed modules, it has to \"tighten\" versioning rules. Every Tide module has to increment the: - MAJOR version when Drupal core or contrib module has an API change. An example of this is moving Media into Drupal core in version 8.5 . - MINOR version when Tide module functionality is enhanced or when other dependent Tide module has it's API change (that would trigger own release). - PATCH version when there is a backwards-compatible bug fixes (no change from SemVer). Maintenance \u00b6 SDP development team is committed to support development, maintain all Tide modules and follow versioning rules. Developing modules \u00b6 See Module development chapter.","title":"Modules"},{"location":"tide/modules/#modules","text":"The standalone modules are split based on the features or functionality they provide. Modules can be installed as a part of the profile as well as a standalone (provided that other dependency modules installed as well). Every module implements a well-defined feature set. Modules are versioned. This allows for more granular approach when picking modules for particular site needs. Every module has a minimal dependency on other modules. Every module has a set of relevant automated tests.","title":"Modules"},{"location":"tide/modules/#list-of-modules","text":"Name Machine name Category Repository Description Tide API tide_api Utility https://github.com/dpc-sdp/tide_api Exposes content entities to API endpoints. it is required for sites running headless. Tide Core tide_core Utility https://github.com/dpc-sdp/tide_core Configurations and settings for Tide distribution. Dependency module for any other Tide module. Tide Event tide_event Content type https://github.com/dpc-sdp/tide_event Event content type and fields. Tide Landing Page tide_landing_page Content type https://github.com/dpc-sdp/tide_landing_page \"Landing page content type with fields. Based on paragrpahs, it allows to create pages with complex layouts.\" Tide Media tide_media Utility https://github.com/dpc-sdp/tide_media Media types and configurations. Tide Monsido tide_monsido 3 rd party integration https://github.com/dpc-sdp/tide_monsido Integration with Monsido platform. Tide News tide_news Content type https://github.com/dpc-sdp/tide_news Event content type and fields. Tide Page tide_page Content type https://github.com/dpc-sdp/tide_page Page content type and fields. Tide Search tide_search Utility https://github.com/dpc-sdp/tide_search Search configurations and settings. Tide Site tide_site Utility https://github.com/dpc-sdp/tide_site Multi-site and multi-section content sharing. Tide Test tide_test Utility https://github.com/dpc-sdp/tide_test Test content type and helpers used to test other modules. Tide Webform tide_webform Utility https://github.com/dpc-sdp/tide_webform Forms supports such as Content Rating form.","title":"List of modules"},{"location":"tide/modules/#automated-testing","text":"Tide modules use PHPUnit and Behat for unit and integration/behavioural testing. The tests are running inside of the Continuous Integration pipeline provided by CircleCI . For every change pushed to the repository, CircleCI starts the build, where tests are running in 2 modes: normal and suggested . In normal mode the module is installed with it's required dependencies into freshly built Drupal site. Once installed, the tests will run and check that the configuration shipped with the module indeed works. In suggested mode, the module is installed with it's requires and optional dependencies. Once installed, the tests will run and check that the configuration shipped with the module indeed works and that it does not conflict with other optional modules. This \"double-testing\" is very powerful tool to keep configuration in releasable state.","title":"Automated testing"},{"location":"tide/modules/#versions","text":"Modules versions follow semantic versioning : Quote Given a version number MAJOR.MINOR.PATCH , increment the: MAJOR version when you make incompatible API changes, MINOR version when you add functionality in a backwards-compatible manner, and PATCH version when you make backwards-compatible bug fixes. Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format. With some Tide functionality heavily relying on specific Drupal core version, when features added and changed in MINOR Drupal core versions (like moving Media into Drupal core), Tide modules increment their MAJOR version when Drupal core or dependent contributed modules change their API. Since Tide modules functionality is built on top of Drupal core and contributed modules, it has to \"tighten\" versioning rules. Every Tide module has to increment the: - MAJOR version when Drupal core or contrib module has an API change. An example of this is moving Media into Drupal core in version 8.5 . - MINOR version when Tide module functionality is enhanced or when other dependent Tide module has it's API change (that would trigger own release). - PATCH version when there is a backwards-compatible bug fixes (no change from SemVer).","title":"Versions"},{"location":"tide/modules/#maintenance","text":"SDP development team is committed to support development, maintain all Tide modules and follow versioning rules.","title":"Maintenance"},{"location":"tide/modules/#developing-modules","text":"See Module development chapter.","title":"Developing modules"},{"location":"tide/setup/","text":"Setting up a new Content Repository \u00b6 Note This chapter describes how to setup Content Repository using whole Tide distribution with all Tide modules included. It does not cover setting up of Tide modules outside of the distribution. Setup \u00b6 Setting up Tide Content Repository is similar to setting up a Drupal site from any other contributed profile. Create drupal project. Using drupal-project composer create-project drupal-composer/drupal-project:8.x-dev some-dir --no-interaction Add Tide profile: composer require dpc-sdp/tide Commit scaffolding files. Install a site using drush site-install : drush site-install tide --db-url=mysql://user:pwd@localhost/db_name --site-name=Example --account-name=admin --account-pass=pwd Export the database and import it into your production database. Hosting on Bay \u00b6 Content repository can be hosted on Bay. See Onboarding to Bay chapter. Environments \u00b6 The diagram below describes recommended environments for efficient front-end and back-end development: Production front-end sites are connected to production Content repository where API is stable and content is live. This is standard environments for production sites. UAT front-end sites are connected to UAT Content repository, where API is stable and content is live, but changes are not public. These environments allow to work with a copy of the live content without exposing it to public, which is useful during new feature testing. Local, CI and Preview (per branch) environments are connected to API-DEV Content repository, where the latest API is still being developed and demonstrative-only but consistent content. This provides access to the latest API changes while developing new front-end or back-end functionality. Other content consumers under active development may connect to the API Content repository with stable API and demonstrative-only but consistent content. This allows predictable API behaviour and data, but without access to change it.","title":"Content repository setup"},{"location":"tide/setup/#setting-up-a-new-content-repository","text":"Note This chapter describes how to setup Content Repository using whole Tide distribution with all Tide modules included. It does not cover setting up of Tide modules outside of the distribution.","title":"Setting up a new Content Repository"},{"location":"tide/setup/#setup","text":"Setting up Tide Content Repository is similar to setting up a Drupal site from any other contributed profile. Create drupal project. Using drupal-project composer create-project drupal-composer/drupal-project:8.x-dev some-dir --no-interaction Add Tide profile: composer require dpc-sdp/tide Commit scaffolding files. Install a site using drush site-install : drush site-install tide --db-url=mysql://user:pwd@localhost/db_name --site-name=Example --account-name=admin --account-pass=pwd Export the database and import it into your production database.","title":"Setup"},{"location":"tide/setup/#hosting-on-bay","text":"Content repository can be hosted on Bay. See Onboarding to Bay chapter.","title":"Hosting on Bay"},{"location":"tide/setup/#environments","text":"The diagram below describes recommended environments for efficient front-end and back-end development: Production front-end sites are connected to production Content repository where API is stable and content is live. This is standard environments for production sites. UAT front-end sites are connected to UAT Content repository, where API is stable and content is live, but changes are not public. These environments allow to work with a copy of the live content without exposing it to public, which is useful during new feature testing. Local, CI and Preview (per branch) environments are connected to API-DEV Content repository, where the latest API is still being developed and demonstrative-only but consistent content. This provides access to the latest API changes while developing new front-end or back-end functionality. Other content consumers under active development may connect to the API Content repository with stable API and demonstrative-only but consistent content. This allows predictable API behaviour and data, but without access to change it.","title":"Environments"},{"location":"tide/sites-sections/","text":"Sites and sections \u00b6 Content repository supports multi-site and multi-section content publishing. This means that a content piece may be re-used several times on multiple sites and sections ( sections belong to sites ). Tide Site module provides an ability for Editor to publish content to selected sites and sections . How it works \u00b6 Sites and sections defined in a single vocabulary Sites with the maximum depth of 1, making root-level terms to become sites and terms of depth level 1 to become sections . The module has code to provide back-end validation to prevent creating of terms with depth more than 1. We decided to use Drupal taxonomy for sites and sections for multiple reasons: Taxonomy terms are fieldable entities. This means that consumer sites can extend per-site properties as required, exposing them to the API. Taxonomy terms support hierarchy, which helps to define site-section relationship, and, as a result of this, easily filter associated content by site. Taxonomy terms can be selected in UI using one of the existing contributed widgets. Taxonomy terms have full Token and Pathauto support, which makes it easy to use them for building content URLs based on IA. Taxonomy terms have full JSONAPI support and can be queried by consumer front-ends in the same way as any other entities. The concept of using taxonomy terms to group content is easy to grasp. Content may be shared between sites, but never between sections, as this would lead to the same content being served from different URLs, which is highly discouraged by search engines. To mitigate the problem when the same content is shared between different websites, a selection of Primary site is required, which will be used to generate canonical URL for the content piece. As a result, every content type has 2 fields created automatically: site and primary_site . Both fields are compulsory. Editors are expected to select destination site and section for each content piece. Site and Section Fields \u00b6 To provide site and section-specific information through API, every Site taxonomy term has a set of the following information fields: Field Description Domains Multiline plain text field to specify site domains. This is used by Ripple to match on the domain where the request is coming from. One domain per line. Wildcards supported. Title Text field to specify site title. Slogan Text field to specify site slogan. Logo File field to upload site logo. Footer message Text field with WYSIWYG support to specify site footer message. Main Menu Per-site and per-section menus may be helpful to build section-based navigation experience. Site admins may associate existing or create new menu with every site term. This is an entity reference field. Footer Menu Per-site and per-section menus may be helpful to build section-based navigation experience. Site admins may associate existing or create new menu with every site term. This is an entity reference field. Site menus \u00b6 Per-site and per-section menus may be helpful to build section-based navigation experience. They allow to provide custom menu items for specific sites and sections. Site menus automatically created when a new Site taxonomy term is created. Basically, instead of creating a site and then creating a menu on the separate screen, we automatically create and assign a menu for each site within the site creation screen by checking relevant checkbox on Site term ctreation page. Expand for Site menu creation flow diagram Multi-site URL rendering \u00b6 When content piece belongs to multiple sites or sections, it may have links to it from other content pieces of the current domain or other domains. Drupal has to render these links with correct domains as a part of url, so that front-end consumers could output these links as-is. For example, if we have: - 2 sites first.com and second.com - 2 pages page1 and page2 - page1 has a link to page2 - page1 belongs to first.com - page2 belongs to both first.com and second.com; the primary site is set to second.com When the visitor is on the page first.com/page1 and follows the link /page2 she should end up on first.com/page2 and not second.com/page2 . And if the visitor comes from Google search to page2 , she should end up at second.com/page2 , because second.com is a primary site for page2 . This is just an example of the part of the problem. There are more use-cases and they are explained below. For content exposed through API, the links may come from different places: - For link fields, this should be fairly straightforward: the user enters the link and we have an internal node id. - For links entered in WYSIWYG, we need to use the LinkIt module so that we can extract a node id. - For links entered in WYSIWYG within referenced entities (for example, field on the paragraph belonging to the page) the API output will contains the path alias. For all links presented to the user: - internal links should be rendered as a relative path. If the link is to a page available on the current site, either primary or not, render as relative link - external links (including links to other sites/section) should be rendered with an absolute path. For links within WYSIWYG, Drupal has to extract, analyse and replace links before rendering it through API. For this, we use an enhancer (special piece of code to manipulate content output before it is rendered through API) to scrape the content, then render the relevant link. Implementation details The content is extracted from the raw contents of WYSIWYG filed using Link Extractor . Link Extractor scans HTML and extracts all links. This happens before Drupal sanitizes WYSIWYG field output. Every extracted link is then passed to a Link Resolver . Link Resolver takes node id, loads up the path alias using some complex logic (see diagram below) and then swaps it within the href. Resolved URL is then passed to Link Replacer . Link Replacer replaces old extracted links with new resolved ones within contents of the WYSIWYG field. The processsed field contents is then passed to API for normal rendering. For links coming from Link fields, the above applies, but starting from Link Resolver (there is no HTML to extarct teh link from , so Link Extractor is not required). The following diagram describes URL processing and link resolution in detail.","title":"Sites and sections"},{"location":"tide/sites-sections/#sites-and-sections","text":"Content repository supports multi-site and multi-section content publishing. This means that a content piece may be re-used several times on multiple sites and sections ( sections belong to sites ). Tide Site module provides an ability for Editor to publish content to selected sites and sections .","title":"Sites and sections"},{"location":"tide/sites-sections/#how-it-works","text":"Sites and sections defined in a single vocabulary Sites with the maximum depth of 1, making root-level terms to become sites and terms of depth level 1 to become sections . The module has code to provide back-end validation to prevent creating of terms with depth more than 1. We decided to use Drupal taxonomy for sites and sections for multiple reasons: Taxonomy terms are fieldable entities. This means that consumer sites can extend per-site properties as required, exposing them to the API. Taxonomy terms support hierarchy, which helps to define site-section relationship, and, as a result of this, easily filter associated content by site. Taxonomy terms can be selected in UI using one of the existing contributed widgets. Taxonomy terms have full Token and Pathauto support, which makes it easy to use them for building content URLs based on IA. Taxonomy terms have full JSONAPI support and can be queried by consumer front-ends in the same way as any other entities. The concept of using taxonomy terms to group content is easy to grasp. Content may be shared between sites, but never between sections, as this would lead to the same content being served from different URLs, which is highly discouraged by search engines. To mitigate the problem when the same content is shared between different websites, a selection of Primary site is required, which will be used to generate canonical URL for the content piece. As a result, every content type has 2 fields created automatically: site and primary_site . Both fields are compulsory. Editors are expected to select destination site and section for each content piece.","title":"How it works"},{"location":"tide/sites-sections/#site-and-section-fields","text":"To provide site and section-specific information through API, every Site taxonomy term has a set of the following information fields: Field Description Domains Multiline plain text field to specify site domains. This is used by Ripple to match on the domain where the request is coming from. One domain per line. Wildcards supported. Title Text field to specify site title. Slogan Text field to specify site slogan. Logo File field to upload site logo. Footer message Text field with WYSIWYG support to specify site footer message. Main Menu Per-site and per-section menus may be helpful to build section-based navigation experience. Site admins may associate existing or create new menu with every site term. This is an entity reference field. Footer Menu Per-site and per-section menus may be helpful to build section-based navigation experience. Site admins may associate existing or create new menu with every site term. This is an entity reference field.","title":"Site and Section Fields"},{"location":"tide/sites-sections/#site-menus","text":"Per-site and per-section menus may be helpful to build section-based navigation experience. They allow to provide custom menu items for specific sites and sections. Site menus automatically created when a new Site taxonomy term is created. Basically, instead of creating a site and then creating a menu on the separate screen, we automatically create and assign a menu for each site within the site creation screen by checking relevant checkbox on Site term ctreation page. Expand for Site menu creation flow diagram","title":"Site menus"},{"location":"tide/sites-sections/#multi-site-url-rendering","text":"When content piece belongs to multiple sites or sections, it may have links to it from other content pieces of the current domain or other domains. Drupal has to render these links with correct domains as a part of url, so that front-end consumers could output these links as-is. For example, if we have: - 2 sites first.com and second.com - 2 pages page1 and page2 - page1 has a link to page2 - page1 belongs to first.com - page2 belongs to both first.com and second.com; the primary site is set to second.com When the visitor is on the page first.com/page1 and follows the link /page2 she should end up on first.com/page2 and not second.com/page2 . And if the visitor comes from Google search to page2 , she should end up at second.com/page2 , because second.com is a primary site for page2 . This is just an example of the part of the problem. There are more use-cases and they are explained below. For content exposed through API, the links may come from different places: - For link fields, this should be fairly straightforward: the user enters the link and we have an internal node id. - For links entered in WYSIWYG, we need to use the LinkIt module so that we can extract a node id. - For links entered in WYSIWYG within referenced entities (for example, field on the paragraph belonging to the page) the API output will contains the path alias. For all links presented to the user: - internal links should be rendered as a relative path. If the link is to a page available on the current site, either primary or not, render as relative link - external links (including links to other sites/section) should be rendered with an absolute path. For links within WYSIWYG, Drupal has to extract, analyse and replace links before rendering it through API. For this, we use an enhancer (special piece of code to manipulate content output before it is rendered through API) to scrape the content, then render the relevant link. Implementation details The content is extracted from the raw contents of WYSIWYG filed using Link Extractor . Link Extractor scans HTML and extracts all links. This happens before Drupal sanitizes WYSIWYG field output. Every extracted link is then passed to a Link Resolver . Link Resolver takes node id, loads up the path alias using some complex logic (see diagram below) and then swaps it within the href. Resolved URL is then passed to Link Replacer . Link Replacer replaces old extracted links with new resolved ones within contents of the WYSIWYG field. The processsed field contents is then passed to API for normal rendering. For links coming from Link fields, the above applies, but starting from Link Resolver (there is no HTML to extarct teh link from , so Link Extractor is not required). The following diagram describes URL processing and link resolution in detail.","title":"Multi-site URL rendering"}]}